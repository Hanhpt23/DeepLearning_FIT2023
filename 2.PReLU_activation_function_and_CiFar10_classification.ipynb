{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanhpt23/DeepLearning_FIT2023/blob/main/PReLU_activation_function_and_CiFar10_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Grandient Descent"
      ],
      "metadata": {
        "id": "JS8-tKm-k2Dz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem**: Consider a single neuron with 3 inputs and PReLU activation function. Find the mathematical formula for the gradient of the activated output with respect to its incoming weights and the learnable PReLU parameter.\n",
        "\n",
        "**Solution:**\n",
        "\n",
        "A single neuron with 3 inputs and PReLU activation function can be difined in terms of\n",
        "\n",
        "- Inputs:`x0, x1, x2, x3`\n",
        "- Weights: `1, w1, w2, w3`\n",
        "- PReLU parameter: `a` (learnable)\n",
        "\n",
        "The output of the neuron before the activation function is given by:\n",
        "$$\n",
        "z = x_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2 + w_3 \\cdot x_3\n",
        "$$\n",
        "\n",
        "Parametric Rectified Linear Unit (PReLU) activation function can be expressed as follows:\n",
        "$$\n",
        "y = f(z) = \\begin{cases}\n",
        "z & \\text{if } z > 0 \\\\\n",
        "a \\cdot z & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The gradient of (PReLU) with respect to `w_1` can be expressed as follows:\n",
        "$$\n",
        "\\frac{\\partial y}{\\partial w_1} = \\frac{\\partial y}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w_1} = \\begin{cases}\n",
        "x_1 & \\text{if } z > 0 \\\\\n",
        "a \\cdot x_1 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The gradient of (PReLU) with respect to `w_2` can be expressed as follows:\n",
        "$$\n",
        "\\frac{\\partial y}{\\partial w_2} = \\frac{\\partial y}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w_2} = \\begin{cases}\n",
        "x_2 & \\text{if } z > 0 \\\\\n",
        "a \\cdot x_2 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The gradient of (PReLU) with respect to `w_3` can be expressed as follows:\n",
        "$$\n",
        "\\frac{\\partial y}{\\partial w_3} = \\frac{\\partial y}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w_3} = \\begin{cases}\n",
        "x_3 & \\text{if } z > 0 \\\\\n",
        "a \\cdot x_3 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The gradient of (PReLU) with respect to `a` can be expressed as follows:\n",
        "$$\n",
        "\\frac{\\partial y}{\\partial a} = \\begin{cases}\n",
        "0 & \\text{if } z > 0 \\\\\n",
        "x_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2 + w_3 \\cdot x_3 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "<!-- $$\n",
        "\\frac{df(Z)}{dZ} = \\begin{cases}\n",
        "1 & \\text{if } x > 0 \\\\\n",
        "a & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$ -->\n",
        "\n"
      ],
      "metadata": {
        "id": "NMXuR03GFpKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Building dense Neural Networks for CiFar10\n",
        "**Problem**: Building a deep learning model using fully connected neural networks for CiFar10 classification.\n",
        "\n",
        "**Solution:**"
      ],
      "metadata": {
        "id": "A_xmKZ0kkYO5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYtyftBLy1yL"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aJzFL0vmEcC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNgfs9koucVF"
      },
      "source": [
        "## Split the data into 60% training, 20% validation, and 20% testing with random_state = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMbswFX5uF9J",
        "outputId": "189cb0a1-fd6c-4199-ca75-deb4c508010b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n",
            "30000 30000 10000 10000 10000 10000\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "random_state = 1\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(x_train, y_train, test_size=0.4, random_state=random_state)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=random_state)\n",
        "\n",
        "print(len(x_train), len(y_train), len(x_val), len(y_val), len(x_test), len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK4cS2S_pXNm"
      },
      "outputs": [],
      "source": [
        "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking inputs and ground truths"
      ],
      "metadata": {
        "id": "h4Ss0HxSQpey"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "91l2VyM8p3Q4",
        "outputId": "6a0461f2-b142-4e12-d8f7-b7697ccdd077"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_sample(X, y, index):\n",
        "    plt.figure(figsize = (15,2))\n",
        "    plt.imshow(X[index])\n",
        "    plt.xlabel(classes[int(y[index])])\n",
        "\n",
        "plot_sample(x_test, y_test, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU4UL0mLsbSQ"
      },
      "source": [
        "##Normalizing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3PTpoW_xx6E",
        "outputId": "8fe0d660-1878-46f9-a9b0-97441e1c6f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 1.0 1.0\n"
          ]
        }
      ],
      "source": [
        "# Convert pixel values to floats and scale to the range [0, 1]\n",
        "X_train = x_train.astype('float32') / 255.0\n",
        "X_val = x_val.astype('float32') / 255.0\n",
        "X_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "print(X_train.max(), X_val.max(), X_test.max())\n",
        "\n",
        "# Calculate the mean and standard deviation of the training data\n",
        "mean = np.mean(X_train, axis=(0, 1, 2, 3))\n",
        "std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "\n",
        "# Standardize the data using the mean and standard deviation\n",
        "X_train_norm = (X_train - mean) / (std + 1e-7)\n",
        "X_val_norm = (X_val - mean) / (std + 1e-7)\n",
        "X_test_norm = (X_test - mean) / (std + 1e-7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sv-m81dAZny",
        "outputId": "fd48bd87-ed32-4eac-c891-a1ff800600f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.094039 2.094039 2.094039\n"
          ]
        }
      ],
      "source": [
        "print(X_train_norm.max(), X_val_norm.max(), X_test_norm.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDc2CJbY24jE"
      },
      "source": [
        "## One-node Classifier\n",
        "\n",
        "- Training Runtime: 394.98 seconds\n",
        "- Test Loss: 1.7291\n",
        "- Test Accuracy: 0.4082"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGGmethY3AvE",
        "outputId": "689c3e99-c3a7-4ef4-9b2c-5cd654bd6790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.6642 - accuracy: 0.2227\n",
            "Epoch 1: val_loss improved from inf to 1.91003, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 2.6640 - accuracy: 0.2227 - val_loss: 1.9100 - val_accuracy: 0.3443\n",
            "Epoch 2/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.3950 - accuracy: 0.2698\n",
            "Epoch 2: val_loss improved from 1.91003 to 1.85697, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.3949 - accuracy: 0.2699 - val_loss: 1.8570 - val_accuracy: 0.3649\n",
            "Epoch 3/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 2.2933 - accuracy: 0.2833\n",
            "Epoch 3: val_loss improved from 1.85697 to 1.81572, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 2.2924 - accuracy: 0.2835 - val_loss: 1.8157 - val_accuracy: 0.3714\n",
            "Epoch 4/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 2.2201 - accuracy: 0.2986\n",
            "Epoch 4: val_loss improved from 1.81572 to 1.81302, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.2193 - accuracy: 0.2989 - val_loss: 1.8130 - val_accuracy: 0.3736\n",
            "Epoch 5/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 2.1422 - accuracy: 0.3075\n",
            "Epoch 5: val_loss improved from 1.81302 to 1.78231, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.1424 - accuracy: 0.3073 - val_loss: 1.7823 - val_accuracy: 0.3870\n",
            "Epoch 6/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 2.0958 - accuracy: 0.3150\n",
            "Epoch 6: val_loss improved from 1.78231 to 1.78009, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 2.0964 - accuracy: 0.3148 - val_loss: 1.7801 - val_accuracy: 0.3825\n",
            "Epoch 7/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 2.0517 - accuracy: 0.3199\n",
            "Epoch 7: val_loss improved from 1.78009 to 1.76925, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 2.0509 - accuracy: 0.3203 - val_loss: 1.7693 - val_accuracy: 0.3928\n",
            "Epoch 8/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 2.0097 - accuracy: 0.3327\n",
            "Epoch 8: val_loss improved from 1.76925 to 1.76313, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.0099 - accuracy: 0.3323 - val_loss: 1.7631 - val_accuracy: 0.3897\n",
            "Epoch 9/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.9786 - accuracy: 0.3348\n",
            "Epoch 9: val_loss improved from 1.76313 to 1.75694, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.9779 - accuracy: 0.3350 - val_loss: 1.7569 - val_accuracy: 0.3912\n",
            "Epoch 10/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.9463 - accuracy: 0.3431\n",
            "Epoch 10: val_loss improved from 1.75694 to 1.74527, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 1.9461 - accuracy: 0.3432 - val_loss: 1.7453 - val_accuracy: 0.3976\n",
            "Epoch 11/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.9175 - accuracy: 0.3479\n",
            "Epoch 11: val_loss did not improve from 1.74527\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.9174 - accuracy: 0.3478 - val_loss: 1.7506 - val_accuracy: 0.3967\n",
            "Epoch 12/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.8934 - accuracy: 0.3533\n",
            "Epoch 12: val_loss did not improve from 1.74527\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.8935 - accuracy: 0.3531 - val_loss: 1.7485 - val_accuracy: 0.3974\n",
            "Epoch 13/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.8775 - accuracy: 0.3558\n",
            "Epoch 13: val_loss did not improve from 1.74527\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.8783 - accuracy: 0.3556 - val_loss: 1.7465 - val_accuracy: 0.3985\n",
            "Epoch 14/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.8634 - accuracy: 0.3617\n",
            "Epoch 14: val_loss improved from 1.74527 to 1.74255, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.8629 - accuracy: 0.3618 - val_loss: 1.7426 - val_accuracy: 0.4008\n",
            "Epoch 15/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.8420 - accuracy: 0.3671\n",
            "Epoch 15: val_loss improved from 1.74255 to 1.73634, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.8422 - accuracy: 0.3668 - val_loss: 1.7363 - val_accuracy: 0.4013\n",
            "Epoch 16/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.8335 - accuracy: 0.3722\n",
            "Epoch 16: val_loss did not improve from 1.73634\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.8330 - accuracy: 0.3725 - val_loss: 1.7399 - val_accuracy: 0.4017\n",
            "Epoch 17/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.8152 - accuracy: 0.3722\n",
            "Epoch 17: val_loss improved from 1.73634 to 1.73207, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.8149 - accuracy: 0.3723 - val_loss: 1.7321 - val_accuracy: 0.4029\n",
            "Epoch 18/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.8061 - accuracy: 0.3786\n",
            "Epoch 18: val_loss did not improve from 1.73207\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.8062 - accuracy: 0.3784 - val_loss: 1.7347 - val_accuracy: 0.4046\n",
            "Epoch 19/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.7943 - accuracy: 0.3813\n",
            "Epoch 19: val_loss did not improve from 1.73207\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7943 - accuracy: 0.3813 - val_loss: 1.7334 - val_accuracy: 0.4071\n",
            "Epoch 20/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.7938 - accuracy: 0.3808\n",
            "Epoch 20: val_loss improved from 1.73207 to 1.73138, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7938 - accuracy: 0.3808 - val_loss: 1.7314 - val_accuracy: 0.4050\n",
            "Epoch 21/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.7873 - accuracy: 0.3873\n",
            "Epoch 21: val_loss improved from 1.73138 to 1.72956, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7873 - accuracy: 0.3872 - val_loss: 1.7296 - val_accuracy: 0.4043\n",
            "Epoch 22/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.7837 - accuracy: 0.3850\n",
            "Epoch 22: val_loss did not improve from 1.72956\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7837 - accuracy: 0.3852 - val_loss: 1.7378 - val_accuracy: 0.4033\n",
            "Epoch 23/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.7799 - accuracy: 0.3852\n",
            "Epoch 23: val_loss did not improve from 1.72956\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7799 - accuracy: 0.3852 - val_loss: 1.7314 - val_accuracy: 0.4021\n",
            "Epoch 24/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.7734 - accuracy: 0.3879\n",
            "Epoch 24: val_loss improved from 1.72956 to 1.72946, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7737 - accuracy: 0.3880 - val_loss: 1.7295 - val_accuracy: 0.4030\n",
            "Epoch 25/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.7684 - accuracy: 0.3903\n",
            "Epoch 25: val_loss did not improve from 1.72946\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 1.7688 - accuracy: 0.3903 - val_loss: 1.7362 - val_accuracy: 0.3987\n",
            "Epoch 26/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.7612 - accuracy: 0.3907\n",
            "Epoch 26: val_loss did not improve from 1.72946\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7611 - accuracy: 0.3907 - val_loss: 1.7353 - val_accuracy: 0.4069\n",
            "Epoch 27/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 1.7622 - accuracy: 0.3960\n",
            "Epoch 27: val_loss improved from 1.72946 to 1.72770, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 1.7633 - accuracy: 0.3958 - val_loss: 1.7277 - val_accuracy: 0.4017\n",
            "Epoch 28/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.7604 - accuracy: 0.3962\n",
            "Epoch 28: val_loss did not improve from 1.72770\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 1.7597 - accuracy: 0.3964 - val_loss: 1.7280 - val_accuracy: 0.4002\n",
            "Epoch 29/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.7597 - accuracy: 0.3924\n",
            "Epoch 29: val_loss did not improve from 1.72770\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7598 - accuracy: 0.3925 - val_loss: 1.7327 - val_accuracy: 0.4012\n",
            "Epoch 30/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.7531 - accuracy: 0.3964\n",
            "Epoch 30: val_loss improved from 1.72770 to 1.72365, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7532 - accuracy: 0.3965 - val_loss: 1.7236 - val_accuracy: 0.4034\n",
            "Epoch 31/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.7554 - accuracy: 0.3927\n",
            "Epoch 31: val_loss did not improve from 1.72365\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 1.7556 - accuracy: 0.3928 - val_loss: 1.7287 - val_accuracy: 0.4016\n",
            "Epoch 32/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.7526 - accuracy: 0.3950\n",
            "Epoch 32: val_loss did not improve from 1.72365\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7526 - accuracy: 0.3950 - val_loss: 1.7280 - val_accuracy: 0.4032\n",
            "Epoch 33/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.7490 - accuracy: 0.3951\n",
            "Epoch 33: val_loss improved from 1.72365 to 1.72258, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7504 - accuracy: 0.3947 - val_loss: 1.7226 - val_accuracy: 0.4093\n",
            "Epoch 34/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.7513 - accuracy: 0.3951\n",
            "Epoch 34: val_loss did not improve from 1.72258\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7510 - accuracy: 0.3954 - val_loss: 1.7361 - val_accuracy: 0.3999\n",
            "Epoch 35/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.7548 - accuracy: 0.3948\n",
            "Epoch 35: val_loss did not improve from 1.72258\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 1.7548 - accuracy: 0.3948 - val_loss: 1.7353 - val_accuracy: 0.3992\n",
            "Epoch 36/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.7498 - accuracy: 0.3959\n",
            "Epoch 36: val_loss did not improve from 1.72258\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7493 - accuracy: 0.3958 - val_loss: 1.7273 - val_accuracy: 0.4007\n",
            "Epoch 37/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.7477 - accuracy: 0.3982\n",
            "Epoch 37: val_loss did not improve from 1.72258\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7478 - accuracy: 0.3980 - val_loss: 1.7253 - val_accuracy: 0.4025\n",
            "Epoch 38/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.7439 - accuracy: 0.3976\n",
            "Epoch 38: val_loss did not improve from 1.72258\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7436 - accuracy: 0.3976 - val_loss: 1.7262 - val_accuracy: 0.4044\n",
            "Epoch 39/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.7475 - accuracy: 0.3960\n",
            "Epoch 39: val_loss did not improve from 1.72258\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7475 - accuracy: 0.3960 - val_loss: 1.7244 - val_accuracy: 0.4072\n",
            "Epoch 40/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.7426 - accuracy: 0.3976\n",
            "Epoch 40: val_loss improved from 1.72258 to 1.71977, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7430 - accuracy: 0.3975 - val_loss: 1.7198 - val_accuracy: 0.4083\n",
            "Epoch 41/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.7434 - accuracy: 0.3962\n",
            "Epoch 41: val_loss improved from 1.71977 to 1.71832, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7434 - accuracy: 0.3962 - val_loss: 1.7183 - val_accuracy: 0.4095\n",
            "Epoch 42/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.7451 - accuracy: 0.3993\n",
            "Epoch 42: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7452 - accuracy: 0.3993 - val_loss: 1.7312 - val_accuracy: 0.4048\n",
            "Epoch 43/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.7444 - accuracy: 0.4002\n",
            "Epoch 43: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7446 - accuracy: 0.4002 - val_loss: 1.7252 - val_accuracy: 0.4050\n",
            "Epoch 44/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.7460 - accuracy: 0.3965\n",
            "Epoch 44: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7461 - accuracy: 0.3965 - val_loss: 1.7257 - val_accuracy: 0.4082\n",
            "Epoch 45/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.7456 - accuracy: 0.3942\n",
            "Epoch 45: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7453 - accuracy: 0.3943 - val_loss: 1.7263 - val_accuracy: 0.4067\n",
            "Epoch 46/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.7472 - accuracy: 0.3975\n",
            "Epoch 46: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 1.7469 - accuracy: 0.3974 - val_loss: 1.7250 - val_accuracy: 0.4050\n",
            "Epoch 47/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.7487 - accuracy: 0.3960\n",
            "Epoch 47: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 1.7480 - accuracy: 0.3961 - val_loss: 1.7263 - val_accuracy: 0.4021\n",
            "Epoch 48/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.7419 - accuracy: 0.3971\n",
            "Epoch 48: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7424 - accuracy: 0.3970 - val_loss: 1.7263 - val_accuracy: 0.4045\n",
            "Epoch 49/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.7455 - accuracy: 0.3956\n",
            "Epoch 49: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 1.7456 - accuracy: 0.3956 - val_loss: 1.7198 - val_accuracy: 0.4060\n",
            "Epoch 50/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.7394 - accuracy: 0.3973\n",
            "Epoch 50: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7387 - accuracy: 0.3975 - val_loss: 1.7262 - val_accuracy: 0.4045\n",
            "Epoch 51/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.7466 - accuracy: 0.3956\n",
            "Epoch 51: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7465 - accuracy: 0.3953 - val_loss: 1.7285 - val_accuracy: 0.4030\n",
            "Epoch 52/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.7441 - accuracy: 0.3990\n",
            "Epoch 52: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7429 - accuracy: 0.3991 - val_loss: 1.7318 - val_accuracy: 0.4003\n",
            "Epoch 53/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.7440 - accuracy: 0.3964\n",
            "Epoch 53: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 1.7443 - accuracy: 0.3963 - val_loss: 1.7207 - val_accuracy: 0.4104\n",
            "Epoch 54/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.7424 - accuracy: 0.3972\n",
            "Epoch 54: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7420 - accuracy: 0.3973 - val_loss: 1.7251 - val_accuracy: 0.4077\n",
            "Epoch 55/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.7426 - accuracy: 0.3984\n",
            "Epoch 55: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7422 - accuracy: 0.3986 - val_loss: 1.7260 - val_accuracy: 0.4042\n",
            "Epoch 56/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.7433 - accuracy: 0.3992\n",
            "Epoch 56: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7441 - accuracy: 0.3990 - val_loss: 1.7350 - val_accuracy: 0.3962\n",
            "Epoch 57/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.7439 - accuracy: 0.3994\n",
            "Epoch 57: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7461 - accuracy: 0.3989 - val_loss: 1.7234 - val_accuracy: 0.4046\n",
            "Epoch 58/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.7429 - accuracy: 0.3982\n",
            "Epoch 58: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 1.7432 - accuracy: 0.3981 - val_loss: 1.7224 - val_accuracy: 0.4023\n",
            "Epoch 59/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.7427 - accuracy: 0.3956\n",
            "Epoch 59: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7428 - accuracy: 0.3957 - val_loss: 1.7193 - val_accuracy: 0.4087\n",
            "Epoch 60/500\n",
            "924/938 [============================>.] - ETA: 0s - loss: 1.7386 - accuracy: 0.3966\n",
            "Epoch 60: val_loss did not improve from 1.71832\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7406 - accuracy: 0.3962 - val_loss: 1.7205 - val_accuracy: 0.4058\n",
            "Epoch 61/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.7435 - accuracy: 0.4007\n",
            "Epoch 61: val_loss improved from 1.71832 to 1.71690, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7437 - accuracy: 0.4007 - val_loss: 1.7169 - val_accuracy: 0.4080\n",
            "Epoch 62/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.7424 - accuracy: 0.3972\n",
            "Epoch 62: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7424 - accuracy: 0.3972 - val_loss: 1.7229 - val_accuracy: 0.4054\n",
            "Epoch 63/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.7434 - accuracy: 0.3962\n",
            "Epoch 63: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7439 - accuracy: 0.3956 - val_loss: 1.7231 - val_accuracy: 0.4052\n",
            "Epoch 64/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.7407 - accuracy: 0.4001\n",
            "Epoch 64: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7424 - accuracy: 0.3997 - val_loss: 1.7223 - val_accuracy: 0.4060\n",
            "Epoch 65/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.7418 - accuracy: 0.3951\n",
            "Epoch 65: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7408 - accuracy: 0.3955 - val_loss: 1.7230 - val_accuracy: 0.4075\n",
            "Epoch 66/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.7406 - accuracy: 0.3990\n",
            "Epoch 66: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 1.7406 - accuracy: 0.3989 - val_loss: 1.7215 - val_accuracy: 0.4065\n",
            "Epoch 67/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.7384 - accuracy: 0.3979\n",
            "Epoch 67: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7391 - accuracy: 0.3980 - val_loss: 1.7234 - val_accuracy: 0.4075\n",
            "Epoch 68/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.7381 - accuracy: 0.4012\n",
            "Epoch 68: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7378 - accuracy: 0.4013 - val_loss: 1.7317 - val_accuracy: 0.4049\n",
            "Epoch 69/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.7408 - accuracy: 0.3974\n",
            "Epoch 69: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7404 - accuracy: 0.3974 - val_loss: 1.7272 - val_accuracy: 0.4045\n",
            "Epoch 70/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.7435 - accuracy: 0.3986\n",
            "Epoch 70: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7427 - accuracy: 0.3989 - val_loss: 1.7275 - val_accuracy: 0.4051\n",
            "Epoch 71/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.7420 - accuracy: 0.3975\n",
            "Epoch 71: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7426 - accuracy: 0.3974 - val_loss: 1.7177 - val_accuracy: 0.4079\n",
            "Epoch 72/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.7408 - accuracy: 0.3973\n",
            "Epoch 72: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7407 - accuracy: 0.3975 - val_loss: 1.7222 - val_accuracy: 0.4038\n",
            "Epoch 73/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.7408 - accuracy: 0.3980\n",
            "Epoch 73: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7406 - accuracy: 0.3980 - val_loss: 1.7226 - val_accuracy: 0.4052\n",
            "Epoch 74/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.7400 - accuracy: 0.3957\n",
            "Epoch 74: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7398 - accuracy: 0.3958 - val_loss: 1.7203 - val_accuracy: 0.4077\n",
            "Epoch 75/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.7380 - accuracy: 0.3999\n",
            "Epoch 75: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7380 - accuracy: 0.3999 - val_loss: 1.7216 - val_accuracy: 0.4021\n",
            "Epoch 76/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.7401 - accuracy: 0.4002\n",
            "Epoch 76: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7401 - accuracy: 0.4001 - val_loss: 1.7236 - val_accuracy: 0.4030\n",
            "Epoch 77/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.7426 - accuracy: 0.3958\n",
            "Epoch 77: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7428 - accuracy: 0.3957 - val_loss: 1.7232 - val_accuracy: 0.4045\n",
            "Epoch 78/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.7419 - accuracy: 0.3976\n",
            "Epoch 78: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7419 - accuracy: 0.3977 - val_loss: 1.7181 - val_accuracy: 0.4063\n",
            "Epoch 79/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.7458 - accuracy: 0.3961\n",
            "Epoch 79: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7457 - accuracy: 0.3959 - val_loss: 1.7277 - val_accuracy: 0.4016\n",
            "Epoch 80/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.7443 - accuracy: 0.4000\n",
            "Epoch 80: val_loss did not improve from 1.71690\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7446 - accuracy: 0.4000 - val_loss: 1.7268 - val_accuracy: 0.3991\n",
            "Epoch 81/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.7359 - accuracy: 0.4000\n",
            "Epoch 81: val_loss did not improve from 1.71690\n",
            "Restoring model weights from the end of the best epoch: 61.\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7375 - accuracy: 0.3996 - val_loss: 1.7276 - val_accuracy: 0.4015\n",
            "Epoch 81: early stopping\n",
            "Training Runtime: 394.98 seconds\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.7291 - accuracy: 0.4082\n",
            "Test Loss: 1.7291\n",
            "Test Accuracy: 0.4082\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10  # 10-class problem\n",
        "drop_rate = 0.5\n",
        "# Define model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(32,32,3)))\n",
        "model.add(layers.Dropout(drop_rate))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create an SGD optimizer instance with the desired learning rate\n",
        "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# Train the model with callbacks\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(X_train_norm, y_train, epochs=500, batch_size=32, validation_data=(X_val_norm, y_val), callbacks=[checkpoint, early_stopping])\n",
        "\n",
        "end_time = time.time()\n",
        "# Calculate the training runtime\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training Runtime: {training_time:.2f} seconds\")\n",
        "\n",
        "# Load the best model weights\n",
        "model.load_weights(\"best_model.h5\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_norm, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXQKQ7d1qU7F"
      },
      "source": [
        "## Model 1 (Adding 2 Dense layers)\n",
        "\n",
        "The one-node classifier models seems to have problem with the architecture, do not have enough neurons. Therefore, it should be better to try with a deeper architecture.\n",
        "\n",
        "- Training Runtime: 263.42 seconds\n",
        "- Test Loss: 2.9312\n",
        "- Test Accuracy: 0.5384"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZxkmO93rBSp",
        "outputId": "73f40f9f-6f3d-4196-ac99-95dd0317053f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "927/938 [============================>.] - ETA: 0s - loss: 11.9153 - accuracy: 0.2502\n",
            "Epoch 1: val_loss improved from inf to 11.46510, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 5ms/step - loss: 11.9107 - accuracy: 0.2510 - val_loss: 11.4651 - val_accuracy: 0.3583\n",
            "Epoch 2/50\n",
            " 33/938 [>.............................] - ETA: 2s - loss: 11.5146 - accuracy: 0.3390"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "931/938 [============================>.] - ETA: 0s - loss: 11.3379 - accuracy: 0.3289\n",
            "Epoch 2: val_loss improved from 11.46510 to 11.02216, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 11.3356 - accuracy: 0.3293 - val_loss: 11.0222 - val_accuracy: 0.3876\n",
            "Epoch 3/50\n",
            "930/938 [============================>.] - ETA: 0s - loss: 10.9014 - accuracy: 0.3635\n",
            "Epoch 3: val_loss improved from 11.02216 to 10.62951, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 10.9000 - accuracy: 0.3638 - val_loss: 10.6295 - val_accuracy: 0.4065\n",
            "Epoch 4/50\n",
            "931/938 [============================>.] - ETA: 0s - loss: 10.5153 - accuracy: 0.3825\n",
            "Epoch 4: val_loss improved from 10.62951 to 10.26842, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 10.5141 - accuracy: 0.3827 - val_loss: 10.2684 - val_accuracy: 0.4191\n",
            "Epoch 5/50\n",
            "930/938 [============================>.] - ETA: 0s - loss: 10.1489 - accuracy: 0.4018\n",
            "Epoch 5: val_loss improved from 10.26842 to 9.92175, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 10.1475 - accuracy: 0.4017 - val_loss: 9.9217 - val_accuracy: 0.4318\n",
            "Epoch 6/50\n",
            "934/938 [============================>.] - ETA: 0s - loss: 9.8057 - accuracy: 0.4110\n",
            "Epoch 6: val_loss improved from 9.92175 to 9.59350, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 9.8046 - accuracy: 0.4111 - val_loss: 9.5935 - val_accuracy: 0.4393\n",
            "Epoch 7/50\n",
            "927/938 [============================>.] - ETA: 0s - loss: 9.4814 - accuracy: 0.4222\n",
            "Epoch 7: val_loss improved from 9.59350 to 9.28566, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 9.4795 - accuracy: 0.4222 - val_loss: 9.2857 - val_accuracy: 0.4458\n",
            "Epoch 8/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 9.1651 - accuracy: 0.4330\n",
            "Epoch 8: val_loss improved from 9.28566 to 8.98567, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 9.1650 - accuracy: 0.4330 - val_loss: 8.9857 - val_accuracy: 0.4522\n",
            "Epoch 9/50\n",
            "935/938 [============================>.] - ETA: 0s - loss: 8.8648 - accuracy: 0.4421\n",
            "Epoch 9: val_loss improved from 8.98567 to 8.69949, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 8.8644 - accuracy: 0.4420 - val_loss: 8.6995 - val_accuracy: 0.4532\n",
            "Epoch 10/50\n",
            "924/938 [============================>.] - ETA: 0s - loss: 8.5808 - accuracy: 0.4505\n",
            "Epoch 10: val_loss improved from 8.69949 to 8.42387, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 8.5798 - accuracy: 0.4496 - val_loss: 8.4239 - val_accuracy: 0.4601\n",
            "Epoch 11/50\n",
            "930/938 [============================>.] - ETA: 0s - loss: 8.3047 - accuracy: 0.4573\n",
            "Epoch 11: val_loss improved from 8.42387 to 8.16411, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 8.3038 - accuracy: 0.4571 - val_loss: 8.1641 - val_accuracy: 0.4617\n",
            "Epoch 12/50\n",
            "935/938 [============================>.] - ETA: 0s - loss: 8.0366 - accuracy: 0.4641\n",
            "Epoch 12: val_loss improved from 8.16411 to 7.90328, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 8.0367 - accuracy: 0.4640 - val_loss: 7.9033 - val_accuracy: 0.4691\n",
            "Epoch 13/50\n",
            "933/938 [============================>.] - ETA: 0s - loss: 7.7907 - accuracy: 0.4680\n",
            "Epoch 13: val_loss improved from 7.90328 to 7.66318, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 7.7897 - accuracy: 0.4686 - val_loss: 7.6632 - val_accuracy: 0.4719\n",
            "Epoch 14/50\n",
            "934/938 [============================>.] - ETA: 0s - loss: 7.5359 - accuracy: 0.4772\n",
            "Epoch 14: val_loss improved from 7.66318 to 7.42742, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 7.5356 - accuracy: 0.4772 - val_loss: 7.4274 - val_accuracy: 0.4749\n",
            "Epoch 15/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 7.3069 - accuracy: 0.4837\n",
            "Epoch 15: val_loss improved from 7.42742 to 7.20609, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 7.3068 - accuracy: 0.4838 - val_loss: 7.2061 - val_accuracy: 0.4790\n",
            "Epoch 16/50\n",
            "929/938 [============================>.] - ETA: 0s - loss: 7.0780 - accuracy: 0.4871\n",
            "Epoch 16: val_loss improved from 7.20609 to 6.98667, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 7.0764 - accuracy: 0.4874 - val_loss: 6.9867 - val_accuracy: 0.4833\n",
            "Epoch 17/50\n",
            "924/938 [============================>.] - ETA: 0s - loss: 6.8606 - accuracy: 0.4929\n",
            "Epoch 17: val_loss improved from 6.98667 to 6.77832, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 6.8594 - accuracy: 0.4928 - val_loss: 6.7783 - val_accuracy: 0.4852\n",
            "Epoch 18/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 6.6500 - accuracy: 0.4962\n",
            "Epoch 18: val_loss improved from 6.77832 to 6.57786, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 6.6495 - accuracy: 0.4962 - val_loss: 6.5779 - val_accuracy: 0.4880\n",
            "Epoch 19/50\n",
            "932/938 [============================>.] - ETA: 0s - loss: 6.4467 - accuracy: 0.5027\n",
            "Epoch 19: val_loss improved from 6.57786 to 6.38314, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 6.4464 - accuracy: 0.5028 - val_loss: 6.3831 - val_accuracy: 0.4911\n",
            "Epoch 20/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 6.2553 - accuracy: 0.5096\n",
            "Epoch 20: val_loss improved from 6.38314 to 6.19821, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 6.2551 - accuracy: 0.5096 - val_loss: 6.1982 - val_accuracy: 0.4924\n",
            "Epoch 21/50\n",
            "935/938 [============================>.] - ETA: 0s - loss: 6.0659 - accuracy: 0.5103\n",
            "Epoch 21: val_loss improved from 6.19821 to 6.01931, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 6.0664 - accuracy: 0.5101 - val_loss: 6.0193 - val_accuracy: 0.4986\n",
            "Epoch 22/50\n",
            "928/938 [============================>.] - ETA: 0s - loss: 5.8887 - accuracy: 0.5122\n",
            "Epoch 22: val_loss improved from 6.01931 to 5.84880, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 5.8873 - accuracy: 0.5124 - val_loss: 5.8488 - val_accuracy: 0.4957\n",
            "Epoch 23/50\n",
            "930/938 [============================>.] - ETA: 0s - loss: 5.7146 - accuracy: 0.5196\n",
            "Epoch 23: val_loss improved from 5.84880 to 5.68161, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 5.7150 - accuracy: 0.5195 - val_loss: 5.6816 - val_accuracy: 0.5009\n",
            "Epoch 24/50\n",
            "938/938 [==============================] - ETA: 0s - loss: 5.5519 - accuracy: 0.5166\n",
            "Epoch 24: val_loss improved from 5.68161 to 5.52343, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 5.5519 - accuracy: 0.5166 - val_loss: 5.5234 - val_accuracy: 0.5026\n",
            "Epoch 25/50\n",
            "924/938 [============================>.] - ETA: 0s - loss: 5.3854 - accuracy: 0.5293\n",
            "Epoch 25: val_loss improved from 5.52343 to 5.36975, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 5.3847 - accuracy: 0.5288 - val_loss: 5.3697 - val_accuracy: 0.5056\n",
            "Epoch 26/50\n",
            "927/938 [============================>.] - ETA: 0s - loss: 5.2261 - accuracy: 0.5324\n",
            "Epoch 26: val_loss improved from 5.36975 to 5.22566, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.2248 - accuracy: 0.5323 - val_loss: 5.2257 - val_accuracy: 0.5043\n",
            "Epoch 27/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 5.0772 - accuracy: 0.5369\n",
            "Epoch 27: val_loss improved from 5.22566 to 5.08033, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 5.0771 - accuracy: 0.5369 - val_loss: 5.0803 - val_accuracy: 0.5094\n",
            "Epoch 28/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 4.9330 - accuracy: 0.5426\n",
            "Epoch 28: val_loss improved from 5.08033 to 4.94477, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 4.9328 - accuracy: 0.5426 - val_loss: 4.9448 - val_accuracy: 0.5095\n",
            "Epoch 29/50\n",
            "925/938 [============================>.] - ETA: 0s - loss: 4.7947 - accuracy: 0.5437\n",
            "Epoch 29: val_loss improved from 4.94477 to 4.81135, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 4.7947 - accuracy: 0.5437 - val_loss: 4.8113 - val_accuracy: 0.5147\n",
            "Epoch 30/50\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.6597 - accuracy: 0.5486\n",
            "Epoch 30: val_loss improved from 4.81135 to 4.69188, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 4.6597 - accuracy: 0.5486 - val_loss: 4.6919 - val_accuracy: 0.5129\n",
            "Epoch 31/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 4.5317 - accuracy: 0.5518\n",
            "Epoch 31: val_loss improved from 4.69188 to 4.56555, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 4.5316 - accuracy: 0.5518 - val_loss: 4.5655 - val_accuracy: 0.5163\n",
            "Epoch 32/50\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.4122 - accuracy: 0.5513\n",
            "Epoch 32: val_loss improved from 4.56555 to 4.44743, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 4.4122 - accuracy: 0.5513 - val_loss: 4.4474 - val_accuracy: 0.5146\n",
            "Epoch 33/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 4.2835 - accuracy: 0.5583\n",
            "Epoch 33: val_loss improved from 4.44743 to 4.33272, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 4.2834 - accuracy: 0.5583 - val_loss: 4.3327 - val_accuracy: 0.5197\n",
            "Epoch 34/50\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.1648 - accuracy: 0.5630\n",
            "Epoch 34: val_loss improved from 4.33272 to 4.22743, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 4.1648 - accuracy: 0.5630 - val_loss: 4.2274 - val_accuracy: 0.5197\n",
            "Epoch 35/50\n",
            "927/938 [============================>.] - ETA: 0s - loss: 4.0570 - accuracy: 0.5661\n",
            "Epoch 35: val_loss improved from 4.22743 to 4.12366, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.0564 - accuracy: 0.5664 - val_loss: 4.1237 - val_accuracy: 0.5209\n",
            "Epoch 36/50\n",
            "929/938 [============================>.] - ETA: 0s - loss: 3.9558 - accuracy: 0.5623\n",
            "Epoch 36: val_loss improved from 4.12366 to 4.02185, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 3.9554 - accuracy: 0.5622 - val_loss: 4.0218 - val_accuracy: 0.5228\n",
            "Epoch 37/50\n",
            "927/938 [============================>.] - ETA: 0s - loss: 3.8490 - accuracy: 0.5695\n",
            "Epoch 37: val_loss improved from 4.02185 to 3.92415, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 3.8479 - accuracy: 0.5700 - val_loss: 3.9241 - val_accuracy: 0.5216\n",
            "Epoch 38/50\n",
            "933/938 [============================>.] - ETA: 0s - loss: 3.7476 - accuracy: 0.5718\n",
            "Epoch 38: val_loss improved from 3.92415 to 3.83290, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 3.7478 - accuracy: 0.5718 - val_loss: 3.8329 - val_accuracy: 0.5256\n",
            "Epoch 39/50\n",
            "925/938 [============================>.] - ETA: 0s - loss: 3.6505 - accuracy: 0.5754\n",
            "Epoch 39: val_loss improved from 3.83290 to 3.74435, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 3.6491 - accuracy: 0.5756 - val_loss: 3.7443 - val_accuracy: 0.5202\n",
            "Epoch 40/50\n",
            "930/938 [============================>.] - ETA: 0s - loss: 3.5578 - accuracy: 0.5797\n",
            "Epoch 40: val_loss improved from 3.74435 to 3.65705, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 3.5569 - accuracy: 0.5795 - val_loss: 3.6570 - val_accuracy: 0.5217\n",
            "Epoch 41/50\n",
            "927/938 [============================>.] - ETA: 0s - loss: 3.4701 - accuracy: 0.5811\n",
            "Epoch 41: val_loss improved from 3.65705 to 3.57184, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 3.4699 - accuracy: 0.5813 - val_loss: 3.5718 - val_accuracy: 0.5289\n",
            "Epoch 42/50\n",
            "933/938 [============================>.] - ETA: 0s - loss: 3.3817 - accuracy: 0.5843\n",
            "Epoch 42: val_loss improved from 3.57184 to 3.49841, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 3.3811 - accuracy: 0.5845 - val_loss: 3.4984 - val_accuracy: 0.5275\n",
            "Epoch 43/50\n",
            "932/938 [============================>.] - ETA: 0s - loss: 3.2988 - accuracy: 0.5882\n",
            "Epoch 43: val_loss improved from 3.49841 to 3.41189, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 3.2983 - accuracy: 0.5882 - val_loss: 3.4119 - val_accuracy: 0.5296\n",
            "Epoch 44/50\n",
            "931/938 [============================>.] - ETA: 0s - loss: 3.2115 - accuracy: 0.5931\n",
            "Epoch 44: val_loss improved from 3.41189 to 3.34103, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.2113 - accuracy: 0.5934 - val_loss: 3.3410 - val_accuracy: 0.5296\n",
            "Epoch 45/50\n",
            "931/938 [============================>.] - ETA: 0s - loss: 3.1376 - accuracy: 0.5944\n",
            "Epoch 45: val_loss improved from 3.34103 to 3.27247, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 3.1377 - accuracy: 0.5942 - val_loss: 3.2725 - val_accuracy: 0.5286\n",
            "Epoch 46/50\n",
            "930/938 [============================>.] - ETA: 0s - loss: 3.0626 - accuracy: 0.5978\n",
            "Epoch 46: val_loss improved from 3.27247 to 3.19874, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 3.0619 - accuracy: 0.5979 - val_loss: 3.1987 - val_accuracy: 0.5307\n",
            "Epoch 47/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.9913 - accuracy: 0.6006\n",
            "Epoch 47: val_loss improved from 3.19874 to 3.13652, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.9916 - accuracy: 0.6005 - val_loss: 3.1365 - val_accuracy: 0.5309\n",
            "Epoch 48/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 2.9205 - accuracy: 0.6012\n",
            "Epoch 48: val_loss improved from 3.13652 to 3.07665, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 2.9202 - accuracy: 0.6014 - val_loss: 3.0766 - val_accuracy: 0.5299\n",
            "Epoch 49/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.8516 - accuracy: 0.6085\n",
            "Epoch 49: val_loss improved from 3.07665 to 3.00703, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 2.8516 - accuracy: 0.6085 - val_loss: 3.0070 - val_accuracy: 0.5357\n",
            "Epoch 50/50\n",
            "927/938 [============================>.] - ETA: 0s - loss: 2.7904 - accuracy: 0.6084\n",
            "Epoch 50: val_loss improved from 3.00703 to 2.94642, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.7898 - accuracy: 0.6083 - val_loss: 2.9464 - val_accuracy: 0.5379\n",
            "Training Runtime: 263.42 seconds\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.9312 - accuracy: 0.5384\n",
            "Test Loss: 2.9312\n",
            "Test Accuracy: 0.5384\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10  # 10-class problem\n",
        "drop_rate = 0.5\n",
        "# Define model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(32,32,3)))\n",
        "model.add(layers.Dense(1000, kernel_initializer='lecun_normal', kernel_regularizer='l2', activation='relu'))\n",
        "model.add(layers.Dropout(drop_rate))\n",
        "model.add(layers.Dense(100, kernel_initializer='lecun_normal', activation='relu'))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create an SGD optimizer instance with the desired learning rate\n",
        "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# Train the model with callbacks\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(X_train_norm, y_train, epochs=50, batch_size=32, validation_data=(X_val_norm, y_val), callbacks=[checkpoint, early_stopping])\n",
        "\n",
        "end_time = time.time()\n",
        "# Calculate the training runtime\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training Runtime: {training_time:.2f} seconds\")\n",
        "\n",
        "# Load the best model weights\n",
        "model.load_weights(\"best_model.h5\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_norm, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8fvc4SG5h2b"
      },
      "source": [
        "## Model 2- Test architecture by adding one layer and dropout regulization\n",
        "\n",
        "Continue testing the architecture because as the same reason as model 1\n",
        "\n",
        "- Training Runtime: 853.75 seconds\n",
        "\n",
        "- Test Loss: 1.6158\n",
        "\n",
        "- Test Accuracy: 0.5649\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-VwOpjssadS",
        "outputId": "ab7612ed-e86c-461c-e328-880314d29457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 21.8620 - accuracy: 0.1862\n",
            "Epoch 1: val_loss improved from inf to 21.25554, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 6ms/step - loss: 21.8591 - accuracy: 0.1867 - val_loss: 21.2555 - val_accuracy: 0.2972\n",
            "Epoch 2/500\n",
            "924/938 [============================>.] - ETA: 0s - loss: 20.9453 - accuracy: 0.2582\n",
            "Epoch 2: val_loss improved from 21.25554 to 20.44403, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 20.9400 - accuracy: 0.2581 - val_loss: 20.4440 - val_accuracy: 0.3340\n",
            "Epoch 3/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 20.1643 - accuracy: 0.2960\n",
            "Epoch 3: val_loss improved from 20.44403 to 19.69648, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 20.1619 - accuracy: 0.2960 - val_loss: 19.6965 - val_accuracy: 0.3594\n",
            "Epoch 4/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 19.4392 - accuracy: 0.3157\n",
            "Epoch 4: val_loss improved from 19.69648 to 18.99188, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19.4353 - accuracy: 0.3159 - val_loss: 18.9919 - val_accuracy: 0.3753\n",
            "Epoch 5/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 18.7518 - accuracy: 0.3356\n",
            "Epoch 5: val_loss improved from 18.99188 to 18.32179, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 18.7487 - accuracy: 0.3361 - val_loss: 18.3218 - val_accuracy: 0.3860\n",
            "Epoch 6/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 18.0942 - accuracy: 0.3480\n",
            "Epoch 6: val_loss improved from 18.32179 to 17.68627, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18.0940 - accuracy: 0.3479 - val_loss: 17.6863 - val_accuracy: 0.3900\n",
            "Epoch 7/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 17.4690 - accuracy: 0.3580\n",
            "Epoch 7: val_loss improved from 17.68627 to 17.07392, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 17.4675 - accuracy: 0.3582 - val_loss: 17.0739 - val_accuracy: 0.3980\n",
            "Epoch 8/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 16.8665 - accuracy: 0.3660\n",
            "Epoch 8: val_loss improved from 17.07392 to 16.48874, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 16.8659 - accuracy: 0.3659 - val_loss: 16.4887 - val_accuracy: 0.4062\n",
            "Epoch 9/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 16.2868 - accuracy: 0.3756\n",
            "Epoch 9: val_loss improved from 16.48874 to 15.93013, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16.2856 - accuracy: 0.3759 - val_loss: 15.9301 - val_accuracy: 0.4131\n",
            "Epoch 10/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 15.7357 - accuracy: 0.3810\n",
            "Epoch 10: val_loss improved from 15.93013 to 15.38718, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15.7356 - accuracy: 0.3810 - val_loss: 15.3872 - val_accuracy: 0.4171\n",
            "Epoch 11/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 15.2049 - accuracy: 0.3921\n",
            "Epoch 11: val_loss improved from 15.38718 to 14.86880, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15.2014 - accuracy: 0.3924 - val_loss: 14.8688 - val_accuracy: 0.4220\n",
            "Epoch 12/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 14.6927 - accuracy: 0.3940\n",
            "Epoch 12: val_loss improved from 14.86880 to 14.36911, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14.6925 - accuracy: 0.3940 - val_loss: 14.3691 - val_accuracy: 0.4289\n",
            "Epoch 13/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 14.1957 - accuracy: 0.4036\n",
            "Epoch 13: val_loss improved from 14.36911 to 13.89088, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 14.1938 - accuracy: 0.4039 - val_loss: 13.8909 - val_accuracy: 0.4293\n",
            "Epoch 14/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 13.7276 - accuracy: 0.4027\n",
            "Epoch 14: val_loss improved from 13.89088 to 13.43194, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13.7278 - accuracy: 0.4026 - val_loss: 13.4319 - val_accuracy: 0.4314\n",
            "Epoch 15/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 13.2712 - accuracy: 0.4121\n",
            "Epoch 15: val_loss improved from 13.43194 to 12.98368, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13.2685 - accuracy: 0.4124 - val_loss: 12.9837 - val_accuracy: 0.4376\n",
            "Epoch 16/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 12.8377 - accuracy: 0.4143\n",
            "Epoch 16: val_loss improved from 12.98368 to 12.55635, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 12.8340 - accuracy: 0.4147 - val_loss: 12.5564 - val_accuracy: 0.4425\n",
            "Epoch 17/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 12.4074 - accuracy: 0.4235\n",
            "Epoch 17: val_loss improved from 12.55635 to 12.14396, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12.4074 - accuracy: 0.4235 - val_loss: 12.1440 - val_accuracy: 0.4471\n",
            "Epoch 18/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 12.0026 - accuracy: 0.4302\n",
            "Epoch 18: val_loss improved from 12.14396 to 11.75141, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 12.0015 - accuracy: 0.4302 - val_loss: 11.7514 - val_accuracy: 0.4485\n",
            "Epoch 19/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 11.6126 - accuracy: 0.4317\n",
            "Epoch 19: val_loss improved from 11.75141 to 11.36834, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 11.6126 - accuracy: 0.4317 - val_loss: 11.3683 - val_accuracy: 0.4489\n",
            "Epoch 20/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 11.2318 - accuracy: 0.4355\n",
            "Epoch 20: val_loss improved from 11.36834 to 11.00295, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 11.2313 - accuracy: 0.4355 - val_loss: 11.0030 - val_accuracy: 0.4518\n",
            "Epoch 21/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 10.8757 - accuracy: 0.4362\n",
            "Epoch 21: val_loss improved from 11.00295 to 10.64626, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 10.8729 - accuracy: 0.4363 - val_loss: 10.6463 - val_accuracy: 0.4548\n",
            "Epoch 22/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 10.5229 - accuracy: 0.4436\n",
            "Epoch 22: val_loss improved from 10.64626 to 10.30765, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 10.5220 - accuracy: 0.4436 - val_loss: 10.3076 - val_accuracy: 0.4597\n",
            "Epoch 23/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 10.1887 - accuracy: 0.4445\n",
            "Epoch 23: val_loss improved from 10.30765 to 9.98216, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 10.1885 - accuracy: 0.4444 - val_loss: 9.9822 - val_accuracy: 0.4615\n",
            "Epoch 24/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 9.8632 - accuracy: 0.4502\n",
            "Epoch 24: val_loss improved from 9.98216 to 9.66457, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 9.8627 - accuracy: 0.4502 - val_loss: 9.6646 - val_accuracy: 0.4658\n",
            "Epoch 25/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 9.5496 - accuracy: 0.4577\n",
            "Epoch 25: val_loss improved from 9.66457 to 9.35819, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 9.5490 - accuracy: 0.4574 - val_loss: 9.3582 - val_accuracy: 0.4695\n",
            "Epoch 26/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 9.2442 - accuracy: 0.4566\n",
            "Epoch 26: val_loss improved from 9.35819 to 9.06894, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 9.2426 - accuracy: 0.4564 - val_loss: 9.0689 - val_accuracy: 0.4700\n",
            "Epoch 27/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 8.9526 - accuracy: 0.4628\n",
            "Epoch 27: val_loss improved from 9.06894 to 8.78444, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 8.9525 - accuracy: 0.4629 - val_loss: 8.7844 - val_accuracy: 0.4734\n",
            "Epoch 28/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 8.6777 - accuracy: 0.4626\n",
            "Epoch 28: val_loss improved from 8.78444 to 8.51760, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 8.6777 - accuracy: 0.4626 - val_loss: 8.5176 - val_accuracy: 0.4703\n",
            "Epoch 29/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 8.4043 - accuracy: 0.4747\n",
            "Epoch 29: val_loss improved from 8.51760 to 8.25242, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 8.4027 - accuracy: 0.4748 - val_loss: 8.2524 - val_accuracy: 0.4744\n",
            "Epoch 30/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 8.1472 - accuracy: 0.4729\n",
            "Epoch 30: val_loss improved from 8.25242 to 8.00335, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 8.1471 - accuracy: 0.4729 - val_loss: 8.0033 - val_accuracy: 0.4753\n",
            "Epoch 31/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 7.8960 - accuracy: 0.4795\n",
            "Epoch 31: val_loss improved from 8.00335 to 7.75748, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 7.8947 - accuracy: 0.4796 - val_loss: 7.7575 - val_accuracy: 0.4823\n",
            "Epoch 32/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 7.6548 - accuracy: 0.4799\n",
            "Epoch 32: val_loss improved from 7.75748 to 7.52438, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 7.6537 - accuracy: 0.4803 - val_loss: 7.5244 - val_accuracy: 0.4803\n",
            "Epoch 33/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 7.4274 - accuracy: 0.4798\n",
            "Epoch 33: val_loss improved from 7.52438 to 7.29715, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 7.4259 - accuracy: 0.4802 - val_loss: 7.2972 - val_accuracy: 0.4862\n",
            "Epoch 34/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 7.1942 - accuracy: 0.4861\n",
            "Epoch 34: val_loss improved from 7.29715 to 7.08095, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 7.1942 - accuracy: 0.4860 - val_loss: 7.0810 - val_accuracy: 0.4873\n",
            "Epoch 35/500\n",
            "924/938 [============================>.] - ETA: 0s - loss: 6.9802 - accuracy: 0.4915\n",
            "Epoch 35: val_loss improved from 7.08095 to 6.87523, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 6.9795 - accuracy: 0.4915 - val_loss: 6.8752 - val_accuracy: 0.4885\n",
            "Epoch 36/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 6.7709 - accuracy: 0.4926\n",
            "Epoch 36: val_loss improved from 6.87523 to 6.67186, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.7709 - accuracy: 0.4926 - val_loss: 6.6719 - val_accuracy: 0.4913\n",
            "Epoch 37/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 6.5715 - accuracy: 0.4966\n",
            "Epoch 37: val_loss improved from 6.67186 to 6.48010, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 6.5707 - accuracy: 0.4964 - val_loss: 6.4801 - val_accuracy: 0.4915\n",
            "Epoch 38/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 6.3744 - accuracy: 0.5023\n",
            "Epoch 38: val_loss improved from 6.48010 to 6.29378, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.3746 - accuracy: 0.5021 - val_loss: 6.2938 - val_accuracy: 0.4922\n",
            "Epoch 39/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 6.1953 - accuracy: 0.5021\n",
            "Epoch 39: val_loss improved from 6.29378 to 6.11614, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.1950 - accuracy: 0.5022 - val_loss: 6.1161 - val_accuracy: 0.4967\n",
            "Epoch 40/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 6.0146 - accuracy: 0.5045\n",
            "Epoch 40: val_loss improved from 6.11614 to 5.93932, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.0137 - accuracy: 0.5046 - val_loss: 5.9393 - val_accuracy: 0.4983\n",
            "Epoch 41/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 5.8411 - accuracy: 0.5096\n",
            "Epoch 41: val_loss improved from 5.93932 to 5.77241, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.8404 - accuracy: 0.5098 - val_loss: 5.7724 - val_accuracy: 0.4992\n",
            "Epoch 42/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 5.6749 - accuracy: 0.5112\n",
            "Epoch 42: val_loss improved from 5.77241 to 5.61264, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 5.6747 - accuracy: 0.5111 - val_loss: 5.6126 - val_accuracy: 0.4996\n",
            "Epoch 43/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 5.5120 - accuracy: 0.5150\n",
            "Epoch 43: val_loss improved from 5.61264 to 5.45747, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.5121 - accuracy: 0.5147 - val_loss: 5.4575 - val_accuracy: 0.5025\n",
            "Epoch 44/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 5.3613 - accuracy: 0.5160\n",
            "Epoch 44: val_loss improved from 5.45747 to 5.31057, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.3607 - accuracy: 0.5161 - val_loss: 5.3106 - val_accuracy: 0.5037\n",
            "Epoch 45/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 5.2065 - accuracy: 0.5205\n",
            "Epoch 45: val_loss improved from 5.31057 to 5.16478, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 5.2059 - accuracy: 0.5208 - val_loss: 5.1648 - val_accuracy: 0.5060\n",
            "Epoch 46/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 5.0651 - accuracy: 0.5197\n",
            "Epoch 46: val_loss improved from 5.16478 to 5.03433, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.0654 - accuracy: 0.5196 - val_loss: 5.0343 - val_accuracy: 0.5075\n",
            "Epoch 47/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 4.9241 - accuracy: 0.5216\n",
            "Epoch 47: val_loss improved from 5.03433 to 4.89828, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 4.9241 - accuracy: 0.5215 - val_loss: 4.8983 - val_accuracy: 0.5076\n",
            "Epoch 48/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 4.7902 - accuracy: 0.5276\n",
            "Epoch 48: val_loss improved from 4.89828 to 4.77078, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 4.7890 - accuracy: 0.5281 - val_loss: 4.7708 - val_accuracy: 0.5107\n",
            "Epoch 49/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 4.6593 - accuracy: 0.5329\n",
            "Epoch 49: val_loss improved from 4.77078 to 4.64535, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.6589 - accuracy: 0.5331 - val_loss: 4.6454 - val_accuracy: 0.5110\n",
            "Epoch 50/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.5375 - accuracy: 0.5335\n",
            "Epoch 50: val_loss improved from 4.64535 to 4.53106, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 4.5375 - accuracy: 0.5335 - val_loss: 4.5311 - val_accuracy: 0.5116\n",
            "Epoch 51/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.4160 - accuracy: 0.5352\n",
            "Epoch 51: val_loss improved from 4.53106 to 4.41836, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 4.4160 - accuracy: 0.5352 - val_loss: 4.4184 - val_accuracy: 0.5140\n",
            "Epoch 52/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 4.3006 - accuracy: 0.5366\n",
            "Epoch 52: val_loss improved from 4.41836 to 4.30709, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.3000 - accuracy: 0.5363 - val_loss: 4.3071 - val_accuracy: 0.5104\n",
            "Epoch 53/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.1871 - accuracy: 0.5424\n",
            "Epoch 53: val_loss improved from 4.30709 to 4.19947, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 4.1871 - accuracy: 0.5424 - val_loss: 4.1995 - val_accuracy: 0.5138\n",
            "Epoch 54/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 4.0793 - accuracy: 0.5481\n",
            "Epoch 54: val_loss improved from 4.19947 to 4.09388, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 4.0792 - accuracy: 0.5482 - val_loss: 4.0939 - val_accuracy: 0.5197\n",
            "Epoch 55/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 3.9708 - accuracy: 0.5488\n",
            "Epoch 55: val_loss improved from 4.09388 to 4.00019, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.9709 - accuracy: 0.5487 - val_loss: 4.0002 - val_accuracy: 0.5169\n",
            "Epoch 56/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 3.8659 - accuracy: 0.5535\n",
            "Epoch 56: val_loss improved from 4.00019 to 3.90284, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 3.8659 - accuracy: 0.5535 - val_loss: 3.9028 - val_accuracy: 0.5193\n",
            "Epoch 57/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 3.7771 - accuracy: 0.5533\n",
            "Epoch 57: val_loss improved from 3.90284 to 3.81602, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.7771 - accuracy: 0.5533 - val_loss: 3.8160 - val_accuracy: 0.5240\n",
            "Epoch 58/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 3.6820 - accuracy: 0.5539\n",
            "Epoch 58: val_loss improved from 3.81602 to 3.72714, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 3.6821 - accuracy: 0.5539 - val_loss: 3.7271 - val_accuracy: 0.5215\n",
            "Epoch 59/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 3.5917 - accuracy: 0.5559\n",
            "Epoch 59: val_loss improved from 3.72714 to 3.64393, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 3.5917 - accuracy: 0.5559 - val_loss: 3.6439 - val_accuracy: 0.5228\n",
            "Epoch 60/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 3.5033 - accuracy: 0.5608\n",
            "Epoch 60: val_loss improved from 3.64393 to 3.55855, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.5034 - accuracy: 0.5603 - val_loss: 3.5585 - val_accuracy: 0.5254\n",
            "Epoch 61/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 3.4196 - accuracy: 0.5640\n",
            "Epoch 61: val_loss improved from 3.55855 to 3.48100, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 3.4189 - accuracy: 0.5640 - val_loss: 3.4810 - val_accuracy: 0.5259\n",
            "Epoch 62/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 3.3408 - accuracy: 0.5648\n",
            "Epoch 62: val_loss improved from 3.48100 to 3.40484, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.3408 - accuracy: 0.5648 - val_loss: 3.4048 - val_accuracy: 0.5275\n",
            "Epoch 63/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 3.2637 - accuracy: 0.5703\n",
            "Epoch 63: val_loss improved from 3.40484 to 3.33758, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.2636 - accuracy: 0.5705 - val_loss: 3.3376 - val_accuracy: 0.5286\n",
            "Epoch 64/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 3.1915 - accuracy: 0.5670\n",
            "Epoch 64: val_loss improved from 3.33758 to 3.26848, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 3.1914 - accuracy: 0.5671 - val_loss: 3.2685 - val_accuracy: 0.5240\n",
            "Epoch 65/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 3.1181 - accuracy: 0.5764\n",
            "Epoch 65: val_loss improved from 3.26848 to 3.20121, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.1180 - accuracy: 0.5762 - val_loss: 3.2012 - val_accuracy: 0.5260\n",
            "Epoch 66/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 3.0463 - accuracy: 0.5744\n",
            "Epoch 66: val_loss improved from 3.20121 to 3.13758, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 3.0463 - accuracy: 0.5744 - val_loss: 3.1376 - val_accuracy: 0.5297\n",
            "Epoch 67/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 2.9805 - accuracy: 0.5753\n",
            "Epoch 67: val_loss improved from 3.13758 to 3.07230, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 2.9801 - accuracy: 0.5756 - val_loss: 3.0723 - val_accuracy: 0.5319\n",
            "Epoch 68/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 2.9095 - accuracy: 0.5808\n",
            "Epoch 68: val_loss improved from 3.07230 to 3.01224, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.9095 - accuracy: 0.5808 - val_loss: 3.0122 - val_accuracy: 0.5359\n",
            "Epoch 69/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 2.8481 - accuracy: 0.5842\n",
            "Epoch 69: val_loss improved from 3.01224 to 2.95654, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 2.8486 - accuracy: 0.5840 - val_loss: 2.9565 - val_accuracy: 0.5333\n",
            "Epoch 70/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 2.7889 - accuracy: 0.5839\n",
            "Epoch 70: val_loss improved from 2.95654 to 2.90760, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 2.7885 - accuracy: 0.5841 - val_loss: 2.9076 - val_accuracy: 0.5323\n",
            "Epoch 71/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 2.7273 - accuracy: 0.5875\n",
            "Epoch 71: val_loss improved from 2.90760 to 2.84670, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.7273 - accuracy: 0.5875 - val_loss: 2.8467 - val_accuracy: 0.5351\n",
            "Epoch 72/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 2.6747 - accuracy: 0.5868\n",
            "Epoch 72: val_loss improved from 2.84670 to 2.80023, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 2.6746 - accuracy: 0.5869 - val_loss: 2.8002 - val_accuracy: 0.5309\n",
            "Epoch 73/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 2.6167 - accuracy: 0.5934\n",
            "Epoch 73: val_loss improved from 2.80023 to 2.75044, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.6157 - accuracy: 0.5937 - val_loss: 2.7504 - val_accuracy: 0.5371\n",
            "Epoch 74/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 2.5680 - accuracy: 0.5925\n",
            "Epoch 74: val_loss improved from 2.75044 to 2.70385, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.5675 - accuracy: 0.5926 - val_loss: 2.7039 - val_accuracy: 0.5359\n",
            "Epoch 75/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.5121 - accuracy: 0.5989\n",
            "Epoch 75: val_loss improved from 2.70385 to 2.67199, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 2.5124 - accuracy: 0.5987 - val_loss: 2.6720 - val_accuracy: 0.5342\n",
            "Epoch 76/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 2.4646 - accuracy: 0.6009\n",
            "Epoch 76: val_loss improved from 2.67199 to 2.61720, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.4639 - accuracy: 0.6011 - val_loss: 2.6172 - val_accuracy: 0.5357\n",
            "Epoch 77/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 2.4176 - accuracy: 0.6000\n",
            "Epoch 77: val_loss improved from 2.61720 to 2.57906, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 2.4178 - accuracy: 0.5999 - val_loss: 2.5791 - val_accuracy: 0.5356\n",
            "Epoch 78/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.3731 - accuracy: 0.6002\n",
            "Epoch 78: val_loss improved from 2.57906 to 2.53680, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 2.3731 - accuracy: 0.5998 - val_loss: 2.5368 - val_accuracy: 0.5350\n",
            "Epoch 79/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 2.3295 - accuracy: 0.6032\n",
            "Epoch 79: val_loss improved from 2.53680 to 2.49234, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.3295 - accuracy: 0.6034 - val_loss: 2.4923 - val_accuracy: 0.5391\n",
            "Epoch 80/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 2.2850 - accuracy: 0.6074\n",
            "Epoch 80: val_loss improved from 2.49234 to 2.46127, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 2.2845 - accuracy: 0.6075 - val_loss: 2.4613 - val_accuracy: 0.5368\n",
            "Epoch 81/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 2.2427 - accuracy: 0.6075\n",
            "Epoch 81: val_loss improved from 2.46127 to 2.41709, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 2.2438 - accuracy: 0.6072 - val_loss: 2.4171 - val_accuracy: 0.5403\n",
            "Epoch 82/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 2.2086 - accuracy: 0.6112\n",
            "Epoch 82: val_loss improved from 2.41709 to 2.38276, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.2085 - accuracy: 0.6112 - val_loss: 2.3828 - val_accuracy: 0.5408\n",
            "Epoch 83/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.1685 - accuracy: 0.6163\n",
            "Epoch 83: val_loss improved from 2.38276 to 2.35320, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.1686 - accuracy: 0.6161 - val_loss: 2.3532 - val_accuracy: 0.5394\n",
            "Epoch 84/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 2.1285 - accuracy: 0.6181\n",
            "Epoch 84: val_loss improved from 2.35320 to 2.31995, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.1285 - accuracy: 0.6180 - val_loss: 2.3200 - val_accuracy: 0.5398\n",
            "Epoch 85/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 2.0960 - accuracy: 0.6162\n",
            "Epoch 85: val_loss improved from 2.31995 to 2.30331, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 2.0957 - accuracy: 0.6161 - val_loss: 2.3033 - val_accuracy: 0.5396\n",
            "Epoch 86/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 2.0540 - accuracy: 0.6218\n",
            "Epoch 86: val_loss improved from 2.30331 to 2.26279, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 2.0544 - accuracy: 0.6218 - val_loss: 2.2628 - val_accuracy: 0.5419\n",
            "Epoch 87/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 2.0336 - accuracy: 0.6179\n",
            "Epoch 87: val_loss improved from 2.26279 to 2.23336, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.0338 - accuracy: 0.6184 - val_loss: 2.2334 - val_accuracy: 0.5408\n",
            "Epoch 88/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.9955 - accuracy: 0.6273\n",
            "Epoch 88: val_loss improved from 2.23336 to 2.20757, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.9949 - accuracy: 0.6275 - val_loss: 2.2076 - val_accuracy: 0.5422\n",
            "Epoch 89/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.9613 - accuracy: 0.6278\n",
            "Epoch 89: val_loss improved from 2.20757 to 2.18291, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.9613 - accuracy: 0.6277 - val_loss: 2.1829 - val_accuracy: 0.5467\n",
            "Epoch 90/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.9328 - accuracy: 0.6241\n",
            "Epoch 90: val_loss improved from 2.18291 to 2.15168, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.9329 - accuracy: 0.6243 - val_loss: 2.1517 - val_accuracy: 0.5443\n",
            "Epoch 91/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.9011 - accuracy: 0.6298\n",
            "Epoch 91: val_loss improved from 2.15168 to 2.13352, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.9009 - accuracy: 0.6301 - val_loss: 2.1335 - val_accuracy: 0.5435\n",
            "Epoch 92/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.8758 - accuracy: 0.6315\n",
            "Epoch 92: val_loss improved from 2.13352 to 2.13115, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.8759 - accuracy: 0.6317 - val_loss: 2.1312 - val_accuracy: 0.5373\n",
            "Epoch 93/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.8473 - accuracy: 0.6356\n",
            "Epoch 93: val_loss improved from 2.13115 to 2.09310, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.8470 - accuracy: 0.6357 - val_loss: 2.0931 - val_accuracy: 0.5451\n",
            "Epoch 94/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.8230 - accuracy: 0.6340\n",
            "Epoch 94: val_loss improved from 2.09310 to 2.06516, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.8223 - accuracy: 0.6343 - val_loss: 2.0652 - val_accuracy: 0.5443\n",
            "Epoch 95/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.7951 - accuracy: 0.6383\n",
            "Epoch 95: val_loss improved from 2.06516 to 2.05571, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7950 - accuracy: 0.6382 - val_loss: 2.0557 - val_accuracy: 0.5415\n",
            "Epoch 96/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.7761 - accuracy: 0.6392\n",
            "Epoch 96: val_loss improved from 2.05571 to 2.02354, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7757 - accuracy: 0.6393 - val_loss: 2.0235 - val_accuracy: 0.5466\n",
            "Epoch 97/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.7477 - accuracy: 0.6420\n",
            "Epoch 97: val_loss improved from 2.02354 to 2.00783, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7477 - accuracy: 0.6421 - val_loss: 2.0078 - val_accuracy: 0.5459\n",
            "Epoch 98/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.7266 - accuracy: 0.6425\n",
            "Epoch 98: val_loss improved from 2.00783 to 1.99044, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7266 - accuracy: 0.6426 - val_loss: 1.9904 - val_accuracy: 0.5433\n",
            "Epoch 99/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.7111 - accuracy: 0.6433\n",
            "Epoch 99: val_loss improved from 1.99044 to 1.97187, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7111 - accuracy: 0.6433 - val_loss: 1.9719 - val_accuracy: 0.5466\n",
            "Epoch 100/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.6831 - accuracy: 0.6465\n",
            "Epoch 100: val_loss did not improve from 1.97187\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.6824 - accuracy: 0.6467 - val_loss: 1.9725 - val_accuracy: 0.5406\n",
            "Epoch 101/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.6672 - accuracy: 0.6488\n",
            "Epoch 101: val_loss improved from 1.97187 to 1.94477, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.6674 - accuracy: 0.6487 - val_loss: 1.9448 - val_accuracy: 0.5477\n",
            "Epoch 102/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.6453 - accuracy: 0.6472\n",
            "Epoch 102: val_loss did not improve from 1.94477\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.6453 - accuracy: 0.6473 - val_loss: 1.9475 - val_accuracy: 0.5409\n",
            "Epoch 103/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.6248 - accuracy: 0.6545\n",
            "Epoch 103: val_loss improved from 1.94477 to 1.91705, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.6247 - accuracy: 0.6543 - val_loss: 1.9170 - val_accuracy: 0.5450\n",
            "Epoch 104/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.6069 - accuracy: 0.6552\n",
            "Epoch 104: val_loss improved from 1.91705 to 1.90039, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.6069 - accuracy: 0.6552 - val_loss: 1.9004 - val_accuracy: 0.5466\n",
            "Epoch 105/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.5884 - accuracy: 0.6576\n",
            "Epoch 105: val_loss improved from 1.90039 to 1.89333, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5884 - accuracy: 0.6576 - val_loss: 1.8933 - val_accuracy: 0.5459\n",
            "Epoch 106/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.5696 - accuracy: 0.6560\n",
            "Epoch 106: val_loss improved from 1.89333 to 1.88599, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5706 - accuracy: 0.6556 - val_loss: 1.8860 - val_accuracy: 0.5471\n",
            "Epoch 107/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.5547 - accuracy: 0.6610\n",
            "Epoch 107: val_loss improved from 1.88599 to 1.87104, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.5546 - accuracy: 0.6612 - val_loss: 1.8710 - val_accuracy: 0.5438\n",
            "Epoch 108/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.5391 - accuracy: 0.6595\n",
            "Epoch 108: val_loss improved from 1.87104 to 1.85776, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5393 - accuracy: 0.6596 - val_loss: 1.8578 - val_accuracy: 0.5465\n",
            "Epoch 109/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.5214 - accuracy: 0.6640\n",
            "Epoch 109: val_loss improved from 1.85776 to 1.84940, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.5222 - accuracy: 0.6635 - val_loss: 1.8494 - val_accuracy: 0.5452\n",
            "Epoch 110/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.5052 - accuracy: 0.6621\n",
            "Epoch 110: val_loss improved from 1.84940 to 1.83296, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.5055 - accuracy: 0.6619 - val_loss: 1.8330 - val_accuracy: 0.5482\n",
            "Epoch 111/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.4878 - accuracy: 0.6697\n",
            "Epoch 111: val_loss improved from 1.83296 to 1.81552, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.4878 - accuracy: 0.6697 - val_loss: 1.8155 - val_accuracy: 0.5546\n",
            "Epoch 112/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.4790 - accuracy: 0.6644\n",
            "Epoch 112: val_loss did not improve from 1.81552\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4793 - accuracy: 0.6641 - val_loss: 1.8221 - val_accuracy: 0.5446\n",
            "Epoch 113/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.4634 - accuracy: 0.6709\n",
            "Epoch 113: val_loss improved from 1.81552 to 1.80783, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.4634 - accuracy: 0.6709 - val_loss: 1.8078 - val_accuracy: 0.5485\n",
            "Epoch 114/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 1.4522 - accuracy: 0.6683\n",
            "Epoch 114: val_loss improved from 1.80783 to 1.79287, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.4513 - accuracy: 0.6685 - val_loss: 1.7929 - val_accuracy: 0.5514\n",
            "Epoch 115/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.4356 - accuracy: 0.6729\n",
            "Epoch 115: val_loss improved from 1.79287 to 1.78478, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.4350 - accuracy: 0.6731 - val_loss: 1.7848 - val_accuracy: 0.5477\n",
            "Epoch 116/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.4239 - accuracy: 0.6755\n",
            "Epoch 116: val_loss did not improve from 1.78478\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4239 - accuracy: 0.6755 - val_loss: 1.8234 - val_accuracy: 0.5399\n",
            "Epoch 117/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.4130 - accuracy: 0.6759\n",
            "Epoch 117: val_loss improved from 1.78478 to 1.77476, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.4129 - accuracy: 0.6759 - val_loss: 1.7748 - val_accuracy: 0.5494\n",
            "Epoch 118/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.4020 - accuracy: 0.6757\n",
            "Epoch 118: val_loss improved from 1.77476 to 1.76971, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.4021 - accuracy: 0.6756 - val_loss: 1.7697 - val_accuracy: 0.5463\n",
            "Epoch 119/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.3878 - accuracy: 0.6778\n",
            "Epoch 119: val_loss improved from 1.76971 to 1.76480, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3879 - accuracy: 0.6777 - val_loss: 1.7648 - val_accuracy: 0.5454\n",
            "Epoch 120/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.3780 - accuracy: 0.6799\n",
            "Epoch 120: val_loss improved from 1.76480 to 1.75563, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.3778 - accuracy: 0.6797 - val_loss: 1.7556 - val_accuracy: 0.5484\n",
            "Epoch 121/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3645 - accuracy: 0.6813\n",
            "Epoch 121: val_loss did not improve from 1.75563\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3646 - accuracy: 0.6813 - val_loss: 1.7640 - val_accuracy: 0.5456\n",
            "Epoch 122/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.3628 - accuracy: 0.6781\n",
            "Epoch 122: val_loss improved from 1.75563 to 1.73550, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3628 - accuracy: 0.6781 - val_loss: 1.7355 - val_accuracy: 0.5487\n",
            "Epoch 123/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.3468 - accuracy: 0.6820\n",
            "Epoch 123: val_loss improved from 1.73550 to 1.73002, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3463 - accuracy: 0.6824 - val_loss: 1.7300 - val_accuracy: 0.5538\n",
            "Epoch 124/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.3423 - accuracy: 0.6879\n",
            "Epoch 124: val_loss improved from 1.73002 to 1.72950, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3415 - accuracy: 0.6879 - val_loss: 1.7295 - val_accuracy: 0.5515\n",
            "Epoch 125/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 1.3282 - accuracy: 0.6879\n",
            "Epoch 125: val_loss improved from 1.72950 to 1.71815, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.3294 - accuracy: 0.6873 - val_loss: 1.7181 - val_accuracy: 0.5551\n",
            "Epoch 126/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.3166 - accuracy: 0.6898\n",
            "Epoch 126: val_loss did not improve from 1.71815\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3179 - accuracy: 0.6895 - val_loss: 1.7247 - val_accuracy: 0.5509\n",
            "Epoch 127/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 1.3090 - accuracy: 0.6929\n",
            "Epoch 127: val_loss did not improve from 1.71815\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.3090 - accuracy: 0.6927 - val_loss: 1.7391 - val_accuracy: 0.5472\n",
            "Epoch 128/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 1.3040 - accuracy: 0.6924\n",
            "Epoch 128: val_loss improved from 1.71815 to 1.70919, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.3041 - accuracy: 0.6923 - val_loss: 1.7092 - val_accuracy: 0.5503\n",
            "Epoch 129/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.2909 - accuracy: 0.6948\n",
            "Epoch 129: val_loss did not improve from 1.70919\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2910 - accuracy: 0.6951 - val_loss: 1.7098 - val_accuracy: 0.5513\n",
            "Epoch 130/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.2846 - accuracy: 0.6946\n",
            "Epoch 130: val_loss improved from 1.70919 to 1.70814, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.2857 - accuracy: 0.6942 - val_loss: 1.7081 - val_accuracy: 0.5509\n",
            "Epoch 131/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.2829 - accuracy: 0.6956\n",
            "Epoch 131: val_loss did not improve from 1.70814\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2829 - accuracy: 0.6957 - val_loss: 1.7186 - val_accuracy: 0.5435\n",
            "Epoch 132/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.2713 - accuracy: 0.6971\n",
            "Epoch 132: val_loss improved from 1.70814 to 1.69426, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2717 - accuracy: 0.6969 - val_loss: 1.6943 - val_accuracy: 0.5539\n",
            "Epoch 133/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.2687 - accuracy: 0.6947\n",
            "Epoch 133: val_loss improved from 1.69426 to 1.69229, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.2689 - accuracy: 0.6947 - val_loss: 1.6923 - val_accuracy: 0.5497\n",
            "Epoch 134/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.2548 - accuracy: 0.6976\n",
            "Epoch 134: val_loss did not improve from 1.69229\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2551 - accuracy: 0.6976 - val_loss: 1.7296 - val_accuracy: 0.5387\n",
            "Epoch 135/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 1.2463 - accuracy: 0.7017\n",
            "Epoch 135: val_loss improved from 1.69229 to 1.68867, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2468 - accuracy: 0.7012 - val_loss: 1.6887 - val_accuracy: 0.5495\n",
            "Epoch 136/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.2395 - accuracy: 0.7015\n",
            "Epoch 136: val_loss improved from 1.68867 to 1.67790, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2393 - accuracy: 0.7015 - val_loss: 1.6779 - val_accuracy: 0.5526\n",
            "Epoch 137/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.2351 - accuracy: 0.7029\n",
            "Epoch 137: val_loss did not improve from 1.67790\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2354 - accuracy: 0.7027 - val_loss: 1.6832 - val_accuracy: 0.5512\n",
            "Epoch 138/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.2307 - accuracy: 0.7056\n",
            "Epoch 138: val_loss did not improve from 1.67790\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.2309 - accuracy: 0.7052 - val_loss: 1.6899 - val_accuracy: 0.5517\n",
            "Epoch 139/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.2249 - accuracy: 0.7067\n",
            "Epoch 139: val_loss did not improve from 1.67790\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2245 - accuracy: 0.7066 - val_loss: 1.6807 - val_accuracy: 0.5534\n",
            "Epoch 140/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.2159 - accuracy: 0.7079\n",
            "Epoch 140: val_loss did not improve from 1.67790\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2161 - accuracy: 0.7078 - val_loss: 1.6973 - val_accuracy: 0.5445\n",
            "Epoch 141/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.2140 - accuracy: 0.7082\n",
            "Epoch 141: val_loss improved from 1.67790 to 1.66886, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.2141 - accuracy: 0.7082 - val_loss: 1.6689 - val_accuracy: 0.5539\n",
            "Epoch 142/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.1973 - accuracy: 0.7144\n",
            "Epoch 142: val_loss did not improve from 1.66886\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.1973 - accuracy: 0.7144 - val_loss: 1.6698 - val_accuracy: 0.5492\n",
            "Epoch 143/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.2035 - accuracy: 0.7111\n",
            "Epoch 143: val_loss did not improve from 1.66886\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.2036 - accuracy: 0.7111 - val_loss: 1.6781 - val_accuracy: 0.5466\n",
            "Epoch 144/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.1943 - accuracy: 0.7104\n",
            "Epoch 144: val_loss did not improve from 1.66886\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1942 - accuracy: 0.7104 - val_loss: 1.6910 - val_accuracy: 0.5459\n",
            "Epoch 145/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.1876 - accuracy: 0.7134\n",
            "Epoch 145: val_loss improved from 1.66886 to 1.66556, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.1877 - accuracy: 0.7134 - val_loss: 1.6656 - val_accuracy: 0.5481\n",
            "Epoch 146/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.1853 - accuracy: 0.7131\n",
            "Epoch 146: val_loss did not improve from 1.66556\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.1854 - accuracy: 0.7131 - val_loss: 1.6862 - val_accuracy: 0.5413\n",
            "Epoch 147/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.1786 - accuracy: 0.7151\n",
            "Epoch 147: val_loss did not improve from 1.66556\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.1786 - accuracy: 0.7150 - val_loss: 1.6735 - val_accuracy: 0.5473\n",
            "Epoch 148/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.1701 - accuracy: 0.7218\n",
            "Epoch 148: val_loss improved from 1.66556 to 1.65778, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.1697 - accuracy: 0.7220 - val_loss: 1.6578 - val_accuracy: 0.5523\n",
            "Epoch 149/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.1676 - accuracy: 0.7173\n",
            "Epoch 149: val_loss did not improve from 1.65778\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1677 - accuracy: 0.7172 - val_loss: 1.6656 - val_accuracy: 0.5517\n",
            "Epoch 150/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.1622 - accuracy: 0.7200\n",
            "Epoch 150: val_loss did not improve from 1.65778\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.1616 - accuracy: 0.7199 - val_loss: 1.6601 - val_accuracy: 0.5512\n",
            "Epoch 151/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.1655 - accuracy: 0.7171\n",
            "Epoch 151: val_loss did not improve from 1.65778\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1668 - accuracy: 0.7166 - val_loss: 1.6702 - val_accuracy: 0.5495\n",
            "Epoch 152/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.1567 - accuracy: 0.7203\n",
            "Epoch 152: val_loss improved from 1.65778 to 1.65514, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1571 - accuracy: 0.7202 - val_loss: 1.6551 - val_accuracy: 0.5558\n",
            "Epoch 153/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.1517 - accuracy: 0.7246\n",
            "Epoch 153: val_loss did not improve from 1.65514\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.1517 - accuracy: 0.7246 - val_loss: 1.6555 - val_accuracy: 0.5531\n",
            "Epoch 154/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.1479 - accuracy: 0.7246\n",
            "Epoch 154: val_loss improved from 1.65514 to 1.64021, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1479 - accuracy: 0.7247 - val_loss: 1.6402 - val_accuracy: 0.5573\n",
            "Epoch 155/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.1411 - accuracy: 0.7236\n",
            "Epoch 155: val_loss did not improve from 1.64021\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.1411 - accuracy: 0.7236 - val_loss: 1.6442 - val_accuracy: 0.5561\n",
            "Epoch 156/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.1372 - accuracy: 0.7234\n",
            "Epoch 156: val_loss did not improve from 1.64021\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1382 - accuracy: 0.7231 - val_loss: 1.6617 - val_accuracy: 0.5510\n",
            "Epoch 157/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.1345 - accuracy: 0.7268\n",
            "Epoch 157: val_loss did not improve from 1.64021\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1349 - accuracy: 0.7266 - val_loss: 1.6713 - val_accuracy: 0.5464\n",
            "Epoch 158/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.1265 - accuracy: 0.7290\n",
            "Epoch 158: val_loss did not improve from 1.64021\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.1265 - accuracy: 0.7290 - val_loss: 1.6658 - val_accuracy: 0.5470\n",
            "Epoch 159/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.1251 - accuracy: 0.7289\n",
            "Epoch 159: val_loss did not improve from 1.64021\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1247 - accuracy: 0.7292 - val_loss: 1.6609 - val_accuracy: 0.5508\n",
            "Epoch 160/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.1305 - accuracy: 0.7268\n",
            "Epoch 160: val_loss did not improve from 1.64021\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.1306 - accuracy: 0.7267 - val_loss: 1.6565 - val_accuracy: 0.5512\n",
            "Epoch 161/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.1204 - accuracy: 0.7328\n",
            "Epoch 161: val_loss did not improve from 1.64021\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.1204 - accuracy: 0.7328 - val_loss: 1.6475 - val_accuracy: 0.5556\n",
            "Epoch 162/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.1155 - accuracy: 0.7312\n",
            "Epoch 162: val_loss improved from 1.64021 to 1.63337, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.1151 - accuracy: 0.7314 - val_loss: 1.6334 - val_accuracy: 0.5598\n",
            "Epoch 163/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.1114 - accuracy: 0.7313\n",
            "Epoch 163: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.1114 - accuracy: 0.7313 - val_loss: 1.6600 - val_accuracy: 0.5491\n",
            "Epoch 164/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.1120 - accuracy: 0.7331\n",
            "Epoch 164: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1119 - accuracy: 0.7332 - val_loss: 1.6945 - val_accuracy: 0.5451\n",
            "Epoch 165/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.1064 - accuracy: 0.7373\n",
            "Epoch 165: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1060 - accuracy: 0.7376 - val_loss: 1.6423 - val_accuracy: 0.5584\n",
            "Epoch 166/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.1042 - accuracy: 0.7343\n",
            "Epoch 166: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.1042 - accuracy: 0.7343 - val_loss: 1.6971 - val_accuracy: 0.5455\n",
            "Epoch 167/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.1059 - accuracy: 0.7356\n",
            "Epoch 167: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.1063 - accuracy: 0.7351 - val_loss: 1.6524 - val_accuracy: 0.5563\n",
            "Epoch 168/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.0959 - accuracy: 0.7406\n",
            "Epoch 168: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.0956 - accuracy: 0.7407 - val_loss: 1.6553 - val_accuracy: 0.5528\n",
            "Epoch 169/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.0939 - accuracy: 0.7393\n",
            "Epoch 169: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.0941 - accuracy: 0.7394 - val_loss: 1.6554 - val_accuracy: 0.5523\n",
            "Epoch 170/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.0929 - accuracy: 0.7378\n",
            "Epoch 170: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.0931 - accuracy: 0.7379 - val_loss: 1.6539 - val_accuracy: 0.5500\n",
            "Epoch 171/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.0904 - accuracy: 0.7380\n",
            "Epoch 171: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.0909 - accuracy: 0.7380 - val_loss: 1.6444 - val_accuracy: 0.5554\n",
            "Epoch 172/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.0876 - accuracy: 0.7396\n",
            "Epoch 172: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.0876 - accuracy: 0.7396 - val_loss: 1.6577 - val_accuracy: 0.5523\n",
            "Epoch 173/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.0860 - accuracy: 0.7392\n",
            "Epoch 173: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.0859 - accuracy: 0.7392 - val_loss: 1.6401 - val_accuracy: 0.5532\n",
            "Epoch 174/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.0794 - accuracy: 0.7441\n",
            "Epoch 174: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.0793 - accuracy: 0.7441 - val_loss: 1.6936 - val_accuracy: 0.5451\n",
            "Epoch 175/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.0744 - accuracy: 0.7434\n",
            "Epoch 175: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.0749 - accuracy: 0.7431 - val_loss: 1.6572 - val_accuracy: 0.5531\n",
            "Epoch 176/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.0742 - accuracy: 0.7461\n",
            "Epoch 176: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.0744 - accuracy: 0.7460 - val_loss: 1.6498 - val_accuracy: 0.5538\n",
            "Epoch 177/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.0757 - accuracy: 0.7451\n",
            "Epoch 177: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.0757 - accuracy: 0.7451 - val_loss: 1.6557 - val_accuracy: 0.5553\n",
            "Epoch 178/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.0704 - accuracy: 0.7477\n",
            "Epoch 178: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.0701 - accuracy: 0.7481 - val_loss: 1.6482 - val_accuracy: 0.5531\n",
            "Epoch 179/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.0654 - accuracy: 0.7488\n",
            "Epoch 179: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.0655 - accuracy: 0.7486 - val_loss: 1.6731 - val_accuracy: 0.5492\n",
            "Epoch 180/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.0614 - accuracy: 0.7524\n",
            "Epoch 180: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.0616 - accuracy: 0.7523 - val_loss: 1.6731 - val_accuracy: 0.5463\n",
            "Epoch 181/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.0652 - accuracy: 0.7464\n",
            "Epoch 181: val_loss did not improve from 1.63337\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.0654 - accuracy: 0.7460 - val_loss: 1.6994 - val_accuracy: 0.5422\n",
            "Epoch 182/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.0644 - accuracy: 0.7490\n",
            "Epoch 182: val_loss did not improve from 1.63337\n",
            "Restoring model weights from the end of the best epoch: 162.\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.0640 - accuracy: 0.7490 - val_loss: 1.6545 - val_accuracy: 0.5548\n",
            "Epoch 182: early stopping\n",
            "Training Runtime: 853.75 seconds\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.6158 - accuracy: 0.5649\n",
            "Test Loss: 1.6158\n",
            "Test Accuracy: 0.5649\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10  # 10-class problem\n",
        "drop_rate = 0.5\n",
        "# Define model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(32,32,3)))\n",
        "model.add(layers.Dense(1000, kernel_initializer='lecun_normal', kernel_regularizer='l2', activation='relu'))\n",
        "model.add(layers.Dropout(drop_rate))\n",
        "model.add(layers.Dense(1000, kernel_initializer='lecun_normal', kernel_regularizer='l2', activation='relu'))\n",
        "model.add(layers.Dropout(drop_rate))\n",
        "model.add(layers.Dense(100, kernel_initializer='lecun_normal', activation='relu'))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create an SGD optimizer instance with the desired learning rate\n",
        "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# Train the model with callbacks\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(X_train_norm, y_train, epochs=500, batch_size=32, validation_data=(X_val_norm, y_val), callbacks=[checkpoint, early_stopping])\n",
        "\n",
        "end_time = time.time()\n",
        "# Calculate the training runtime\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training Runtime: {training_time:.2f} seconds\")\n",
        "\n",
        "# Load the best model weights\n",
        "model.load_weights(\"best_model.h5\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_norm, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbmbr9Ol-wb0"
      },
      "source": [
        "## Model 3. Test architecture of model 2 by adding one more layers and a dropout\n",
        "\n",
        "- Training Runtime: 980.60 seconds\n",
        "- Test Loss: 1.5925\n",
        "- Test Accuracy: 0.5408"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vutebb596Z5r",
        "outputId": "0df23ab1-6d99-4190-e82a-e932e5a1ab3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 22.0466 - accuracy: 0.1153\n",
            "Epoch 1: val_loss improved from inf to 21.50645, saving model to best_model.h5\n",
            "938/938 [==============================] - 8s 6ms/step - loss: 22.0458 - accuracy: 0.1154 - val_loss: 21.5064 - val_accuracy: 0.1856\n",
            "Epoch 2/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 21.1727 - accuracy: 0.1354\n",
            "Epoch 2: val_loss improved from 21.50645 to 20.74971, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 21.1701 - accuracy: 0.1355 - val_loss: 20.7497 - val_accuracy: 0.2047\n",
            "Epoch 3/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 20.4357 - accuracy: 0.1519\n",
            "Epoch 3: val_loss improved from 20.74971 to 20.02018, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 20.4349 - accuracy: 0.1519 - val_loss: 20.0202 - val_accuracy: 0.2294\n",
            "Epoch 4/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 19.7316 - accuracy: 0.1675\n",
            "Epoch 4: val_loss improved from 20.02018 to 19.31735, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 19.7290 - accuracy: 0.1680 - val_loss: 19.3173 - val_accuracy: 0.2480\n",
            "Epoch 5/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 19.0563 - accuracy: 0.1786\n",
            "Epoch 5: val_loss improved from 19.31735 to 18.65039, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 19.0552 - accuracy: 0.1785 - val_loss: 18.6504 - val_accuracy: 0.2561\n",
            "Epoch 6/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 18.4103 - accuracy: 0.1872\n",
            "Epoch 6: val_loss improved from 18.65039 to 18.00501, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18.4083 - accuracy: 0.1874 - val_loss: 18.0050 - val_accuracy: 0.2653\n",
            "Epoch 7/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 17.7914 - accuracy: 0.1954\n",
            "Epoch 7: val_loss improved from 18.00501 to 17.38941, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17.7914 - accuracy: 0.1954 - val_loss: 17.3894 - val_accuracy: 0.2739\n",
            "Epoch 8/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 17.1956 - accuracy: 0.2051\n",
            "Epoch 8: val_loss improved from 17.38941 to 16.79613, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 17.1934 - accuracy: 0.2052 - val_loss: 16.7961 - val_accuracy: 0.2807\n",
            "Epoch 9/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 16.6232 - accuracy: 0.2139\n",
            "Epoch 9: val_loss improved from 16.79613 to 16.22928, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 16.6224 - accuracy: 0.2136 - val_loss: 16.2293 - val_accuracy: 0.2913\n",
            "Epoch 10/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 16.0650 - accuracy: 0.2220\n",
            "Epoch 10: val_loss improved from 16.22928 to 15.68407, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 16.0642 - accuracy: 0.2219 - val_loss: 15.6841 - val_accuracy: 0.2956\n",
            "Epoch 11/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 15.5292 - accuracy: 0.2289\n",
            "Epoch 11: val_loss improved from 15.68407 to 15.15802, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 15.5289 - accuracy: 0.2290 - val_loss: 15.1580 - val_accuracy: 0.3031\n",
            "Epoch 12/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 15.0222 - accuracy: 0.2358\n",
            "Epoch 12: val_loss improved from 15.15802 to 14.65699, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 15.0221 - accuracy: 0.2358 - val_loss: 14.6570 - val_accuracy: 0.3090\n",
            "Epoch 13/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 14.5267 - accuracy: 0.2384\n",
            "Epoch 13: val_loss improved from 14.65699 to 14.17132, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14.5266 - accuracy: 0.2384 - val_loss: 14.1713 - val_accuracy: 0.3151\n",
            "Epoch 14/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 14.0614 - accuracy: 0.2393\n",
            "Epoch 14: val_loss improved from 14.17132 to 13.70606, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 14.0587 - accuracy: 0.2399 - val_loss: 13.7061 - val_accuracy: 0.3216\n",
            "Epoch 15/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 13.6076 - accuracy: 0.2466\n",
            "Epoch 15: val_loss improved from 13.70606 to 13.25924, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13.6048 - accuracy: 0.2467 - val_loss: 13.2592 - val_accuracy: 0.3230\n",
            "Epoch 16/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 13.1636 - accuracy: 0.2521\n",
            "Epoch 16: val_loss improved from 13.25924 to 12.82743, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13.1631 - accuracy: 0.2519 - val_loss: 12.8274 - val_accuracy: 0.3294\n",
            "Epoch 17/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 12.7433 - accuracy: 0.2583\n",
            "Epoch 17: val_loss improved from 12.82743 to 12.41441, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 12.7423 - accuracy: 0.2582 - val_loss: 12.4144 - val_accuracy: 0.3350\n",
            "Epoch 18/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 12.3279 - accuracy: 0.2661\n",
            "Epoch 18: val_loss improved from 12.41441 to 12.01361, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 12.3275 - accuracy: 0.2661 - val_loss: 12.0136 - val_accuracy: 0.3421\n",
            "Epoch 19/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 11.9425 - accuracy: 0.2660\n",
            "Epoch 19: val_loss improved from 12.01361 to 11.63136, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 11.9423 - accuracy: 0.2659 - val_loss: 11.6314 - val_accuracy: 0.3468\n",
            "Epoch 20/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 11.5616 - accuracy: 0.2709\n",
            "Epoch 20: val_loss improved from 11.63136 to 11.25990, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 11.5609 - accuracy: 0.2708 - val_loss: 11.2599 - val_accuracy: 0.3445\n",
            "Epoch 21/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 11.1954 - accuracy: 0.2799\n",
            "Epoch 21: val_loss improved from 11.25990 to 10.90257, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 11.1953 - accuracy: 0.2798 - val_loss: 10.9026 - val_accuracy: 0.3533\n",
            "Epoch 22/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 10.8510 - accuracy: 0.2796\n",
            "Epoch 22: val_loss improved from 10.90257 to 10.56082, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 10.8510 - accuracy: 0.2796 - val_loss: 10.5608 - val_accuracy: 0.3565\n",
            "Epoch 23/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 10.5172 - accuracy: 0.2856\n",
            "Epoch 23: val_loss improved from 10.56082 to 10.23259, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 10.5151 - accuracy: 0.2856 - val_loss: 10.2326 - val_accuracy: 0.3608\n",
            "Epoch 24/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 10.1901 - accuracy: 0.2875\n",
            "Epoch 24: val_loss improved from 10.23259 to 9.91391, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 10.1900 - accuracy: 0.2875 - val_loss: 9.9139 - val_accuracy: 0.3654\n",
            "Epoch 25/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 9.8788 - accuracy: 0.2903\n",
            "Epoch 25: val_loss improved from 9.91391 to 9.60851, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 9.8788 - accuracy: 0.2902 - val_loss: 9.6085 - val_accuracy: 0.3697\n",
            "Epoch 26/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 9.5727 - accuracy: 0.2971\n",
            "Epoch 26: val_loss improved from 9.60851 to 9.31394, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 9.5727 - accuracy: 0.2971 - val_loss: 9.3139 - val_accuracy: 0.3733\n",
            "Epoch 27/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 9.2812 - accuracy: 0.3016\n",
            "Epoch 27: val_loss improved from 9.31394 to 9.03145, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 9.2805 - accuracy: 0.3015 - val_loss: 9.0314 - val_accuracy: 0.3729\n",
            "Epoch 28/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 9.0039 - accuracy: 0.3048\n",
            "Epoch 28: val_loss improved from 9.03145 to 8.75653, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 9.0036 - accuracy: 0.3050 - val_loss: 8.7565 - val_accuracy: 0.3745\n",
            "Epoch 29/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 8.7377 - accuracy: 0.3089\n",
            "Epoch 29: val_loss improved from 8.75653 to 8.49257, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 8.7365 - accuracy: 0.3091 - val_loss: 8.4926 - val_accuracy: 0.3760\n",
            "Epoch 30/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 8.4802 - accuracy: 0.3095\n",
            "Epoch 30: val_loss improved from 8.49257 to 8.23857, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 8.4801 - accuracy: 0.3095 - val_loss: 8.2386 - val_accuracy: 0.3791\n",
            "Epoch 31/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 8.2225 - accuracy: 0.3120\n",
            "Epoch 31: val_loss improved from 8.23857 to 7.99404, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 8.2225 - accuracy: 0.3120 - val_loss: 7.9940 - val_accuracy: 0.3846\n",
            "Epoch 32/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 7.9794 - accuracy: 0.3192\n",
            "Epoch 32: val_loss improved from 7.99404 to 7.75644, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 7.9779 - accuracy: 0.3194 - val_loss: 7.7564 - val_accuracy: 0.3892\n",
            "Epoch 33/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 7.7539 - accuracy: 0.3220\n",
            "Epoch 33: val_loss improved from 7.75644 to 7.53125, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 7.7536 - accuracy: 0.3220 - val_loss: 7.5312 - val_accuracy: 0.3872\n",
            "Epoch 34/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 7.5227 - accuracy: 0.3264\n",
            "Epoch 34: val_loss improved from 7.53125 to 7.31216, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 7.5221 - accuracy: 0.3257 - val_loss: 7.3122 - val_accuracy: 0.3905\n",
            "Epoch 35/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 7.3074 - accuracy: 0.3318\n",
            "Epoch 35: val_loss improved from 7.31216 to 7.10087, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 7.3069 - accuracy: 0.3316 - val_loss: 7.1009 - val_accuracy: 0.3935\n",
            "Epoch 36/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 7.1058 - accuracy: 0.3315\n",
            "Epoch 36: val_loss improved from 7.10087 to 6.89726, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 7.1038 - accuracy: 0.3315 - val_loss: 6.8973 - val_accuracy: 0.3963\n",
            "Epoch 37/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 6.8951 - accuracy: 0.3351\n",
            "Epoch 37: val_loss improved from 6.89726 to 6.69847, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 6.8949 - accuracy: 0.3351 - val_loss: 6.6985 - val_accuracy: 0.3978\n",
            "Epoch 38/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 6.7098 - accuracy: 0.3397\n",
            "Epoch 38: val_loss improved from 6.69847 to 6.50997, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.7081 - accuracy: 0.3401 - val_loss: 6.5100 - val_accuracy: 0.4007\n",
            "Epoch 39/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 6.5211 - accuracy: 0.3418\n",
            "Epoch 39: val_loss improved from 6.50997 to 6.32507, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 6.5206 - accuracy: 0.3416 - val_loss: 6.3251 - val_accuracy: 0.4029\n",
            "Epoch 40/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 6.3362 - accuracy: 0.3463\n",
            "Epoch 40: val_loss improved from 6.32507 to 6.14999, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.3360 - accuracy: 0.3464 - val_loss: 6.1500 - val_accuracy: 0.4062\n",
            "Epoch 41/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 6.1704 - accuracy: 0.3457\n",
            "Epoch 41: val_loss improved from 6.14999 to 5.97767, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 6.1704 - accuracy: 0.3456 - val_loss: 5.9777 - val_accuracy: 0.4068\n",
            "Epoch 42/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 6.0014 - accuracy: 0.3500\n",
            "Epoch 42: val_loss improved from 5.97767 to 5.81631, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 6.0006 - accuracy: 0.3501 - val_loss: 5.8163 - val_accuracy: 0.4109\n",
            "Epoch 43/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 5.8412 - accuracy: 0.3546\n",
            "Epoch 43: val_loss improved from 5.81631 to 5.65733, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 5.8411 - accuracy: 0.3545 - val_loss: 5.6573 - val_accuracy: 0.4130\n",
            "Epoch 44/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 5.6807 - accuracy: 0.3601\n",
            "Epoch 44: val_loss improved from 5.65733 to 5.50600, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.6807 - accuracy: 0.3601 - val_loss: 5.5060 - val_accuracy: 0.4137\n",
            "Epoch 45/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 5.5288 - accuracy: 0.3624\n",
            "Epoch 45: val_loss improved from 5.50600 to 5.35814, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.5270 - accuracy: 0.3628 - val_loss: 5.3581 - val_accuracy: 0.4186\n",
            "Epoch 46/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 5.3874 - accuracy: 0.3621\n",
            "Epoch 46: val_loss improved from 5.35814 to 5.21829, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 5.3876 - accuracy: 0.3621 - val_loss: 5.2183 - val_accuracy: 0.4184\n",
            "Epoch 47/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 5.2404 - accuracy: 0.3688\n",
            "Epoch 47: val_loss improved from 5.21829 to 5.08019, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.2406 - accuracy: 0.3688 - val_loss: 5.0802 - val_accuracy: 0.4213\n",
            "Epoch 48/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 5.1065 - accuracy: 0.3724\n",
            "Epoch 48: val_loss improved from 5.08019 to 4.95003, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 5.1061 - accuracy: 0.3724 - val_loss: 4.9500 - val_accuracy: 0.4271\n",
            "Epoch 49/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 4.9851 - accuracy: 0.3763\n",
            "Epoch 49: val_loss improved from 4.95003 to 4.82451, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.9847 - accuracy: 0.3758 - val_loss: 4.8245 - val_accuracy: 0.4287\n",
            "Epoch 50/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 4.8540 - accuracy: 0.3770\n",
            "Epoch 50: val_loss improved from 4.82451 to 4.70078, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.8537 - accuracy: 0.3772 - val_loss: 4.7008 - val_accuracy: 0.4315\n",
            "Epoch 51/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 4.7333 - accuracy: 0.3805\n",
            "Epoch 51: val_loss improved from 4.70078 to 4.58066, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 4.7329 - accuracy: 0.3806 - val_loss: 4.5807 - val_accuracy: 0.4329\n",
            "Epoch 52/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 4.6148 - accuracy: 0.3826\n",
            "Epoch 52: val_loss improved from 4.58066 to 4.47451, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.6154 - accuracy: 0.3822 - val_loss: 4.4745 - val_accuracy: 0.4290\n",
            "Epoch 53/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 4.5054 - accuracy: 0.3844\n",
            "Epoch 53: val_loss improved from 4.47451 to 4.35701, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 4.5051 - accuracy: 0.3844 - val_loss: 4.3570 - val_accuracy: 0.4376\n",
            "Epoch 54/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 4.4018 - accuracy: 0.3899\n",
            "Epoch 54: val_loss improved from 4.35701 to 4.25683, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.4017 - accuracy: 0.3898 - val_loss: 4.2568 - val_accuracy: 0.4385\n",
            "Epoch 55/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 4.2878 - accuracy: 0.3948\n",
            "Epoch 55: val_loss improved from 4.25683 to 4.15572, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.2872 - accuracy: 0.3946 - val_loss: 4.1557 - val_accuracy: 0.4394\n",
            "Epoch 56/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 4.1917 - accuracy: 0.3911\n",
            "Epoch 56: val_loss improved from 4.15572 to 4.05702, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 4.1913 - accuracy: 0.3912 - val_loss: 4.0570 - val_accuracy: 0.4444\n",
            "Epoch 57/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 4.0951 - accuracy: 0.3978\n",
            "Epoch 57: val_loss improved from 4.05702 to 3.95938, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.0946 - accuracy: 0.3982 - val_loss: 3.9594 - val_accuracy: 0.4440\n",
            "Epoch 58/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 3.9889 - accuracy: 0.4004\n",
            "Epoch 58: val_loss improved from 3.95938 to 3.86700, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.9890 - accuracy: 0.4003 - val_loss: 3.8670 - val_accuracy: 0.4456\n",
            "Epoch 59/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 3.9055 - accuracy: 0.4045\n",
            "Epoch 59: val_loss improved from 3.86700 to 3.78305, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.9053 - accuracy: 0.4045 - val_loss: 3.7830 - val_accuracy: 0.4542\n",
            "Epoch 60/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 3.8140 - accuracy: 0.4078\n",
            "Epoch 60: val_loss improved from 3.78305 to 3.69577, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.8138 - accuracy: 0.4078 - val_loss: 3.6958 - val_accuracy: 0.4524\n",
            "Epoch 61/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 3.7373 - accuracy: 0.4084\n",
            "Epoch 61: val_loss improved from 3.69577 to 3.61749, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.7365 - accuracy: 0.4087 - val_loss: 3.6175 - val_accuracy: 0.4499\n",
            "Epoch 62/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 3.6488 - accuracy: 0.4132\n",
            "Epoch 62: val_loss improved from 3.61749 to 3.53836, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.6482 - accuracy: 0.4133 - val_loss: 3.5384 - val_accuracy: 0.4517\n",
            "Epoch 63/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 3.5701 - accuracy: 0.4136\n",
            "Epoch 63: val_loss improved from 3.53836 to 3.46194, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.5695 - accuracy: 0.4140 - val_loss: 3.4619 - val_accuracy: 0.4550\n",
            "Epoch 64/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 3.4960 - accuracy: 0.4215\n",
            "Epoch 64: val_loss improved from 3.46194 to 3.39125, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.4965 - accuracy: 0.4213 - val_loss: 3.3912 - val_accuracy: 0.4581\n",
            "Epoch 65/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 3.4239 - accuracy: 0.4197\n",
            "Epoch 65: val_loss improved from 3.39125 to 3.31681, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.4236 - accuracy: 0.4197 - val_loss: 3.3168 - val_accuracy: 0.4611\n",
            "Epoch 66/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 3.3475 - accuracy: 0.4286\n",
            "Epoch 66: val_loss improved from 3.31681 to 3.24665, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 3.3476 - accuracy: 0.4283 - val_loss: 3.2467 - val_accuracy: 0.4605\n",
            "Epoch 67/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 3.2833 - accuracy: 0.4243\n",
            "Epoch 67: val_loss improved from 3.24665 to 3.18758, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.2822 - accuracy: 0.4244 - val_loss: 3.1876 - val_accuracy: 0.4613\n",
            "Epoch 68/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 3.2210 - accuracy: 0.4287\n",
            "Epoch 68: val_loss improved from 3.18758 to 3.13128, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 3.2209 - accuracy: 0.4287 - val_loss: 3.1313 - val_accuracy: 0.4593\n",
            "Epoch 69/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 3.1564 - accuracy: 0.4330\n",
            "Epoch 69: val_loss improved from 3.13128 to 3.06843, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.1557 - accuracy: 0.4333 - val_loss: 3.0684 - val_accuracy: 0.4618\n",
            "Epoch 70/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 3.0960 - accuracy: 0.4310\n",
            "Epoch 70: val_loss improved from 3.06843 to 3.01013, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 3.0960 - accuracy: 0.4311 - val_loss: 3.0101 - val_accuracy: 0.4664\n",
            "Epoch 71/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 3.0375 - accuracy: 0.4336\n",
            "Epoch 71: val_loss improved from 3.01013 to 2.95255, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.0376 - accuracy: 0.4334 - val_loss: 2.9525 - val_accuracy: 0.4659\n",
            "Epoch 72/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 2.9708 - accuracy: 0.4427\n",
            "Epoch 72: val_loss improved from 2.95255 to 2.89424, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.9712 - accuracy: 0.4427 - val_loss: 2.8942 - val_accuracy: 0.4673\n",
            "Epoch 73/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 2.9205 - accuracy: 0.4415\n",
            "Epoch 73: val_loss improved from 2.89424 to 2.84599, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.9206 - accuracy: 0.4416 - val_loss: 2.8460 - val_accuracy: 0.4730\n",
            "Epoch 74/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 2.8651 - accuracy: 0.4457\n",
            "Epoch 74: val_loss improved from 2.84599 to 2.81297, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.8656 - accuracy: 0.4452 - val_loss: 2.8130 - val_accuracy: 0.4675\n",
            "Epoch 75/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.8145 - accuracy: 0.4477\n",
            "Epoch 75: val_loss improved from 2.81297 to 2.74695, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.8148 - accuracy: 0.4477 - val_loss: 2.7469 - val_accuracy: 0.4726\n",
            "Epoch 76/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 2.7671 - accuracy: 0.4491\n",
            "Epoch 76: val_loss improved from 2.74695 to 2.71458, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.7667 - accuracy: 0.4491 - val_loss: 2.7146 - val_accuracy: 0.4725\n",
            "Epoch 77/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.7158 - accuracy: 0.4520\n",
            "Epoch 77: val_loss improved from 2.71458 to 2.65430, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.7158 - accuracy: 0.4519 - val_loss: 2.6543 - val_accuracy: 0.4736\n",
            "Epoch 78/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.6795 - accuracy: 0.4519\n",
            "Epoch 78: val_loss improved from 2.65430 to 2.61264, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.6795 - accuracy: 0.4520 - val_loss: 2.6126 - val_accuracy: 0.4782\n",
            "Epoch 79/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.6254 - accuracy: 0.4585\n",
            "Epoch 79: val_loss improved from 2.61264 to 2.57018, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.6254 - accuracy: 0.4584 - val_loss: 2.5702 - val_accuracy: 0.4833\n",
            "Epoch 80/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 2.5884 - accuracy: 0.4588\n",
            "Epoch 80: val_loss improved from 2.57018 to 2.53365, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.5884 - accuracy: 0.4589 - val_loss: 2.5337 - val_accuracy: 0.4760\n",
            "Epoch 81/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 2.5419 - accuracy: 0.4611\n",
            "Epoch 81: val_loss improved from 2.53365 to 2.49528, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.5418 - accuracy: 0.4608 - val_loss: 2.4953 - val_accuracy: 0.4805\n",
            "Epoch 82/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.5001 - accuracy: 0.4628\n",
            "Epoch 82: val_loss improved from 2.49528 to 2.45876, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.5000 - accuracy: 0.4628 - val_loss: 2.4588 - val_accuracy: 0.4820\n",
            "Epoch 83/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 2.4600 - accuracy: 0.4651\n",
            "Epoch 83: val_loss improved from 2.45876 to 2.43008, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.4600 - accuracy: 0.4652 - val_loss: 2.4301 - val_accuracy: 0.4838\n",
            "Epoch 84/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 2.4282 - accuracy: 0.4683\n",
            "Epoch 84: val_loss improved from 2.43008 to 2.39413, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.4282 - accuracy: 0.4685 - val_loss: 2.3941 - val_accuracy: 0.4826\n",
            "Epoch 85/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 2.3932 - accuracy: 0.4696\n",
            "Epoch 85: val_loss improved from 2.39413 to 2.35223, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.3933 - accuracy: 0.4690 - val_loss: 2.3522 - val_accuracy: 0.4871\n",
            "Epoch 86/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 2.3582 - accuracy: 0.4678\n",
            "Epoch 86: val_loss improved from 2.35223 to 2.32810, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.3576 - accuracy: 0.4682 - val_loss: 2.3281 - val_accuracy: 0.4848\n",
            "Epoch 87/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.3222 - accuracy: 0.4732\n",
            "Epoch 87: val_loss improved from 2.32810 to 2.29318, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.3226 - accuracy: 0.4729 - val_loss: 2.2932 - val_accuracy: 0.4895\n",
            "Epoch 88/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.2856 - accuracy: 0.4779\n",
            "Epoch 88: val_loss improved from 2.29318 to 2.27149, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.2858 - accuracy: 0.4778 - val_loss: 2.2715 - val_accuracy: 0.4853\n",
            "Epoch 89/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.2594 - accuracy: 0.4781\n",
            "Epoch 89: val_loss improved from 2.27149 to 2.23702, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.2592 - accuracy: 0.4782 - val_loss: 2.2370 - val_accuracy: 0.4906\n",
            "Epoch 90/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 2.2203 - accuracy: 0.4786\n",
            "Epoch 90: val_loss improved from 2.23702 to 2.21773, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.2198 - accuracy: 0.4787 - val_loss: 2.2177 - val_accuracy: 0.4860\n",
            "Epoch 91/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.1954 - accuracy: 0.4830\n",
            "Epoch 91: val_loss improved from 2.21773 to 2.19177, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.1956 - accuracy: 0.4829 - val_loss: 2.1918 - val_accuracy: 0.4855\n",
            "Epoch 92/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.1700 - accuracy: 0.4852\n",
            "Epoch 92: val_loss improved from 2.19177 to 2.15710, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.1696 - accuracy: 0.4855 - val_loss: 2.1571 - val_accuracy: 0.4970\n",
            "Epoch 93/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.1437 - accuracy: 0.4862\n",
            "Epoch 93: val_loss improved from 2.15710 to 2.13459, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.1437 - accuracy: 0.4860 - val_loss: 2.1346 - val_accuracy: 0.4962\n",
            "Epoch 94/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 2.1082 - accuracy: 0.4918\n",
            "Epoch 94: val_loss improved from 2.13459 to 2.11431, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.1087 - accuracy: 0.4919 - val_loss: 2.1143 - val_accuracy: 0.4955\n",
            "Epoch 95/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.0878 - accuracy: 0.4904\n",
            "Epoch 95: val_loss improved from 2.11431 to 2.10230, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.0878 - accuracy: 0.4903 - val_loss: 2.1023 - val_accuracy: 0.4907\n",
            "Epoch 96/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 2.0661 - accuracy: 0.4889\n",
            "Epoch 96: val_loss improved from 2.10230 to 2.06522, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.0661 - accuracy: 0.4889 - val_loss: 2.0652 - val_accuracy: 0.4995\n",
            "Epoch 97/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 2.0347 - accuracy: 0.4939\n",
            "Epoch 97: val_loss improved from 2.06522 to 2.05011, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.0348 - accuracy: 0.4939 - val_loss: 2.0501 - val_accuracy: 0.4939\n",
            "Epoch 98/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 2.0197 - accuracy: 0.4930\n",
            "Epoch 98: val_loss improved from 2.05011 to 2.04112, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.0192 - accuracy: 0.4933 - val_loss: 2.0411 - val_accuracy: 0.4938\n",
            "Epoch 99/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.9891 - accuracy: 0.5006\n",
            "Epoch 99: val_loss improved from 2.04112 to 2.01583, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.9883 - accuracy: 0.5008 - val_loss: 2.0158 - val_accuracy: 0.4987\n",
            "Epoch 100/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.9760 - accuracy: 0.5002\n",
            "Epoch 100: val_loss improved from 2.01583 to 2.00150, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.9758 - accuracy: 0.4998 - val_loss: 2.0015 - val_accuracy: 0.4933\n",
            "Epoch 101/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.9507 - accuracy: 0.5029\n",
            "Epoch 101: val_loss improved from 2.00150 to 1.97482, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.9507 - accuracy: 0.5029 - val_loss: 1.9748 - val_accuracy: 0.4983\n",
            "Epoch 102/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.9296 - accuracy: 0.5082\n",
            "Epoch 102: val_loss improved from 1.97482 to 1.95634, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.9297 - accuracy: 0.5081 - val_loss: 1.9563 - val_accuracy: 0.5030\n",
            "Epoch 103/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.9132 - accuracy: 0.5073\n",
            "Epoch 103: val_loss did not improve from 1.95634\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.9127 - accuracy: 0.5072 - val_loss: 1.9585 - val_accuracy: 0.4955\n",
            "Epoch 104/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.8892 - accuracy: 0.5100\n",
            "Epoch 104: val_loss improved from 1.95634 to 1.93434, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.8889 - accuracy: 0.5101 - val_loss: 1.9343 - val_accuracy: 0.4992\n",
            "Epoch 105/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.8670 - accuracy: 0.5112\n",
            "Epoch 105: val_loss improved from 1.93434 to 1.92794, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.8669 - accuracy: 0.5109 - val_loss: 1.9279 - val_accuracy: 0.5011\n",
            "Epoch 106/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.8531 - accuracy: 0.5155\n",
            "Epoch 106: val_loss improved from 1.92794 to 1.90113, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.8526 - accuracy: 0.5158 - val_loss: 1.9011 - val_accuracy: 0.5005\n",
            "Epoch 107/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.8430 - accuracy: 0.5124\n",
            "Epoch 107: val_loss improved from 1.90113 to 1.88184, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.8428 - accuracy: 0.5126 - val_loss: 1.8818 - val_accuracy: 0.5071\n",
            "Epoch 108/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.8190 - accuracy: 0.5175\n",
            "Epoch 108: val_loss improved from 1.88184 to 1.87497, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.8191 - accuracy: 0.5176 - val_loss: 1.8750 - val_accuracy: 0.5073\n",
            "Epoch 109/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.8101 - accuracy: 0.5177\n",
            "Epoch 109: val_loss improved from 1.87497 to 1.86315, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.8103 - accuracy: 0.5177 - val_loss: 1.8631 - val_accuracy: 0.5017\n",
            "Epoch 110/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.7885 - accuracy: 0.5181\n",
            "Epoch 110: val_loss improved from 1.86315 to 1.85578, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7883 - accuracy: 0.5181 - val_loss: 1.8558 - val_accuracy: 0.5028\n",
            "Epoch 111/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.7770 - accuracy: 0.5221\n",
            "Epoch 111: val_loss did not improve from 1.85578\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.7767 - accuracy: 0.5220 - val_loss: 1.8585 - val_accuracy: 0.4967\n",
            "Epoch 112/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.7618 - accuracy: 0.5273\n",
            "Epoch 112: val_loss improved from 1.85578 to 1.82193, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7617 - accuracy: 0.5272 - val_loss: 1.8219 - val_accuracy: 0.5084\n",
            "Epoch 113/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.7443 - accuracy: 0.5247\n",
            "Epoch 113: val_loss improved from 1.82193 to 1.81806, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7442 - accuracy: 0.5247 - val_loss: 1.8181 - val_accuracy: 0.5081\n",
            "Epoch 114/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.7264 - accuracy: 0.5316\n",
            "Epoch 114: val_loss improved from 1.81806 to 1.80438, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7271 - accuracy: 0.5314 - val_loss: 1.8044 - val_accuracy: 0.5052\n",
            "Epoch 115/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.7172 - accuracy: 0.5320\n",
            "Epoch 115: val_loss improved from 1.80438 to 1.80411, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.7173 - accuracy: 0.5322 - val_loss: 1.8041 - val_accuracy: 0.5074\n",
            "Epoch 116/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.7014 - accuracy: 0.5367\n",
            "Epoch 116: val_loss improved from 1.80411 to 1.78590, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.7006 - accuracy: 0.5369 - val_loss: 1.7859 - val_accuracy: 0.5134\n",
            "Epoch 117/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.6989 - accuracy: 0.5315\n",
            "Epoch 117: val_loss did not improve from 1.78590\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.6994 - accuracy: 0.5314 - val_loss: 1.7908 - val_accuracy: 0.5078\n",
            "Epoch 118/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.6852 - accuracy: 0.5345\n",
            "Epoch 118: val_loss improved from 1.78590 to 1.78299, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.6855 - accuracy: 0.5344 - val_loss: 1.7830 - val_accuracy: 0.5086\n",
            "Epoch 119/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.6758 - accuracy: 0.5352\n",
            "Epoch 119: val_loss improved from 1.78299 to 1.76072, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.6757 - accuracy: 0.5353 - val_loss: 1.7607 - val_accuracy: 0.5125\n",
            "Epoch 120/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.6650 - accuracy: 0.5326\n",
            "Epoch 120: val_loss improved from 1.76072 to 1.75612, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.6655 - accuracy: 0.5326 - val_loss: 1.7561 - val_accuracy: 0.5108\n",
            "Epoch 121/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.6445 - accuracy: 0.5417\n",
            "Epoch 121: val_loss improved from 1.75612 to 1.74082, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.6437 - accuracy: 0.5418 - val_loss: 1.7408 - val_accuracy: 0.5123\n",
            "Epoch 122/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.6334 - accuracy: 0.5452\n",
            "Epoch 122: val_loss did not improve from 1.74082\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.6334 - accuracy: 0.5452 - val_loss: 1.7705 - val_accuracy: 0.5039\n",
            "Epoch 123/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.6285 - accuracy: 0.5436\n",
            "Epoch 123: val_loss did not improve from 1.74082\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.6288 - accuracy: 0.5435 - val_loss: 1.7434 - val_accuracy: 0.5105\n",
            "Epoch 124/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.6191 - accuracy: 0.5447\n",
            "Epoch 124: val_loss improved from 1.74082 to 1.73489, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.6189 - accuracy: 0.5448 - val_loss: 1.7349 - val_accuracy: 0.5071\n",
            "Epoch 125/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.6138 - accuracy: 0.5426\n",
            "Epoch 125: val_loss improved from 1.73489 to 1.72432, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.6136 - accuracy: 0.5426 - val_loss: 1.7243 - val_accuracy: 0.5120\n",
            "Epoch 126/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.6039 - accuracy: 0.5478\n",
            "Epoch 126: val_loss improved from 1.72432 to 1.70566, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.6043 - accuracy: 0.5473 - val_loss: 1.7057 - val_accuracy: 0.5147\n",
            "Epoch 127/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.5877 - accuracy: 0.5494\n",
            "Epoch 127: val_loss did not improve from 1.70566\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5876 - accuracy: 0.5495 - val_loss: 1.7067 - val_accuracy: 0.5152\n",
            "Epoch 128/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.5786 - accuracy: 0.5569\n",
            "Epoch 128: val_loss improved from 1.70566 to 1.69407, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5789 - accuracy: 0.5569 - val_loss: 1.6941 - val_accuracy: 0.5128\n",
            "Epoch 129/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.5719 - accuracy: 0.5491\n",
            "Epoch 129: val_loss did not improve from 1.69407\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.5708 - accuracy: 0.5498 - val_loss: 1.7028 - val_accuracy: 0.5122\n",
            "Epoch 130/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.5655 - accuracy: 0.5521\n",
            "Epoch 130: val_loss improved from 1.69407 to 1.68340, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5663 - accuracy: 0.5522 - val_loss: 1.6834 - val_accuracy: 0.5141\n",
            "Epoch 131/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.5554 - accuracy: 0.5587\n",
            "Epoch 131: val_loss improved from 1.68340 to 1.67933, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.5553 - accuracy: 0.5587 - val_loss: 1.6793 - val_accuracy: 0.5160\n",
            "Epoch 132/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.5456 - accuracy: 0.5556\n",
            "Epoch 132: val_loss improved from 1.67933 to 1.67925, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5463 - accuracy: 0.5555 - val_loss: 1.6792 - val_accuracy: 0.5161\n",
            "Epoch 133/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.5432 - accuracy: 0.5579\n",
            "Epoch 133: val_loss improved from 1.67925 to 1.67518, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5431 - accuracy: 0.5579 - val_loss: 1.6752 - val_accuracy: 0.5224\n",
            "Epoch 134/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.5341 - accuracy: 0.5562\n",
            "Epoch 134: val_loss did not improve from 1.67518\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.5341 - accuracy: 0.5562 - val_loss: 1.6875 - val_accuracy: 0.5141\n",
            "Epoch 135/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.5256 - accuracy: 0.5652\n",
            "Epoch 135: val_loss did not improve from 1.67518\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5257 - accuracy: 0.5650 - val_loss: 1.6820 - val_accuracy: 0.5140\n",
            "Epoch 136/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.5233 - accuracy: 0.5619\n",
            "Epoch 136: val_loss improved from 1.67518 to 1.67293, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.5233 - accuracy: 0.5619 - val_loss: 1.6729 - val_accuracy: 0.5206\n",
            "Epoch 137/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.5171 - accuracy: 0.5649\n",
            "Epoch 137: val_loss improved from 1.67293 to 1.66109, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5163 - accuracy: 0.5652 - val_loss: 1.6611 - val_accuracy: 0.5152\n",
            "Epoch 138/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.5074 - accuracy: 0.5660\n",
            "Epoch 138: val_loss did not improve from 1.66109\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5071 - accuracy: 0.5662 - val_loss: 1.6712 - val_accuracy: 0.5159\n",
            "Epoch 139/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.4997 - accuracy: 0.5658\n",
            "Epoch 139: val_loss did not improve from 1.66109\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.4999 - accuracy: 0.5657 - val_loss: 1.6621 - val_accuracy: 0.5159\n",
            "Epoch 140/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.4946 - accuracy: 0.5671\n",
            "Epoch 140: val_loss did not improve from 1.66109\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4940 - accuracy: 0.5676 - val_loss: 1.6639 - val_accuracy: 0.5192\n",
            "Epoch 141/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.4936 - accuracy: 0.5677\n",
            "Epoch 141: val_loss improved from 1.66109 to 1.65960, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.4940 - accuracy: 0.5674 - val_loss: 1.6596 - val_accuracy: 0.5184\n",
            "Epoch 142/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.4772 - accuracy: 0.5744\n",
            "Epoch 142: val_loss improved from 1.65960 to 1.64193, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4782 - accuracy: 0.5740 - val_loss: 1.6419 - val_accuracy: 0.5249\n",
            "Epoch 143/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.4783 - accuracy: 0.5730\n",
            "Epoch 143: val_loss did not improve from 1.64193\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4785 - accuracy: 0.5730 - val_loss: 1.6484 - val_accuracy: 0.5205\n",
            "Epoch 144/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.4720 - accuracy: 0.5734\n",
            "Epoch 144: val_loss did not improve from 1.64193\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.4718 - accuracy: 0.5731 - val_loss: 1.6510 - val_accuracy: 0.5154\n",
            "Epoch 145/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.4632 - accuracy: 0.5774\n",
            "Epoch 145: val_loss did not improve from 1.64193\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4628 - accuracy: 0.5776 - val_loss: 1.6451 - val_accuracy: 0.5218\n",
            "Epoch 146/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.4603 - accuracy: 0.5780\n",
            "Epoch 146: val_loss did not improve from 1.64193\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.4600 - accuracy: 0.5781 - val_loss: 1.7618 - val_accuracy: 0.4990\n",
            "Epoch 147/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.4595 - accuracy: 0.5768\n",
            "Epoch 147: val_loss did not improve from 1.64193\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4590 - accuracy: 0.5770 - val_loss: 1.6420 - val_accuracy: 0.5213\n",
            "Epoch 148/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.4521 - accuracy: 0.5831\n",
            "Epoch 148: val_loss did not improve from 1.64193\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.4526 - accuracy: 0.5828 - val_loss: 1.6444 - val_accuracy: 0.5183\n",
            "Epoch 149/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.4469 - accuracy: 0.5832\n",
            "Epoch 149: val_loss did not improve from 1.64193\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4467 - accuracy: 0.5833 - val_loss: 1.6428 - val_accuracy: 0.5180\n",
            "Epoch 150/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.4406 - accuracy: 0.5841\n",
            "Epoch 150: val_loss improved from 1.64193 to 1.62960, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.4406 - accuracy: 0.5841 - val_loss: 1.6296 - val_accuracy: 0.5276\n",
            "Epoch 151/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.4396 - accuracy: 0.5851\n",
            "Epoch 151: val_loss did not improve from 1.62960\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.4401 - accuracy: 0.5849 - val_loss: 1.6463 - val_accuracy: 0.5212\n",
            "Epoch 152/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.4360 - accuracy: 0.5864\n",
            "Epoch 152: val_loss did not improve from 1.62960\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4362 - accuracy: 0.5864 - val_loss: 1.6362 - val_accuracy: 0.5217\n",
            "Epoch 153/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.4255 - accuracy: 0.5863\n",
            "Epoch 153: val_loss improved from 1.62960 to 1.62378, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.4260 - accuracy: 0.5863 - val_loss: 1.6238 - val_accuracy: 0.5251\n",
            "Epoch 154/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.4265 - accuracy: 0.5882\n",
            "Epoch 154: val_loss did not improve from 1.62378\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4263 - accuracy: 0.5883 - val_loss: 1.6252 - val_accuracy: 0.5172\n",
            "Epoch 155/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.4173 - accuracy: 0.5935\n",
            "Epoch 155: val_loss did not improve from 1.62378\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4175 - accuracy: 0.5934 - val_loss: 1.6796 - val_accuracy: 0.5078\n",
            "Epoch 156/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.4177 - accuracy: 0.5918\n",
            "Epoch 156: val_loss improved from 1.62378 to 1.61688, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.4175 - accuracy: 0.5919 - val_loss: 1.6169 - val_accuracy: 0.5239\n",
            "Epoch 157/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.4137 - accuracy: 0.5895\n",
            "Epoch 157: val_loss did not improve from 1.61688\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4137 - accuracy: 0.5893 - val_loss: 1.6190 - val_accuracy: 0.5262\n",
            "Epoch 158/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.4031 - accuracy: 0.5945\n",
            "Epoch 158: val_loss did not improve from 1.61688\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.4031 - accuracy: 0.5945 - val_loss: 1.6200 - val_accuracy: 0.5232\n",
            "Epoch 159/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.4010 - accuracy: 0.5931\n",
            "Epoch 159: val_loss did not improve from 1.61688\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4010 - accuracy: 0.5932 - val_loss: 1.6636 - val_accuracy: 0.5055\n",
            "Epoch 160/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.3988 - accuracy: 0.5953\n",
            "Epoch 160: val_loss did not improve from 1.61688\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3987 - accuracy: 0.5953 - val_loss: 1.6554 - val_accuracy: 0.5188\n",
            "Epoch 161/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.3927 - accuracy: 0.5996\n",
            "Epoch 161: val_loss did not improve from 1.61688\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3924 - accuracy: 0.5994 - val_loss: 1.6322 - val_accuracy: 0.5193\n",
            "Epoch 162/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.3897 - accuracy: 0.5991\n",
            "Epoch 162: val_loss did not improve from 1.61688\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3906 - accuracy: 0.5988 - val_loss: 1.6237 - val_accuracy: 0.5202\n",
            "Epoch 163/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.3808 - accuracy: 0.6004\n",
            "Epoch 163: val_loss improved from 1.61688 to 1.61314, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.3817 - accuracy: 0.6002 - val_loss: 1.6131 - val_accuracy: 0.5301\n",
            "Epoch 164/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.3831 - accuracy: 0.6016\n",
            "Epoch 164: val_loss did not improve from 1.61314\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3827 - accuracy: 0.6016 - val_loss: 1.6375 - val_accuracy: 0.5241\n",
            "Epoch 165/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.3876 - accuracy: 0.5999\n",
            "Epoch 165: val_loss did not improve from 1.61314\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3875 - accuracy: 0.5999 - val_loss: 1.6162 - val_accuracy: 0.5328\n",
            "Epoch 166/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.3817 - accuracy: 0.6031\n",
            "Epoch 166: val_loss did not improve from 1.61314\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3817 - accuracy: 0.6033 - val_loss: 1.6254 - val_accuracy: 0.5245\n",
            "Epoch 167/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.3821 - accuracy: 0.6048\n",
            "Epoch 167: val_loss did not improve from 1.61314\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3820 - accuracy: 0.6048 - val_loss: 1.6422 - val_accuracy: 0.5183\n",
            "Epoch 168/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.3736 - accuracy: 0.6063\n",
            "Epoch 168: val_loss did not improve from 1.61314\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.3736 - accuracy: 0.6063 - val_loss: 1.6219 - val_accuracy: 0.5270\n",
            "Epoch 169/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.3708 - accuracy: 0.6058\n",
            "Epoch 169: val_loss improved from 1.61314 to 1.61275, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3711 - accuracy: 0.6056 - val_loss: 1.6127 - val_accuracy: 0.5308\n",
            "Epoch 170/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.3752 - accuracy: 0.6054\n",
            "Epoch 170: val_loss improved from 1.61275 to 1.60752, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3751 - accuracy: 0.6056 - val_loss: 1.6075 - val_accuracy: 0.5278\n",
            "Epoch 171/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3674 - accuracy: 0.6056\n",
            "Epoch 171: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3674 - accuracy: 0.6057 - val_loss: 1.6264 - val_accuracy: 0.5254\n",
            "Epoch 172/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.3680 - accuracy: 0.6083\n",
            "Epoch 172: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3685 - accuracy: 0.6081 - val_loss: 1.6432 - val_accuracy: 0.5207\n",
            "Epoch 173/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.3638 - accuracy: 0.6096\n",
            "Epoch 173: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 1.3638 - accuracy: 0.6096 - val_loss: 1.6167 - val_accuracy: 0.5275\n",
            "Epoch 174/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.3617 - accuracy: 0.6092\n",
            "Epoch 174: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3615 - accuracy: 0.6094 - val_loss: 1.6289 - val_accuracy: 0.5200\n",
            "Epoch 175/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.3615 - accuracy: 0.6122\n",
            "Epoch 175: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.3614 - accuracy: 0.6122 - val_loss: 1.6088 - val_accuracy: 0.5321\n",
            "Epoch 176/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.3507 - accuracy: 0.6104\n",
            "Epoch 176: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3503 - accuracy: 0.6106 - val_loss: 1.6307 - val_accuracy: 0.5230\n",
            "Epoch 177/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.3510 - accuracy: 0.6107\n",
            "Epoch 177: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3506 - accuracy: 0.6109 - val_loss: 1.6287 - val_accuracy: 0.5270\n",
            "Epoch 178/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.3451 - accuracy: 0.6152\n",
            "Epoch 178: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3459 - accuracy: 0.6152 - val_loss: 1.6199 - val_accuracy: 0.5312\n",
            "Epoch 179/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.3444 - accuracy: 0.6156\n",
            "Epoch 179: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3453 - accuracy: 0.6154 - val_loss: 1.6392 - val_accuracy: 0.5219\n",
            "Epoch 180/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.3517 - accuracy: 0.6121\n",
            "Epoch 180: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3525 - accuracy: 0.6115 - val_loss: 1.6893 - val_accuracy: 0.5141\n",
            "Epoch 181/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.3359 - accuracy: 0.6194\n",
            "Epoch 181: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3353 - accuracy: 0.6193 - val_loss: 1.6263 - val_accuracy: 0.5272\n",
            "Epoch 182/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3398 - accuracy: 0.6183\n",
            "Epoch 182: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3399 - accuracy: 0.6183 - val_loss: 1.6144 - val_accuracy: 0.5321\n",
            "Epoch 183/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.3351 - accuracy: 0.6218\n",
            "Epoch 183: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3357 - accuracy: 0.6218 - val_loss: 1.6285 - val_accuracy: 0.5282\n",
            "Epoch 184/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.3361 - accuracy: 0.6174\n",
            "Epoch 184: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3365 - accuracy: 0.6173 - val_loss: 1.6343 - val_accuracy: 0.5228\n",
            "Epoch 185/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.3373 - accuracy: 0.6219\n",
            "Epoch 185: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3379 - accuracy: 0.6216 - val_loss: 1.6285 - val_accuracy: 0.5236\n",
            "Epoch 186/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.3339 - accuracy: 0.6207\n",
            "Epoch 186: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3343 - accuracy: 0.6206 - val_loss: 1.6384 - val_accuracy: 0.5231\n",
            "Epoch 187/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.3310 - accuracy: 0.6222\n",
            "Epoch 187: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3310 - accuracy: 0.6221 - val_loss: 1.6287 - val_accuracy: 0.5311\n",
            "Epoch 188/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.3260 - accuracy: 0.6261\n",
            "Epoch 188: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.3259 - accuracy: 0.6261 - val_loss: 1.6189 - val_accuracy: 0.5322\n",
            "Epoch 189/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3245 - accuracy: 0.6277\n",
            "Epoch 189: val_loss did not improve from 1.60752\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.3246 - accuracy: 0.6278 - val_loss: 1.6160 - val_accuracy: 0.5272\n",
            "Epoch 190/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3200 - accuracy: 0.6288\n",
            "Epoch 190: val_loss did not improve from 1.60752\n",
            "Restoring model weights from the end of the best epoch: 170.\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3199 - accuracy: 0.6288 - val_loss: 1.6774 - val_accuracy: 0.5179\n",
            "Epoch 190: early stopping\n",
            "Training Runtime: 980.60 seconds\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5925 - accuracy: 0.5408\n",
            "Test Loss: 1.5925\n",
            "Test Accuracy: 0.5408\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10  # 10-class problem\n",
        "drop_rate = 0.5\n",
        "# Define model\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(32,32,3)))\n",
        "model.add(layers.Dense(1000, kernel_initializer='lecun_normal', kernel_regularizer='l2', activation='relu'))\n",
        "model.add(layers.Dropout(drop_rate))\n",
        "model.add(layers.Dense(1000, kernel_initializer='lecun_normal', kernel_regularizer='l2', activation='relu'))\n",
        "model.add(layers.Dropout(drop_rate))\n",
        "model.add(layers.Dense(100, kernel_initializer='lecun_normal', activation='relu'))\n",
        "model.add(layers.Dropout(drop_rate))\n",
        "model.add(layers.Dense(100, kernel_initializer='lecun_normal', activation='relu'))\n",
        "model.add(layers.Dropout(drop_rate))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create an SGD optimizer instance with the desired learning rate\n",
        "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# Train the model with callbacks\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(X_train_norm, y_train, epochs=500, batch_size=32, validation_data=(X_val_norm, y_val), callbacks=[checkpoint, early_stopping])\n",
        "\n",
        "end_time = time.time()\n",
        "# Calculate the training runtime\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training Runtime: {training_time:.2f} seconds\")\n",
        "\n",
        "# Load the best model weights\n",
        "model.load_weights(\"best_model.h5\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_norm, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4\n",
        "\n",
        "By now, we have been using the same parameters and changing only the architectures of the models. We realize that the `Model 2` is suitable for our problem, we we pick it up and use to tune parameters"
      ],
      "metadata": {
        "id": "rqS952TcHPih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10  # 10-class problem\n",
        "drop_rate = 0.5\n",
        "# Define model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(32,32,3)))\n",
        "model.add(layers.Dense(1000, kernel_initializer='lecun_normal', kernel_regularizer='l2', activation='relu'))\n",
        "model.add(layers.Dropout(drop_rate))\n",
        "model.add(layers.Dense(1000, kernel_initializer='lecun_normal', kernel_regularizer='l2', activation='relu'))\n",
        "model.add(layers.Dropout(drop_rate))\n",
        "model.add(layers.Dense(100, kernel_initializer='lecun_normal', kernel_regularizer='l2', activation='relu'))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "learning_rate = 0.0005\n",
        "\n",
        "# Create an SGD optimizer instance with the desired learning rate\n",
        "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# Train the model with callbacks\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(X_train_norm, y_train, epochs=500, batch_size=32, validation_data=(X_val_norm, y_val), callbacks=[checkpoint, early_stopping])\n",
        "\n",
        "end_time = time.time()\n",
        "# Calculate the training runtime\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training Runtime: {training_time:.2f} seconds\")\n",
        "\n",
        "# Load the best model weights\n",
        "model.load_weights(\"best_model.h5\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_norm, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAoCKPPRHsRe",
        "outputId": "ee3d5faf-a2e9-45c0-e036-fb024a5dcb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 23.1208 - accuracy: 0.1564\n",
            "Epoch 1: val_loss improved from inf to 22.67519, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 5ms/step - loss: 23.1189 - accuracy: 0.1567 - val_loss: 22.6752 - val_accuracy: 0.2531\n",
            "Epoch 2/500\n",
            " 11/938 [..............................] - ETA: 4s - loss: 22.8029 - accuracy: 0.1932"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "925/938 [============================>.] - ETA: 0s - loss: 22.5489 - accuracy: 0.2197\n",
            "Epoch 2: val_loss improved from 22.67519 to 22.20671, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 22.5465 - accuracy: 0.2196 - val_loss: 22.2067 - val_accuracy: 0.2843\n",
            "Epoch 3/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 22.0889 - accuracy: 0.2498\n",
            "Epoch 3: val_loss improved from 22.20671 to 21.77016, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 22.0880 - accuracy: 0.2496 - val_loss: 21.7702 - val_accuracy: 0.3080\n",
            "Epoch 4/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 21.6634 - accuracy: 0.2705\n",
            "Epoch 4: val_loss improved from 21.77016 to 21.35847, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 21.6612 - accuracy: 0.2704 - val_loss: 21.3585 - val_accuracy: 0.3262\n",
            "Epoch 5/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 21.2570 - accuracy: 0.2889\n",
            "Epoch 5: val_loss improved from 21.35847 to 20.96187, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 21.2547 - accuracy: 0.2889 - val_loss: 20.9619 - val_accuracy: 0.3389\n",
            "Epoch 6/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 20.8635 - accuracy: 0.3011\n",
            "Epoch 6: val_loss improved from 20.96187 to 20.57852, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 20.8625 - accuracy: 0.3008 - val_loss: 20.5785 - val_accuracy: 0.3527\n",
            "Epoch 7/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 20.4822 - accuracy: 0.3162\n",
            "Epoch 7: val_loss improved from 20.57852 to 20.20789, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 20.4805 - accuracy: 0.3166 - val_loss: 20.2079 - val_accuracy: 0.3598\n",
            "Epoch 8/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 20.1161 - accuracy: 0.3252\n",
            "Epoch 8: val_loss improved from 20.20789 to 19.84719, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 20.1146 - accuracy: 0.3253 - val_loss: 19.8472 - val_accuracy: 0.3683\n",
            "Epoch 9/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 19.7535 - accuracy: 0.3303\n",
            "Epoch 9: val_loss improved from 19.84719 to 19.49465, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 19.7530 - accuracy: 0.3302 - val_loss: 19.4946 - val_accuracy: 0.3736\n",
            "Epoch 10/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 19.4110 - accuracy: 0.3339\n",
            "Epoch 10: val_loss improved from 19.49465 to 19.14967, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 19.4102 - accuracy: 0.3339 - val_loss: 19.1497 - val_accuracy: 0.3813\n",
            "Epoch 11/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 19.0643 - accuracy: 0.3438\n",
            "Epoch 11: val_loss improved from 19.14967 to 18.81483, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 19.0640 - accuracy: 0.3437 - val_loss: 18.8148 - val_accuracy: 0.3868\n",
            "Epoch 12/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 18.7322 - accuracy: 0.3492\n",
            "Epoch 12: val_loss improved from 18.81483 to 18.48612, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18.7321 - accuracy: 0.3490 - val_loss: 18.4861 - val_accuracy: 0.3928\n",
            "Epoch 13/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 18.4065 - accuracy: 0.3556\n",
            "Epoch 13: val_loss improved from 18.48612 to 18.16360, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 18.4057 - accuracy: 0.3553 - val_loss: 18.1636 - val_accuracy: 0.3954\n",
            "Epoch 14/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 18.0854 - accuracy: 0.3563\n",
            "Epoch 14: val_loss improved from 18.16360 to 17.84794, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18.0845 - accuracy: 0.3566 - val_loss: 17.8479 - val_accuracy: 0.3985\n",
            "Epoch 15/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 17.7687 - accuracy: 0.3654\n",
            "Epoch 15: val_loss improved from 17.84794 to 17.54004, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17.7685 - accuracy: 0.3655 - val_loss: 17.5400 - val_accuracy: 0.4027\n",
            "Epoch 16/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 17.4615 - accuracy: 0.3699\n",
            "Epoch 16: val_loss improved from 17.54004 to 17.23780, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 17.4602 - accuracy: 0.3702 - val_loss: 17.2378 - val_accuracy: 0.4040\n",
            "Epoch 17/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 17.1582 - accuracy: 0.3750\n",
            "Epoch 17: val_loss improved from 17.23780 to 16.94226, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 17.1582 - accuracy: 0.3750 - val_loss: 16.9423 - val_accuracy: 0.4079\n",
            "Epoch 18/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 16.8648 - accuracy: 0.3743\n",
            "Epoch 18: val_loss improved from 16.94226 to 16.65025, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 16.8644 - accuracy: 0.3742 - val_loss: 16.6503 - val_accuracy: 0.4126\n",
            "Epoch 19/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 16.5752 - accuracy: 0.3808\n",
            "Epoch 19: val_loss improved from 16.65025 to 16.36368, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16.5751 - accuracy: 0.3808 - val_loss: 16.3637 - val_accuracy: 0.4176\n",
            "Epoch 20/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 16.2932 - accuracy: 0.3864\n",
            "Epoch 20: val_loss improved from 16.36368 to 16.08640, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16.2927 - accuracy: 0.3863 - val_loss: 16.0864 - val_accuracy: 0.4200\n",
            "Epoch 21/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 16.0196 - accuracy: 0.3877\n",
            "Epoch 21: val_loss improved from 16.08640 to 15.81320, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 16.0184 - accuracy: 0.3875 - val_loss: 15.8132 - val_accuracy: 0.4209\n",
            "Epoch 22/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 15.7426 - accuracy: 0.3941\n",
            "Epoch 22: val_loss improved from 15.81320 to 15.54577, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15.7422 - accuracy: 0.3941 - val_loss: 15.5458 - val_accuracy: 0.4204\n",
            "Epoch 23/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 15.4806 - accuracy: 0.3942\n",
            "Epoch 23: val_loss improved from 15.54577 to 15.28191, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15.4798 - accuracy: 0.3943 - val_loss: 15.2819 - val_accuracy: 0.4262\n",
            "Epoch 24/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 15.2170 - accuracy: 0.3954\n",
            "Epoch 24: val_loss improved from 15.28191 to 15.02320, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 15.2170 - accuracy: 0.3955 - val_loss: 15.0232 - val_accuracy: 0.4273\n",
            "Epoch 25/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 14.9555 - accuracy: 0.3974\n",
            "Epoch 25: val_loss improved from 15.02320 to 14.77296, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14.9555 - accuracy: 0.3974 - val_loss: 14.7730 - val_accuracy: 0.4298\n",
            "Epoch 26/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 14.7055 - accuracy: 0.4035\n",
            "Epoch 26: val_loss improved from 14.77296 to 14.52205, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 14.7043 - accuracy: 0.4035 - val_loss: 14.5220 - val_accuracy: 0.4307\n",
            "Epoch 27/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 14.4610 - accuracy: 0.4084\n",
            "Epoch 27: val_loss improved from 14.52205 to 14.27918, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14.4607 - accuracy: 0.4081 - val_loss: 14.2792 - val_accuracy: 0.4341\n",
            "Epoch 28/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 14.2162 - accuracy: 0.4070\n",
            "Epoch 28: val_loss improved from 14.27918 to 14.04089, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 14.2153 - accuracy: 0.4066 - val_loss: 14.0409 - val_accuracy: 0.4344\n",
            "Epoch 29/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 13.9802 - accuracy: 0.4125\n",
            "Epoch 29: val_loss improved from 14.04089 to 13.80851, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 13.9790 - accuracy: 0.4126 - val_loss: 13.8085 - val_accuracy: 0.4366\n",
            "Epoch 30/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 13.7449 - accuracy: 0.4163\n",
            "Epoch 30: val_loss improved from 13.80851 to 13.57979, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13.7436 - accuracy: 0.4166 - val_loss: 13.5798 - val_accuracy: 0.4372\n",
            "Epoch 31/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 13.5192 - accuracy: 0.4164\n",
            "Epoch 31: val_loss improved from 13.57979 to 13.35362, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13.5177 - accuracy: 0.4157 - val_loss: 13.3536 - val_accuracy: 0.4395\n",
            "Epoch 32/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 13.2920 - accuracy: 0.4153\n",
            "Epoch 32: val_loss improved from 13.35362 to 13.13153, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13.2912 - accuracy: 0.4154 - val_loss: 13.1315 - val_accuracy: 0.4399\n",
            "Epoch 33/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 13.0728 - accuracy: 0.4237\n",
            "Epoch 33: val_loss improved from 13.13153 to 12.91515, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13.0725 - accuracy: 0.4238 - val_loss: 12.9152 - val_accuracy: 0.4403\n",
            "Epoch 34/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 12.8587 - accuracy: 0.4211\n",
            "Epoch 34: val_loss improved from 12.91515 to 12.70218, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 12.8578 - accuracy: 0.4211 - val_loss: 12.7022 - val_accuracy: 0.4418\n",
            "Epoch 35/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 12.6455 - accuracy: 0.4240\n",
            "Epoch 35: val_loss improved from 12.70218 to 12.49450, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 12.6447 - accuracy: 0.4237 - val_loss: 12.4945 - val_accuracy: 0.4435\n",
            "Epoch 36/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 12.4401 - accuracy: 0.4261\n",
            "Epoch 36: val_loss improved from 12.49450 to 12.28962, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 12.4391 - accuracy: 0.4262 - val_loss: 12.2896 - val_accuracy: 0.4439\n",
            "Epoch 37/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 12.2281 - accuracy: 0.4317\n",
            "Epoch 37: val_loss improved from 12.28962 to 12.08795, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 12.2277 - accuracy: 0.4316 - val_loss: 12.0879 - val_accuracy: 0.4474\n",
            "Epoch 38/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 12.0344 - accuracy: 0.4278\n",
            "Epoch 38: val_loss improved from 12.08795 to 11.89245, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 12.0341 - accuracy: 0.4276 - val_loss: 11.8924 - val_accuracy: 0.4479\n",
            "Epoch 39/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 11.8359 - accuracy: 0.4328\n",
            "Epoch 39: val_loss improved from 11.89245 to 11.70165, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 11.8347 - accuracy: 0.4331 - val_loss: 11.7017 - val_accuracy: 0.4467\n",
            "Epoch 40/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 11.6443 - accuracy: 0.4328\n",
            "Epoch 40: val_loss improved from 11.70165 to 11.50760, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 11.6435 - accuracy: 0.4327 - val_loss: 11.5076 - val_accuracy: 0.4493\n",
            "Epoch 41/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 11.4538 - accuracy: 0.4388\n",
            "Epoch 41: val_loss improved from 11.50760 to 11.32147, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 11.4536 - accuracy: 0.4387 - val_loss: 11.3215 - val_accuracy: 0.4518\n",
            "Epoch 42/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 11.2680 - accuracy: 0.4397\n",
            "Epoch 42: val_loss improved from 11.32147 to 11.14092, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 11.2676 - accuracy: 0.4392 - val_loss: 11.1409 - val_accuracy: 0.4521\n",
            "Epoch 43/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 11.0886 - accuracy: 0.4413\n",
            "Epoch 43: val_loss improved from 11.14092 to 10.96065, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 11.0877 - accuracy: 0.4415 - val_loss: 10.9607 - val_accuracy: 0.4539\n",
            "Epoch 44/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 10.9069 - accuracy: 0.4461\n",
            "Epoch 44: val_loss improved from 10.96065 to 10.78460, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 10.9050 - accuracy: 0.4463 - val_loss: 10.7846 - val_accuracy: 0.4549\n",
            "Epoch 45/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 10.7308 - accuracy: 0.4432\n",
            "Epoch 45: val_loss improved from 10.78460 to 10.61211, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 10.7307 - accuracy: 0.4432 - val_loss: 10.6121 - val_accuracy: 0.4554\n",
            "Epoch 46/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 10.5591 - accuracy: 0.4450\n",
            "Epoch 46: val_loss improved from 10.61211 to 10.44394, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 10.5583 - accuracy: 0.4449 - val_loss: 10.4439 - val_accuracy: 0.4585\n",
            "Epoch 47/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 10.3912 - accuracy: 0.4507\n",
            "Epoch 47: val_loss improved from 10.44394 to 10.27555, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 10.3910 - accuracy: 0.4507 - val_loss: 10.2756 - val_accuracy: 0.4586\n",
            "Epoch 48/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 10.2291 - accuracy: 0.4486\n",
            "Epoch 48: val_loss improved from 10.27555 to 10.11433, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 10.2277 - accuracy: 0.4488 - val_loss: 10.1143 - val_accuracy: 0.4592\n",
            "Epoch 49/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 10.0629 - accuracy: 0.4512\n",
            "Epoch 49: val_loss improved from 10.11433 to 9.95532, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 10.0625 - accuracy: 0.4511 - val_loss: 9.9553 - val_accuracy: 0.4604\n",
            "Epoch 50/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 9.9031 - accuracy: 0.4505\n",
            "Epoch 50: val_loss improved from 9.95532 to 9.79722, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 9.9030 - accuracy: 0.4507 - val_loss: 9.7972 - val_accuracy: 0.4611\n",
            "Epoch 51/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 9.7508 - accuracy: 0.4519\n",
            "Epoch 51: val_loss improved from 9.79722 to 9.64319, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 9.7507 - accuracy: 0.4517 - val_loss: 9.6432 - val_accuracy: 0.4623\n",
            "Epoch 52/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 9.5960 - accuracy: 0.4543\n",
            "Epoch 52: val_loss improved from 9.64319 to 9.49060, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 9.5959 - accuracy: 0.4543 - val_loss: 9.4906 - val_accuracy: 0.4644\n",
            "Epoch 53/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 9.4435 - accuracy: 0.4547\n",
            "Epoch 53: val_loss improved from 9.49060 to 9.34374, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 9.4431 - accuracy: 0.4547 - val_loss: 9.3437 - val_accuracy: 0.4652\n",
            "Epoch 54/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 9.2975 - accuracy: 0.4522\n",
            "Epoch 54: val_loss improved from 9.34374 to 9.19687, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 9.2970 - accuracy: 0.4526 - val_loss: 9.1969 - val_accuracy: 0.4653\n",
            "Epoch 55/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 9.1513 - accuracy: 0.4582\n",
            "Epoch 55: val_loss improved from 9.19687 to 9.05534, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 9.1510 - accuracy: 0.4582 - val_loss: 9.0553 - val_accuracy: 0.4665\n",
            "Epoch 56/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 9.0079 - accuracy: 0.4612\n",
            "Epoch 56: val_loss improved from 9.05534 to 8.91553, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 9.0076 - accuracy: 0.4614 - val_loss: 8.9155 - val_accuracy: 0.4674\n",
            "Epoch 57/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 8.8708 - accuracy: 0.4618\n",
            "Epoch 57: val_loss improved from 8.91553 to 8.77891, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 8.8697 - accuracy: 0.4620 - val_loss: 8.7789 - val_accuracy: 0.4664\n",
            "Epoch 58/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 8.7310 - accuracy: 0.4641\n",
            "Epoch 58: val_loss improved from 8.77891 to 8.64210, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 8.7310 - accuracy: 0.4641 - val_loss: 8.6421 - val_accuracy: 0.4703\n",
            "Epoch 59/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 8.5939 - accuracy: 0.4663\n",
            "Epoch 59: val_loss improved from 8.64210 to 8.51044, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 8.5925 - accuracy: 0.4665 - val_loss: 8.5104 - val_accuracy: 0.4711\n",
            "Epoch 60/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 8.4633 - accuracy: 0.4655\n",
            "Epoch 60: val_loss improved from 8.51044 to 8.37958, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 8.4633 - accuracy: 0.4651 - val_loss: 8.3796 - val_accuracy: 0.4698\n",
            "Epoch 61/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 8.3291 - accuracy: 0.4700\n",
            "Epoch 61: val_loss improved from 8.37958 to 8.25152, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 8.3283 - accuracy: 0.4702 - val_loss: 8.2515 - val_accuracy: 0.4708\n",
            "Epoch 62/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 8.2025 - accuracy: 0.4710\n",
            "Epoch 62: val_loss improved from 8.25152 to 8.12668, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 8.2023 - accuracy: 0.4710 - val_loss: 8.1267 - val_accuracy: 0.4723\n",
            "Epoch 63/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 8.0804 - accuracy: 0.4724\n",
            "Epoch 63: val_loss improved from 8.12668 to 8.00422, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 8.0790 - accuracy: 0.4726 - val_loss: 8.0042 - val_accuracy: 0.4739\n",
            "Epoch 64/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 7.9546 - accuracy: 0.4748\n",
            "Epoch 64: val_loss improved from 8.00422 to 7.88401, saving model to best_model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 7.9545 - accuracy: 0.4748 - val_loss: 7.8840 - val_accuracy: 0.4736\n",
            "Epoch 65/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 7.8320 - accuracy: 0.4793\n",
            "Epoch 65: val_loss improved from 7.88401 to 7.76462, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 7.8313 - accuracy: 0.4794 - val_loss: 7.7646 - val_accuracy: 0.4754\n",
            "Epoch 66/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 7.7186 - accuracy: 0.4746\n",
            "Epoch 66: val_loss improved from 7.76462 to 7.64920, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 7.7176 - accuracy: 0.4749 - val_loss: 7.6492 - val_accuracy: 0.4766\n",
            "Epoch 67/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 7.5996 - accuracy: 0.4785\n",
            "Epoch 67: val_loss improved from 7.64920 to 7.53564, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 7.5996 - accuracy: 0.4785 - val_loss: 7.5356 - val_accuracy: 0.4780\n",
            "Epoch 68/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 7.4858 - accuracy: 0.4792\n",
            "Epoch 68: val_loss improved from 7.53564 to 7.42389, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 7.4847 - accuracy: 0.4791 - val_loss: 7.4239 - val_accuracy: 0.4785\n",
            "Epoch 69/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 7.3721 - accuracy: 0.4798\n",
            "Epoch 69: val_loss improved from 7.42389 to 7.31444, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 7.3721 - accuracy: 0.4797 - val_loss: 7.3144 - val_accuracy: 0.4768\n",
            "Epoch 70/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 7.2660 - accuracy: 0.4786\n",
            "Epoch 70: val_loss improved from 7.31444 to 7.20453, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 7.2659 - accuracy: 0.4786 - val_loss: 7.2045 - val_accuracy: 0.4819\n",
            "Epoch 71/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 7.1547 - accuracy: 0.4812\n",
            "Epoch 71: val_loss improved from 7.20453 to 7.09941, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 7.1547 - accuracy: 0.4812 - val_loss: 7.0994 - val_accuracy: 0.4808\n",
            "Epoch 72/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 7.0494 - accuracy: 0.4876\n",
            "Epoch 72: val_loss improved from 7.09941 to 6.99530, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 7.0492 - accuracy: 0.4876 - val_loss: 6.9953 - val_accuracy: 0.4827\n",
            "Epoch 73/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 6.9443 - accuracy: 0.4880\n",
            "Epoch 73: val_loss improved from 6.99530 to 6.89359, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.9444 - accuracy: 0.4879 - val_loss: 6.8936 - val_accuracy: 0.4839\n",
            "Epoch 74/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 6.8428 - accuracy: 0.4855\n",
            "Epoch 74: val_loss improved from 6.89359 to 6.79644, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.8425 - accuracy: 0.4857 - val_loss: 6.7964 - val_accuracy: 0.4819\n",
            "Epoch 75/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 6.7398 - accuracy: 0.4860\n",
            "Epoch 75: val_loss improved from 6.79644 to 6.69715, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 6.7401 - accuracy: 0.4862 - val_loss: 6.6972 - val_accuracy: 0.4840\n",
            "Epoch 76/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 6.6468 - accuracy: 0.4901\n",
            "Epoch 76: val_loss improved from 6.69715 to 6.59997, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.6466 - accuracy: 0.4900 - val_loss: 6.6000 - val_accuracy: 0.4863\n",
            "Epoch 77/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 6.5474 - accuracy: 0.4944\n",
            "Epoch 77: val_loss improved from 6.59997 to 6.50634, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 6.5478 - accuracy: 0.4942 - val_loss: 6.5063 - val_accuracy: 0.4862\n",
            "Epoch 78/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 6.4558 - accuracy: 0.4909\n",
            "Epoch 78: val_loss improved from 6.50634 to 6.41355, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.4558 - accuracy: 0.4909 - val_loss: 6.4135 - val_accuracy: 0.4876\n",
            "Epoch 79/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 6.3623 - accuracy: 0.4928\n",
            "Epoch 79: val_loss improved from 6.41355 to 6.32402, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.3625 - accuracy: 0.4927 - val_loss: 6.3240 - val_accuracy: 0.4870\n",
            "Epoch 80/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 6.2720 - accuracy: 0.4933\n",
            "Epoch 80: val_loss improved from 6.32402 to 6.23348, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 6.2718 - accuracy: 0.4935 - val_loss: 6.2335 - val_accuracy: 0.4869\n",
            "Epoch 81/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 6.1788 - accuracy: 0.4977\n",
            "Epoch 81: val_loss improved from 6.23348 to 6.14703, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 6.1789 - accuracy: 0.4978 - val_loss: 6.1470 - val_accuracy: 0.4882\n",
            "Epoch 82/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 6.0909 - accuracy: 0.4982\n",
            "Epoch 82: val_loss improved from 6.14703 to 6.06191, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 6.0892 - accuracy: 0.4985 - val_loss: 6.0619 - val_accuracy: 0.4878\n",
            "Epoch 83/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 6.0045 - accuracy: 0.4992\n",
            "Epoch 83: val_loss improved from 6.06191 to 5.97670, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.0046 - accuracy: 0.4992 - val_loss: 5.9767 - val_accuracy: 0.4894\n",
            "Epoch 84/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 5.9195 - accuracy: 0.5007\n",
            "Epoch 84: val_loss improved from 5.97670 to 5.89270, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.9196 - accuracy: 0.5006 - val_loss: 5.8927 - val_accuracy: 0.4918\n",
            "Epoch 85/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 5.8360 - accuracy: 0.5023\n",
            "Epoch 85: val_loss improved from 5.89270 to 5.81140, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.8353 - accuracy: 0.5025 - val_loss: 5.8114 - val_accuracy: 0.4917\n",
            "Epoch 86/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 5.7507 - accuracy: 0.5057\n",
            "Epoch 86: val_loss improved from 5.81140 to 5.73319, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.7509 - accuracy: 0.5056 - val_loss: 5.7332 - val_accuracy: 0.4923\n",
            "Epoch 87/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 5.6792 - accuracy: 0.4992\n",
            "Epoch 87: val_loss improved from 5.73319 to 5.65600, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 5.6787 - accuracy: 0.4993 - val_loss: 5.6560 - val_accuracy: 0.4933\n",
            "Epoch 88/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 5.5987 - accuracy: 0.5039\n",
            "Epoch 88: val_loss improved from 5.65600 to 5.57790, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.5985 - accuracy: 0.5038 - val_loss: 5.5779 - val_accuracy: 0.4948\n",
            "Epoch 89/500\n",
            "925/938 [============================>.] - ETA: 0s - loss: 5.5177 - accuracy: 0.5092\n",
            "Epoch 89: val_loss improved from 5.57790 to 5.50179, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.5189 - accuracy: 0.5080 - val_loss: 5.5018 - val_accuracy: 0.4960\n",
            "Epoch 90/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 5.4430 - accuracy: 0.5076\n",
            "Epoch 90: val_loss improved from 5.50179 to 5.42712, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 5.4423 - accuracy: 0.5080 - val_loss: 5.4271 - val_accuracy: 0.4954\n",
            "Epoch 91/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 5.3675 - accuracy: 0.5097\n",
            "Epoch 91: val_loss improved from 5.42712 to 5.35640, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.3679 - accuracy: 0.5099 - val_loss: 5.3564 - val_accuracy: 0.4960\n",
            "Epoch 92/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 5.2954 - accuracy: 0.5078\n",
            "Epoch 92: val_loss improved from 5.35640 to 5.28565, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.2947 - accuracy: 0.5079 - val_loss: 5.2856 - val_accuracy: 0.4965\n",
            "Epoch 93/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 5.2244 - accuracy: 0.5081\n",
            "Epoch 93: val_loss improved from 5.28565 to 5.21553, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.2240 - accuracy: 0.5084 - val_loss: 5.2155 - val_accuracy: 0.4961\n",
            "Epoch 94/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 5.1490 - accuracy: 0.5137\n",
            "Epoch 94: val_loss improved from 5.21553 to 5.14712, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 5.1495 - accuracy: 0.5132 - val_loss: 5.1471 - val_accuracy: 0.4984\n",
            "Epoch 95/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 5.0805 - accuracy: 0.5155\n",
            "Epoch 95: val_loss improved from 5.14712 to 5.08165, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 5.0806 - accuracy: 0.5152 - val_loss: 5.0817 - val_accuracy: 0.4994\n",
            "Epoch 96/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 5.0199 - accuracy: 0.5131\n",
            "Epoch 96: val_loss improved from 5.08165 to 5.01430, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 5.0196 - accuracy: 0.5129 - val_loss: 5.0143 - val_accuracy: 0.4994\n",
            "Epoch 97/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 4.9510 - accuracy: 0.5139\n",
            "Epoch 97: val_loss improved from 5.01430 to 4.94882, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 4.9512 - accuracy: 0.5137 - val_loss: 4.9488 - val_accuracy: 0.5003\n",
            "Epoch 98/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 4.8872 - accuracy: 0.5164\n",
            "Epoch 98: val_loss improved from 4.94882 to 4.88658, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.8866 - accuracy: 0.5166 - val_loss: 4.8866 - val_accuracy: 0.5003\n",
            "Epoch 99/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 4.8174 - accuracy: 0.5169\n",
            "Epoch 99: val_loss improved from 4.88658 to 4.82253, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 4.8173 - accuracy: 0.5169 - val_loss: 4.8225 - val_accuracy: 0.5003\n",
            "Epoch 100/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 4.7560 - accuracy: 0.5181\n",
            "Epoch 100: val_loss improved from 4.82253 to 4.76285, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 4.7554 - accuracy: 0.5183 - val_loss: 4.7629 - val_accuracy: 0.5010\n",
            "Epoch 101/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.6884 - accuracy: 0.5222\n",
            "Epoch 101: val_loss improved from 4.76285 to 4.70361, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 4.6884 - accuracy: 0.5222 - val_loss: 4.7036 - val_accuracy: 0.5009\n",
            "Epoch 102/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 4.6337 - accuracy: 0.5237\n",
            "Epoch 102: val_loss improved from 4.70361 to 4.64402, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 4.6337 - accuracy: 0.5236 - val_loss: 4.6440 - val_accuracy: 0.5042\n",
            "Epoch 103/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.5704 - accuracy: 0.5238\n",
            "Epoch 103: val_loss improved from 4.64402 to 4.58762, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.5704 - accuracy: 0.5238 - val_loss: 4.5876 - val_accuracy: 0.5043\n",
            "Epoch 104/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 4.5176 - accuracy: 0.5258\n",
            "Epoch 104: val_loss improved from 4.58762 to 4.52990, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 4.5174 - accuracy: 0.5257 - val_loss: 4.5299 - val_accuracy: 0.5054\n",
            "Epoch 105/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 4.4532 - accuracy: 0.5242\n",
            "Epoch 105: val_loss improved from 4.52990 to 4.47309, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.4532 - accuracy: 0.5243 - val_loss: 4.4731 - val_accuracy: 0.5062\n",
            "Epoch 106/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 4.4012 - accuracy: 0.5249\n",
            "Epoch 106: val_loss improved from 4.47309 to 4.42021, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.4013 - accuracy: 0.5250 - val_loss: 4.4202 - val_accuracy: 0.5049\n",
            "Epoch 107/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 4.3417 - accuracy: 0.5310\n",
            "Epoch 107: val_loss improved from 4.42021 to 4.36562, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.3420 - accuracy: 0.5305 - val_loss: 4.3656 - val_accuracy: 0.5072\n",
            "Epoch 108/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.2883 - accuracy: 0.5324\n",
            "Epoch 108: val_loss improved from 4.36562 to 4.31286, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.2883 - accuracy: 0.5324 - val_loss: 4.3129 - val_accuracy: 0.5056\n",
            "Epoch 109/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 4.2383 - accuracy: 0.5304\n",
            "Epoch 109: val_loss improved from 4.31286 to 4.26204, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.2383 - accuracy: 0.5303 - val_loss: 4.2620 - val_accuracy: 0.5079\n",
            "Epoch 110/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 4.1837 - accuracy: 0.5315\n",
            "Epoch 110: val_loss improved from 4.26204 to 4.21093, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.1841 - accuracy: 0.5312 - val_loss: 4.2109 - val_accuracy: 0.5087\n",
            "Epoch 111/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 4.1289 - accuracy: 0.5365\n",
            "Epoch 111: val_loss improved from 4.21093 to 4.16342, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.1287 - accuracy: 0.5359 - val_loss: 4.1634 - val_accuracy: 0.5070\n",
            "Epoch 112/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 4.0775 - accuracy: 0.5326\n",
            "Epoch 112: val_loss improved from 4.16342 to 4.11385, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.0780 - accuracy: 0.5321 - val_loss: 4.1138 - val_accuracy: 0.5085\n",
            "Epoch 113/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.0290 - accuracy: 0.5362\n",
            "Epoch 113: val_loss improved from 4.11385 to 4.06542, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 4.0290 - accuracy: 0.5362 - val_loss: 4.0654 - val_accuracy: 0.5087\n",
            "Epoch 114/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 3.9789 - accuracy: 0.5358\n",
            "Epoch 114: val_loss improved from 4.06542 to 4.01592, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.9789 - accuracy: 0.5358 - val_loss: 4.0159 - val_accuracy: 0.5127\n",
            "Epoch 115/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 3.9314 - accuracy: 0.5374\n",
            "Epoch 115: val_loss improved from 4.01592 to 3.97327, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.9313 - accuracy: 0.5377 - val_loss: 3.9733 - val_accuracy: 0.5080\n",
            "Epoch 116/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 3.8842 - accuracy: 0.5400\n",
            "Epoch 116: val_loss improved from 3.97327 to 3.92565, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.8844 - accuracy: 0.5397 - val_loss: 3.9257 - val_accuracy: 0.5102\n",
            "Epoch 117/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 3.8382 - accuracy: 0.5410\n",
            "Epoch 117: val_loss improved from 3.92565 to 3.88147, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.8381 - accuracy: 0.5410 - val_loss: 3.8815 - val_accuracy: 0.5125\n",
            "Epoch 118/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 3.7907 - accuracy: 0.5439\n",
            "Epoch 118: val_loss improved from 3.88147 to 3.83948, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.7909 - accuracy: 0.5438 - val_loss: 3.8395 - val_accuracy: 0.5117\n",
            "Epoch 119/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 3.7480 - accuracy: 0.5430\n",
            "Epoch 119: val_loss improved from 3.83948 to 3.79816, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.7470 - accuracy: 0.5430 - val_loss: 3.7982 - val_accuracy: 0.5122\n",
            "Epoch 120/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 3.7031 - accuracy: 0.5445\n",
            "Epoch 120: val_loss improved from 3.79816 to 3.75922, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.7028 - accuracy: 0.5447 - val_loss: 3.7592 - val_accuracy: 0.5126\n",
            "Epoch 121/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 3.6605 - accuracy: 0.5458\n",
            "Epoch 121: val_loss improved from 3.75922 to 3.71404, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.6602 - accuracy: 0.5462 - val_loss: 3.7140 - val_accuracy: 0.5119\n",
            "Epoch 122/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 3.6172 - accuracy: 0.5460\n",
            "Epoch 122: val_loss improved from 3.71404 to 3.67384, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.6183 - accuracy: 0.5453 - val_loss: 3.6738 - val_accuracy: 0.5168\n",
            "Epoch 123/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 3.5794 - accuracy: 0.5457\n",
            "Epoch 123: val_loss improved from 3.67384 to 3.63438, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.5794 - accuracy: 0.5456 - val_loss: 3.6344 - val_accuracy: 0.5145\n",
            "Epoch 124/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 3.5388 - accuracy: 0.5474\n",
            "Epoch 124: val_loss improved from 3.63438 to 3.59602, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.5382 - accuracy: 0.5476 - val_loss: 3.5960 - val_accuracy: 0.5177\n",
            "Epoch 125/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 3.4953 - accuracy: 0.5496\n",
            "Epoch 125: val_loss improved from 3.59602 to 3.55752, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.4960 - accuracy: 0.5496 - val_loss: 3.5575 - val_accuracy: 0.5156\n",
            "Epoch 126/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 3.4570 - accuracy: 0.5500\n",
            "Epoch 126: val_loss improved from 3.55752 to 3.52058, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.4572 - accuracy: 0.5499 - val_loss: 3.5206 - val_accuracy: 0.5154\n",
            "Epoch 127/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 3.4217 - accuracy: 0.5495\n",
            "Epoch 127: val_loss improved from 3.52058 to 3.48460, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.4222 - accuracy: 0.5493 - val_loss: 3.4846 - val_accuracy: 0.5187\n",
            "Epoch 128/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 3.3773 - accuracy: 0.5535\n",
            "Epoch 128: val_loss improved from 3.48460 to 3.44803, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.3770 - accuracy: 0.5536 - val_loss: 3.4480 - val_accuracy: 0.5164\n",
            "Epoch 129/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 3.3439 - accuracy: 0.5535\n",
            "Epoch 129: val_loss improved from 3.44803 to 3.41527, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.3438 - accuracy: 0.5539 - val_loss: 3.4153 - val_accuracy: 0.5186\n",
            "Epoch 130/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 3.3046 - accuracy: 0.5553\n",
            "Epoch 130: val_loss improved from 3.41527 to 3.38288, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.3046 - accuracy: 0.5551 - val_loss: 3.3829 - val_accuracy: 0.5162\n",
            "Epoch 131/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 3.2689 - accuracy: 0.5580\n",
            "Epoch 131: val_loss improved from 3.38288 to 3.34352, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.2689 - accuracy: 0.5579 - val_loss: 3.3435 - val_accuracy: 0.5183\n",
            "Epoch 132/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 3.2352 - accuracy: 0.5536\n",
            "Epoch 132: val_loss improved from 3.34352 to 3.31248, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 3.2347 - accuracy: 0.5538 - val_loss: 3.3125 - val_accuracy: 0.5209\n",
            "Epoch 133/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 3.1994 - accuracy: 0.5561\n",
            "Epoch 133: val_loss improved from 3.31248 to 3.27838, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.1991 - accuracy: 0.5558 - val_loss: 3.2784 - val_accuracy: 0.5196\n",
            "Epoch 134/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 3.1655 - accuracy: 0.5608\n",
            "Epoch 134: val_loss improved from 3.27838 to 3.24688, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.1646 - accuracy: 0.5604 - val_loss: 3.2469 - val_accuracy: 0.5217\n",
            "Epoch 135/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 3.1335 - accuracy: 0.5592\n",
            "Epoch 135: val_loss improved from 3.24688 to 3.21703, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.1333 - accuracy: 0.5593 - val_loss: 3.2170 - val_accuracy: 0.5193\n",
            "Epoch 136/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 3.0999 - accuracy: 0.5615\n",
            "Epoch 136: val_loss improved from 3.21703 to 3.18870, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 3.0990 - accuracy: 0.5616 - val_loss: 3.1887 - val_accuracy: 0.5205\n",
            "Epoch 137/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 3.0657 - accuracy: 0.5621\n",
            "Epoch 137: val_loss improved from 3.18870 to 3.15497, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.0668 - accuracy: 0.5618 - val_loss: 3.1550 - val_accuracy: 0.5248\n",
            "Epoch 138/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 3.0400 - accuracy: 0.5613\n",
            "Epoch 138: val_loss improved from 3.15497 to 3.12462, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.0405 - accuracy: 0.5609 - val_loss: 3.1246 - val_accuracy: 0.5235\n",
            "Epoch 139/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 3.0060 - accuracy: 0.5660\n",
            "Epoch 139: val_loss improved from 3.12462 to 3.09506, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 3.0057 - accuracy: 0.5662 - val_loss: 3.0951 - val_accuracy: 0.5242\n",
            "Epoch 140/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 2.9751 - accuracy: 0.5668\n",
            "Epoch 140: val_loss improved from 3.09506 to 3.07325, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.9749 - accuracy: 0.5666 - val_loss: 3.0733 - val_accuracy: 0.5204\n",
            "Epoch 141/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.9454 - accuracy: 0.5661\n",
            "Epoch 141: val_loss improved from 3.07325 to 3.04049, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.9452 - accuracy: 0.5661 - val_loss: 3.0405 - val_accuracy: 0.5203\n",
            "Epoch 142/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 2.9139 - accuracy: 0.5693\n",
            "Epoch 142: val_loss improved from 3.04049 to 3.01029, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.9136 - accuracy: 0.5693 - val_loss: 3.0103 - val_accuracy: 0.5255\n",
            "Epoch 143/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.8848 - accuracy: 0.5716\n",
            "Epoch 143: val_loss improved from 3.01029 to 2.98732, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.8844 - accuracy: 0.5717 - val_loss: 2.9873 - val_accuracy: 0.5238\n",
            "Epoch 144/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 2.8601 - accuracy: 0.5709\n",
            "Epoch 144: val_loss improved from 2.98732 to 2.95735, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.8599 - accuracy: 0.5706 - val_loss: 2.9573 - val_accuracy: 0.5267\n",
            "Epoch 145/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.8276 - accuracy: 0.5734\n",
            "Epoch 145: val_loss improved from 2.95735 to 2.93370, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.8277 - accuracy: 0.5733 - val_loss: 2.9337 - val_accuracy: 0.5248\n",
            "Epoch 146/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.8043 - accuracy: 0.5698\n",
            "Epoch 146: val_loss improved from 2.93370 to 2.90954, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 2.8045 - accuracy: 0.5696 - val_loss: 2.9095 - val_accuracy: 0.5238\n",
            "Epoch 147/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.7788 - accuracy: 0.5724\n",
            "Epoch 147: val_loss improved from 2.90954 to 2.88464, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.7778 - accuracy: 0.5725 - val_loss: 2.8846 - val_accuracy: 0.5249\n",
            "Epoch 148/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 2.7478 - accuracy: 0.5733\n",
            "Epoch 148: val_loss improved from 2.88464 to 2.85689, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.7473 - accuracy: 0.5734 - val_loss: 2.8569 - val_accuracy: 0.5240\n",
            "Epoch 149/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 2.7198 - accuracy: 0.5785\n",
            "Epoch 149: val_loss improved from 2.85689 to 2.83265, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.7195 - accuracy: 0.5785 - val_loss: 2.8327 - val_accuracy: 0.5278\n",
            "Epoch 150/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.6961 - accuracy: 0.5760\n",
            "Epoch 150: val_loss improved from 2.83265 to 2.80952, saving model to best_model.h5\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 2.6962 - accuracy: 0.5757 - val_loss: 2.8095 - val_accuracy: 0.5284\n",
            "Epoch 151/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 2.6710 - accuracy: 0.5754\n",
            "Epoch 151: val_loss improved from 2.80952 to 2.78833, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.6714 - accuracy: 0.5754 - val_loss: 2.7883 - val_accuracy: 0.5269\n",
            "Epoch 152/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 2.6485 - accuracy: 0.5777\n",
            "Epoch 152: val_loss improved from 2.78833 to 2.76500, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.6486 - accuracy: 0.5779 - val_loss: 2.7650 - val_accuracy: 0.5266\n",
            "Epoch 153/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 2.6196 - accuracy: 0.5820\n",
            "Epoch 153: val_loss improved from 2.76500 to 2.74197, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.6193 - accuracy: 0.5821 - val_loss: 2.7420 - val_accuracy: 0.5284\n",
            "Epoch 154/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 2.5976 - accuracy: 0.5801\n",
            "Epoch 154: val_loss improved from 2.74197 to 2.72189, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.5975 - accuracy: 0.5801 - val_loss: 2.7219 - val_accuracy: 0.5283\n",
            "Epoch 155/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 2.5754 - accuracy: 0.5801\n",
            "Epoch 155: val_loss improved from 2.72189 to 2.69931, saving model to best_model.h5\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 2.5754 - accuracy: 0.5804 - val_loss: 2.6993 - val_accuracy: 0.5302\n",
            "Epoch 156/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 2.5536 - accuracy: 0.5790\n",
            "Epoch 156: val_loss improved from 2.69931 to 2.67972, saving model to best_model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 2.5537 - accuracy: 0.5790 - val_loss: 2.6797 - val_accuracy: 0.5296\n",
            "Epoch 157/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 2.5273 - accuracy: 0.5852\n",
            "Epoch 157: val_loss improved from 2.67972 to 2.65775, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.5272 - accuracy: 0.5855 - val_loss: 2.6577 - val_accuracy: 0.5321\n",
            "Epoch 158/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 2.5064 - accuracy: 0.5831\n",
            "Epoch 158: val_loss improved from 2.65775 to 2.63844, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.5068 - accuracy: 0.5827 - val_loss: 2.6384 - val_accuracy: 0.5300\n",
            "Epoch 159/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 2.4866 - accuracy: 0.5817\n",
            "Epoch 159: val_loss improved from 2.63844 to 2.61815, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 2.4861 - accuracy: 0.5819 - val_loss: 2.6181 - val_accuracy: 0.5294\n",
            "Epoch 160/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 2.4657 - accuracy: 0.5870\n",
            "Epoch 160: val_loss improved from 2.61815 to 2.59717, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.4656 - accuracy: 0.5872 - val_loss: 2.5972 - val_accuracy: 0.5312\n",
            "Epoch 161/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 2.4444 - accuracy: 0.5869\n",
            "Epoch 161: val_loss improved from 2.59717 to 2.57970, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 2.4449 - accuracy: 0.5867 - val_loss: 2.5797 - val_accuracy: 0.5310\n",
            "Epoch 162/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 2.4219 - accuracy: 0.5882\n",
            "Epoch 162: val_loss improved from 2.57970 to 2.56396, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 2.4219 - accuracy: 0.5882 - val_loss: 2.5640 - val_accuracy: 0.5330\n",
            "Epoch 163/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.4029 - accuracy: 0.5902\n",
            "Epoch 163: val_loss improved from 2.56396 to 2.54433, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 2.4036 - accuracy: 0.5899 - val_loss: 2.5443 - val_accuracy: 0.5293\n",
            "Epoch 164/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.3827 - accuracy: 0.5903\n",
            "Epoch 164: val_loss improved from 2.54433 to 2.52646, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 2.3824 - accuracy: 0.5905 - val_loss: 2.5265 - val_accuracy: 0.5309\n",
            "Epoch 165/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.3617 - accuracy: 0.5942\n",
            "Epoch 165: val_loss improved from 2.52646 to 2.51178, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 2.3614 - accuracy: 0.5943 - val_loss: 2.5118 - val_accuracy: 0.5333\n",
            "Epoch 166/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.3392 - accuracy: 0.5952\n",
            "Epoch 166: val_loss improved from 2.51178 to 2.49314, saving model to best_model.h5\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 2.3392 - accuracy: 0.5952 - val_loss: 2.4931 - val_accuracy: 0.5329\n",
            "Epoch 167/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.3233 - accuracy: 0.5941\n",
            "Epoch 167: val_loss improved from 2.49314 to 2.47314, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 2.3234 - accuracy: 0.5939 - val_loss: 2.4731 - val_accuracy: 0.5330\n",
            "Epoch 168/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.3072 - accuracy: 0.5940\n",
            "Epoch 168: val_loss improved from 2.47314 to 2.45916, saving model to best_model.h5\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 2.3070 - accuracy: 0.5941 - val_loss: 2.4592 - val_accuracy: 0.5340\n",
            "Epoch 169/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 2.2855 - accuracy: 0.5964\n",
            "Epoch 169: val_loss improved from 2.45916 to 2.44051, saving model to best_model.h5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 2.2855 - accuracy: 0.5965 - val_loss: 2.4405 - val_accuracy: 0.5350\n",
            "Epoch 170/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.2726 - accuracy: 0.5944\n",
            "Epoch 170: val_loss improved from 2.44051 to 2.42427, saving model to best_model.h5\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 2.2727 - accuracy: 0.5944 - val_loss: 2.4243 - val_accuracy: 0.5355\n",
            "Epoch 171/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.2503 - accuracy: 0.5967\n",
            "Epoch 171: val_loss improved from 2.42427 to 2.41079, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 2.2503 - accuracy: 0.5967 - val_loss: 2.4108 - val_accuracy: 0.5353\n",
            "Epoch 172/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 2.2337 - accuracy: 0.5978\n",
            "Epoch 172: val_loss improved from 2.41079 to 2.39404, saving model to best_model.h5\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 2.2337 - accuracy: 0.5978 - val_loss: 2.3940 - val_accuracy: 0.5356\n",
            "Epoch 173/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.2132 - accuracy: 0.6019\n",
            "Epoch 173: val_loss improved from 2.39404 to 2.38042, saving model to best_model.h5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 2.2133 - accuracy: 0.6014 - val_loss: 2.3804 - val_accuracy: 0.5349\n",
            "Epoch 174/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 2.1986 - accuracy: 0.6006\n",
            "Epoch 174: val_loss improved from 2.38042 to 2.36536, saving model to best_model.h5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 2.1984 - accuracy: 0.6007 - val_loss: 2.3654 - val_accuracy: 0.5370\n",
            "Epoch 175/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 2.1841 - accuracy: 0.6002\n",
            "Epoch 175: val_loss improved from 2.36536 to 2.35333, saving model to best_model.h5\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 2.1834 - accuracy: 0.6005 - val_loss: 2.3533 - val_accuracy: 0.5362\n",
            "Epoch 176/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 2.1678 - accuracy: 0.6009\n",
            "Epoch 176: val_loss improved from 2.35333 to 2.33705, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 2.1665 - accuracy: 0.6010 - val_loss: 2.3370 - val_accuracy: 0.5340\n",
            "Epoch 177/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 2.1546 - accuracy: 0.6032\n",
            "Epoch 177: val_loss improved from 2.33705 to 2.32660, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 2.1546 - accuracy: 0.6032 - val_loss: 2.3266 - val_accuracy: 0.5324\n",
            "Epoch 178/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.1336 - accuracy: 0.6075\n",
            "Epoch 178: val_loss improved from 2.32660 to 2.30949, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 2.1332 - accuracy: 0.6078 - val_loss: 2.3095 - val_accuracy: 0.5356\n",
            "Epoch 179/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 2.1189 - accuracy: 0.6059\n",
            "Epoch 179: val_loss improved from 2.30949 to 2.29947, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 2.1190 - accuracy: 0.6060 - val_loss: 2.2995 - val_accuracy: 0.5388\n",
            "Epoch 180/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 2.1049 - accuracy: 0.6053\n",
            "Epoch 180: val_loss improved from 2.29947 to 2.28278, saving model to best_model.h5\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 2.1048 - accuracy: 0.6054 - val_loss: 2.2828 - val_accuracy: 0.5390\n",
            "Epoch 181/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.0931 - accuracy: 0.6078\n",
            "Epoch 181: val_loss improved from 2.28278 to 2.27229, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 2.0931 - accuracy: 0.6078 - val_loss: 2.2723 - val_accuracy: 0.5366\n",
            "Epoch 182/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 2.0737 - accuracy: 0.6100\n",
            "Epoch 182: val_loss improved from 2.27229 to 2.25827, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 2.0734 - accuracy: 0.6102 - val_loss: 2.2583 - val_accuracy: 0.5371\n",
            "Epoch 183/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 2.0618 - accuracy: 0.6090\n",
            "Epoch 183: val_loss improved from 2.25827 to 2.24682, saving model to best_model.h5\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 2.0619 - accuracy: 0.6090 - val_loss: 2.2468 - val_accuracy: 0.5390\n",
            "Epoch 184/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 2.0491 - accuracy: 0.6105\n",
            "Epoch 184: val_loss improved from 2.24682 to 2.23259, saving model to best_model.h5\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 2.0488 - accuracy: 0.6105 - val_loss: 2.2326 - val_accuracy: 0.5394\n",
            "Epoch 185/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 2.0358 - accuracy: 0.6140\n",
            "Epoch 185: val_loss improved from 2.23259 to 2.22442, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 2.0355 - accuracy: 0.6143 - val_loss: 2.2244 - val_accuracy: 0.5370\n",
            "Epoch 186/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 2.0180 - accuracy: 0.6137\n",
            "Epoch 186: val_loss improved from 2.22442 to 2.21188, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 2.0180 - accuracy: 0.6136 - val_loss: 2.2119 - val_accuracy: 0.5381\n",
            "Epoch 187/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 2.0061 - accuracy: 0.6135\n",
            "Epoch 187: val_loss improved from 2.21188 to 2.19764, saving model to best_model.h5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 2.0061 - accuracy: 0.6135 - val_loss: 2.1976 - val_accuracy: 0.5385\n",
            "Epoch 188/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.9966 - accuracy: 0.6134\n",
            "Epoch 188: val_loss improved from 2.19764 to 2.19062, saving model to best_model.h5\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 1.9966 - accuracy: 0.6134 - val_loss: 2.1906 - val_accuracy: 0.5379\n",
            "Epoch 189/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.9821 - accuracy: 0.6185\n",
            "Epoch 189: val_loss improved from 2.19062 to 2.17903, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.9826 - accuracy: 0.6181 - val_loss: 2.1790 - val_accuracy: 0.5403\n",
            "Epoch 190/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.9662 - accuracy: 0.6197\n",
            "Epoch 190: val_loss improved from 2.17903 to 2.16584, saving model to best_model.h5\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 1.9669 - accuracy: 0.6194 - val_loss: 2.1658 - val_accuracy: 0.5416\n",
            "Epoch 191/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.9558 - accuracy: 0.6175\n",
            "Epoch 191: val_loss improved from 2.16584 to 2.16032, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 1.9560 - accuracy: 0.6174 - val_loss: 2.1603 - val_accuracy: 0.5400\n",
            "Epoch 192/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.9446 - accuracy: 0.6162\n",
            "Epoch 192: val_loss improved from 2.16032 to 2.14758, saving model to best_model.h5\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 1.9445 - accuracy: 0.6164 - val_loss: 2.1476 - val_accuracy: 0.5403\n",
            "Epoch 193/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.9303 - accuracy: 0.6206\n",
            "Epoch 193: val_loss improved from 2.14758 to 2.13557, saving model to best_model.h5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 1.9305 - accuracy: 0.6205 - val_loss: 2.1356 - val_accuracy: 0.5400\n",
            "Epoch 194/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.9183 - accuracy: 0.6201\n",
            "Epoch 194: val_loss improved from 2.13557 to 2.12493, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 1.9182 - accuracy: 0.6199 - val_loss: 2.1249 - val_accuracy: 0.5389\n",
            "Epoch 195/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.9097 - accuracy: 0.6209\n",
            "Epoch 195: val_loss improved from 2.12493 to 2.12137, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.9094 - accuracy: 0.6214 - val_loss: 2.1214 - val_accuracy: 0.5368\n",
            "Epoch 196/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.8953 - accuracy: 0.6251\n",
            "Epoch 196: val_loss improved from 2.12137 to 2.11156, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.8952 - accuracy: 0.6251 - val_loss: 2.1116 - val_accuracy: 0.5413\n",
            "Epoch 197/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.8848 - accuracy: 0.6248\n",
            "Epoch 197: val_loss improved from 2.11156 to 2.09922, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.8845 - accuracy: 0.6251 - val_loss: 2.0992 - val_accuracy: 0.5403\n",
            "Epoch 198/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.8730 - accuracy: 0.6245\n",
            "Epoch 198: val_loss improved from 2.09922 to 2.09164, saving model to best_model.h5\n",
            "938/938 [==============================] - 16s 17ms/step - loss: 1.8733 - accuracy: 0.6247 - val_loss: 2.0916 - val_accuracy: 0.5408\n",
            "Epoch 199/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.8663 - accuracy: 0.6236\n",
            "Epoch 199: val_loss improved from 2.09164 to 2.08465, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 1.8659 - accuracy: 0.6234 - val_loss: 2.0847 - val_accuracy: 0.5379\n",
            "Epoch 200/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.8562 - accuracy: 0.6236\n",
            "Epoch 200: val_loss improved from 2.08465 to 2.07363, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.8562 - accuracy: 0.6236 - val_loss: 2.0736 - val_accuracy: 0.5421\n",
            "Epoch 201/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.8434 - accuracy: 0.6254\n",
            "Epoch 201: val_loss improved from 2.07363 to 2.06528, saving model to best_model.h5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 1.8433 - accuracy: 0.6249 - val_loss: 2.0653 - val_accuracy: 0.5402\n",
            "Epoch 202/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.8331 - accuracy: 0.6262\n",
            "Epoch 202: val_loss improved from 2.06528 to 2.05596, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.8331 - accuracy: 0.6262 - val_loss: 2.0560 - val_accuracy: 0.5407\n",
            "Epoch 203/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.8207 - accuracy: 0.6293\n",
            "Epoch 203: val_loss improved from 2.05596 to 2.04686, saving model to best_model.h5\n",
            "938/938 [==============================] - 14s 14ms/step - loss: 1.8204 - accuracy: 0.6296 - val_loss: 2.0469 - val_accuracy: 0.5407\n",
            "Epoch 204/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.8123 - accuracy: 0.6274\n",
            "Epoch 204: val_loss improved from 2.04686 to 2.03683, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.8122 - accuracy: 0.6274 - val_loss: 2.0368 - val_accuracy: 0.5441\n",
            "Epoch 205/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.8021 - accuracy: 0.6334\n",
            "Epoch 205: val_loss improved from 2.03683 to 2.03040, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.8021 - accuracy: 0.6334 - val_loss: 2.0304 - val_accuracy: 0.5420\n",
            "Epoch 206/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.7936 - accuracy: 0.6293\n",
            "Epoch 206: val_loss improved from 2.03040 to 2.02216, saving model to best_model.h5\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 1.7940 - accuracy: 0.6291 - val_loss: 2.0222 - val_accuracy: 0.5432\n",
            "Epoch 207/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.7841 - accuracy: 0.6338\n",
            "Epoch 207: val_loss improved from 2.02216 to 2.01573, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.7841 - accuracy: 0.6337 - val_loss: 2.0157 - val_accuracy: 0.5462\n",
            "Epoch 208/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.7714 - accuracy: 0.6326\n",
            "Epoch 208: val_loss improved from 2.01573 to 2.00897, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.7716 - accuracy: 0.6326 - val_loss: 2.0090 - val_accuracy: 0.5433\n",
            "Epoch 209/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.7648 - accuracy: 0.6298\n",
            "Epoch 209: val_loss improved from 2.00897 to 2.00181, saving model to best_model.h5\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 1.7649 - accuracy: 0.6299 - val_loss: 2.0018 - val_accuracy: 0.5419\n",
            "Epoch 210/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.7564 - accuracy: 0.6339\n",
            "Epoch 210: val_loss improved from 2.00181 to 1.99711, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.7563 - accuracy: 0.6338 - val_loss: 1.9971 - val_accuracy: 0.5449\n",
            "Epoch 211/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.7477 - accuracy: 0.6369\n",
            "Epoch 211: val_loss improved from 1.99711 to 1.98337, saving model to best_model.h5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 1.7479 - accuracy: 0.6368 - val_loss: 1.9834 - val_accuracy: 0.5430\n",
            "Epoch 212/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.7357 - accuracy: 0.6382\n",
            "Epoch 212: val_loss did not improve from 1.98337\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.7358 - accuracy: 0.6382 - val_loss: 1.9845 - val_accuracy: 0.5401\n",
            "Epoch 213/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.7335 - accuracy: 0.6374\n",
            "Epoch 213: val_loss improved from 1.98337 to 1.97412, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.7336 - accuracy: 0.6375 - val_loss: 1.9741 - val_accuracy: 0.5431\n",
            "Epoch 214/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.7194 - accuracy: 0.6403\n",
            "Epoch 214: val_loss improved from 1.97412 to 1.97183, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.7193 - accuracy: 0.6403 - val_loss: 1.9718 - val_accuracy: 0.5414\n",
            "Epoch 215/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.7115 - accuracy: 0.6391\n",
            "Epoch 215: val_loss improved from 1.97183 to 1.95859, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.7114 - accuracy: 0.6392 - val_loss: 1.9586 - val_accuracy: 0.5467\n",
            "Epoch 216/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.7015 - accuracy: 0.6435\n",
            "Epoch 216: val_loss improved from 1.95859 to 1.95846, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.7016 - accuracy: 0.6433 - val_loss: 1.9585 - val_accuracy: 0.5422\n",
            "Epoch 217/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.6967 - accuracy: 0.6406\n",
            "Epoch 217: val_loss improved from 1.95846 to 1.95190, saving model to best_model.h5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 1.6969 - accuracy: 0.6406 - val_loss: 1.9519 - val_accuracy: 0.5454\n",
            "Epoch 218/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.6854 - accuracy: 0.6441\n",
            "Epoch 218: val_loss improved from 1.95190 to 1.94970, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 1.6858 - accuracy: 0.6438 - val_loss: 1.9497 - val_accuracy: 0.5410\n",
            "Epoch 219/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.6789 - accuracy: 0.6443\n",
            "Epoch 219: val_loss improved from 1.94970 to 1.93555, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.6783 - accuracy: 0.6443 - val_loss: 1.9355 - val_accuracy: 0.5451\n",
            "Epoch 220/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.6745 - accuracy: 0.6426\n",
            "Epoch 220: val_loss improved from 1.93555 to 1.93183, saving model to best_model.h5\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 1.6747 - accuracy: 0.6424 - val_loss: 1.9318 - val_accuracy: 0.5440\n",
            "Epoch 221/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.6621 - accuracy: 0.6453\n",
            "Epoch 221: val_loss improved from 1.93183 to 1.92482, saving model to best_model.h5\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.6618 - accuracy: 0.6453 - val_loss: 1.9248 - val_accuracy: 0.5461\n",
            "Epoch 222/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.6572 - accuracy: 0.6435\n",
            "Epoch 222: val_loss improved from 1.92482 to 1.92039, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 1.6569 - accuracy: 0.6439 - val_loss: 1.9204 - val_accuracy: 0.5458\n",
            "Epoch 223/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.6452 - accuracy: 0.6441\n",
            "Epoch 223: val_loss improved from 1.92039 to 1.91914, saving model to best_model.h5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.6450 - accuracy: 0.6444 - val_loss: 1.9191 - val_accuracy: 0.5438\n",
            "Epoch 224/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.6434 - accuracy: 0.6484\n",
            "Epoch 224: val_loss improved from 1.91914 to 1.91138, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.6426 - accuracy: 0.6487 - val_loss: 1.9114 - val_accuracy: 0.5461\n",
            "Epoch 225/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.6295 - accuracy: 0.6531\n",
            "Epoch 225: val_loss improved from 1.91138 to 1.90516, saving model to best_model.h5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 1.6297 - accuracy: 0.6530 - val_loss: 1.9052 - val_accuracy: 0.5472\n",
            "Epoch 226/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.6255 - accuracy: 0.6503\n",
            "Epoch 226: val_loss improved from 1.90516 to 1.90109, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.6257 - accuracy: 0.6502 - val_loss: 1.9011 - val_accuracy: 0.5486\n",
            "Epoch 227/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.6271 - accuracy: 0.6461\n",
            "Epoch 227: val_loss improved from 1.90109 to 1.89625, saving model to best_model.h5\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 1.6265 - accuracy: 0.6462 - val_loss: 1.8963 - val_accuracy: 0.5458\n",
            "Epoch 228/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.6167 - accuracy: 0.6470\n",
            "Epoch 228: val_loss improved from 1.89625 to 1.88714, saving model to best_model.h5\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 1.6168 - accuracy: 0.6470 - val_loss: 1.8871 - val_accuracy: 0.5478\n",
            "Epoch 229/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.6108 - accuracy: 0.6514\n",
            "Epoch 229: val_loss improved from 1.88714 to 1.88679, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.6108 - accuracy: 0.6513 - val_loss: 1.8868 - val_accuracy: 0.5447\n",
            "Epoch 230/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.5983 - accuracy: 0.6522\n",
            "Epoch 230: val_loss did not improve from 1.88679\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.5994 - accuracy: 0.6515 - val_loss: 1.8902 - val_accuracy: 0.5425\n",
            "Epoch 231/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.5964 - accuracy: 0.6518\n",
            "Epoch 231: val_loss improved from 1.88679 to 1.88208, saving model to best_model.h5\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 1.5960 - accuracy: 0.6519 - val_loss: 1.8821 - val_accuracy: 0.5424\n",
            "Epoch 232/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.5896 - accuracy: 0.6545\n",
            "Epoch 232: val_loss improved from 1.88208 to 1.87544, saving model to best_model.h5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 1.5889 - accuracy: 0.6549 - val_loss: 1.8754 - val_accuracy: 0.5454\n",
            "Epoch 233/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.5835 - accuracy: 0.6534\n",
            "Epoch 233: val_loss improved from 1.87544 to 1.86999, saving model to best_model.h5\n",
            "938/938 [==============================] - 16s 17ms/step - loss: 1.5834 - accuracy: 0.6535 - val_loss: 1.8700 - val_accuracy: 0.5450\n",
            "Epoch 234/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.5798 - accuracy: 0.6556\n",
            "Epoch 234: val_loss improved from 1.86999 to 1.86557, saving model to best_model.h5\n",
            "938/938 [==============================] - 17s 19ms/step - loss: 1.5798 - accuracy: 0.6556 - val_loss: 1.8656 - val_accuracy: 0.5464\n",
            "Epoch 235/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.5725 - accuracy: 0.6551\n",
            "Epoch 235: val_loss improved from 1.86557 to 1.86476, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 17ms/step - loss: 1.5725 - accuracy: 0.6551 - val_loss: 1.8648 - val_accuracy: 0.5460\n",
            "Epoch 236/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.5577 - accuracy: 0.6601\n",
            "Epoch 236: val_loss improved from 1.86476 to 1.85995, saving model to best_model.h5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 1.5579 - accuracy: 0.6600 - val_loss: 1.8599 - val_accuracy: 0.5441\n",
            "Epoch 237/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.5529 - accuracy: 0.6615\n",
            "Epoch 237: val_loss improved from 1.85995 to 1.85705, saving model to best_model.h5\n",
            "938/938 [==============================] - 16s 17ms/step - loss: 1.5530 - accuracy: 0.6615 - val_loss: 1.8571 - val_accuracy: 0.5459\n",
            "Epoch 238/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.5517 - accuracy: 0.6581\n",
            "Epoch 238: val_loss improved from 1.85705 to 1.85511, saving model to best_model.h5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 1.5521 - accuracy: 0.6580 - val_loss: 1.8551 - val_accuracy: 0.5474\n",
            "Epoch 239/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.5456 - accuracy: 0.6589\n",
            "Epoch 239: val_loss did not improve from 1.85511\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.5456 - accuracy: 0.6588 - val_loss: 1.8569 - val_accuracy: 0.5448\n",
            "Epoch 240/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.5444 - accuracy: 0.6580\n",
            "Epoch 240: val_loss improved from 1.85511 to 1.84295, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.5438 - accuracy: 0.6580 - val_loss: 1.8430 - val_accuracy: 0.5480\n",
            "Epoch 241/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.5351 - accuracy: 0.6608\n",
            "Epoch 241: val_loss improved from 1.84295 to 1.83908, saving model to best_model.h5\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 1.5359 - accuracy: 0.6605 - val_loss: 1.8391 - val_accuracy: 0.5477\n",
            "Epoch 242/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.5316 - accuracy: 0.6634\n",
            "Epoch 242: val_loss did not improve from 1.83908\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5314 - accuracy: 0.6635 - val_loss: 1.8397 - val_accuracy: 0.5475\n",
            "Epoch 243/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.6627\n",
            "Epoch 243: val_loss improved from 1.83908 to 1.83754, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.5270 - accuracy: 0.6631 - val_loss: 1.8375 - val_accuracy: 0.5414\n",
            "Epoch 244/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.5164 - accuracy: 0.6618\n",
            "Epoch 244: val_loss improved from 1.83754 to 1.82922, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.5165 - accuracy: 0.6619 - val_loss: 1.8292 - val_accuracy: 0.5436\n",
            "Epoch 245/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.5164 - accuracy: 0.6661\n",
            "Epoch 245: val_loss improved from 1.82922 to 1.82413, saving model to best_model.h5\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 1.5165 - accuracy: 0.6664 - val_loss: 1.8241 - val_accuracy: 0.5504\n",
            "Epoch 246/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.5097 - accuracy: 0.6627\n",
            "Epoch 246: val_loss improved from 1.82413 to 1.82093, saving model to best_model.h5\n",
            "938/938 [==============================] - 16s 17ms/step - loss: 1.5101 - accuracy: 0.6628 - val_loss: 1.8209 - val_accuracy: 0.5490\n",
            "Epoch 247/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.5044 - accuracy: 0.6642\n",
            "Epoch 247: val_loss did not improve from 1.82093\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.5039 - accuracy: 0.6645 - val_loss: 1.8210 - val_accuracy: 0.5439\n",
            "Epoch 248/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.5047 - accuracy: 0.6665\n",
            "Epoch 248: val_loss improved from 1.82093 to 1.81798, saving model to best_model.h5\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 1.5040 - accuracy: 0.6668 - val_loss: 1.8180 - val_accuracy: 0.5451\n",
            "Epoch 249/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.4942 - accuracy: 0.6662\n",
            "Epoch 249: val_loss improved from 1.81798 to 1.81593, saving model to best_model.h5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 1.4944 - accuracy: 0.6659 - val_loss: 1.8159 - val_accuracy: 0.5468\n",
            "Epoch 250/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.4925 - accuracy: 0.6680\n",
            "Epoch 250: val_loss improved from 1.81593 to 1.80926, saving model to best_model.h5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 1.4932 - accuracy: 0.6676 - val_loss: 1.8093 - val_accuracy: 0.5484\n",
            "Epoch 251/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.4854 - accuracy: 0.6719\n",
            "Epoch 251: val_loss did not improve from 1.80926\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.4856 - accuracy: 0.6718 - val_loss: 1.8128 - val_accuracy: 0.5486\n",
            "Epoch 252/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.4808 - accuracy: 0.6721\n",
            "Epoch 252: val_loss did not improve from 1.80926\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4799 - accuracy: 0.6724 - val_loss: 1.8097 - val_accuracy: 0.5497\n",
            "Epoch 253/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.6708\n",
            "Epoch 253: val_loss improved from 1.80926 to 1.80413, saving model to best_model.h5\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 1.4750 - accuracy: 0.6708 - val_loss: 1.8041 - val_accuracy: 0.5499\n",
            "Epoch 254/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.4731 - accuracy: 0.6712\n",
            "Epoch 254: val_loss did not improve from 1.80413\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4728 - accuracy: 0.6712 - val_loss: 1.8043 - val_accuracy: 0.5497\n",
            "Epoch 255/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.4658 - accuracy: 0.6715\n",
            "Epoch 255: val_loss improved from 1.80413 to 1.79892, saving model to best_model.h5\n",
            "938/938 [==============================] - 19s 20ms/step - loss: 1.4659 - accuracy: 0.6713 - val_loss: 1.7989 - val_accuracy: 0.5497\n",
            "Epoch 256/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.4635 - accuracy: 0.6721\n",
            "Epoch 256: val_loss improved from 1.79892 to 1.79381, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.4635 - accuracy: 0.6720 - val_loss: 1.7938 - val_accuracy: 0.5500\n",
            "Epoch 257/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.4581 - accuracy: 0.6717\n",
            "Epoch 257: val_loss improved from 1.79381 to 1.79350, saving model to best_model.h5\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 1.4581 - accuracy: 0.6717 - val_loss: 1.7935 - val_accuracy: 0.5456\n",
            "Epoch 258/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.4560 - accuracy: 0.6758\n",
            "Epoch 258: val_loss improved from 1.79350 to 1.78955, saving model to best_model.h5\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 1.4558 - accuracy: 0.6758 - val_loss: 1.7896 - val_accuracy: 0.5467\n",
            "Epoch 259/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.4464 - accuracy: 0.6770\n",
            "Epoch 259: val_loss improved from 1.78955 to 1.78634, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.4468 - accuracy: 0.6768 - val_loss: 1.7863 - val_accuracy: 0.5467\n",
            "Epoch 260/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.4459 - accuracy: 0.6766\n",
            "Epoch 260: val_loss improved from 1.78634 to 1.78358, saving model to best_model.h5\n",
            "938/938 [==============================] - 20s 21ms/step - loss: 1.4458 - accuracy: 0.6766 - val_loss: 1.7836 - val_accuracy: 0.5469\n",
            "Epoch 261/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.4404 - accuracy: 0.6765\n",
            "Epoch 261: val_loss improved from 1.78358 to 1.78287, saving model to best_model.h5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.4404 - accuracy: 0.6765 - val_loss: 1.7829 - val_accuracy: 0.5476\n",
            "Epoch 262/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.4373 - accuracy: 0.6799\n",
            "Epoch 262: val_loss improved from 1.78287 to 1.77897, saving model to best_model.h5\n",
            "938/938 [==============================] - 19s 21ms/step - loss: 1.4375 - accuracy: 0.6795 - val_loss: 1.7790 - val_accuracy: 0.5495\n",
            "Epoch 263/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.4352 - accuracy: 0.6772\n",
            "Epoch 263: val_loss did not improve from 1.77897\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4351 - accuracy: 0.6772 - val_loss: 1.7804 - val_accuracy: 0.5492\n",
            "Epoch 264/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.4279 - accuracy: 0.6801\n",
            "Epoch 264: val_loss did not improve from 1.77897\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.4280 - accuracy: 0.6801 - val_loss: 1.7792 - val_accuracy: 0.5490\n",
            "Epoch 265/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.4249 - accuracy: 0.6810\n",
            "Epoch 265: val_loss improved from 1.77897 to 1.77720, saving model to best_model.h5\n",
            "938/938 [==============================] - 20s 21ms/step - loss: 1.4250 - accuracy: 0.6810 - val_loss: 1.7772 - val_accuracy: 0.5473\n",
            "Epoch 266/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.4205 - accuracy: 0.6840\n",
            "Epoch 266: val_loss did not improve from 1.77720\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.4210 - accuracy: 0.6833 - val_loss: 1.7777 - val_accuracy: 0.5472\n",
            "Epoch 267/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.4148 - accuracy: 0.6842\n",
            "Epoch 267: val_loss did not improve from 1.77720\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.4148 - accuracy: 0.6841 - val_loss: 1.7772 - val_accuracy: 0.5486\n",
            "Epoch 268/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.4178 - accuracy: 0.6799\n",
            "Epoch 268: val_loss improved from 1.77720 to 1.77154, saving model to best_model.h5\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 1.4179 - accuracy: 0.6798 - val_loss: 1.7715 - val_accuracy: 0.5483\n",
            "Epoch 269/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.4134 - accuracy: 0.6812\n",
            "Epoch 269: val_loss improved from 1.77154 to 1.76855, saving model to best_model.h5\n",
            "938/938 [==============================] - 21s 23ms/step - loss: 1.4130 - accuracy: 0.6813 - val_loss: 1.7685 - val_accuracy: 0.5505\n",
            "Epoch 270/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.4048 - accuracy: 0.6841\n",
            "Epoch 270: val_loss improved from 1.76855 to 1.76519, saving model to best_model.h5\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 1.4048 - accuracy: 0.6841 - val_loss: 1.7652 - val_accuracy: 0.5491\n",
            "Epoch 271/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.4038 - accuracy: 0.6833\n",
            "Epoch 271: val_loss did not improve from 1.76519\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4036 - accuracy: 0.6836 - val_loss: 1.7665 - val_accuracy: 0.5464\n",
            "Epoch 272/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.4020 - accuracy: 0.6852\n",
            "Epoch 272: val_loss improved from 1.76519 to 1.76159, saving model to best_model.h5\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 1.4017 - accuracy: 0.6855 - val_loss: 1.7616 - val_accuracy: 0.5511\n",
            "Epoch 273/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.3925 - accuracy: 0.6867\n",
            "Epoch 273: val_loss did not improve from 1.76159\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3926 - accuracy: 0.6868 - val_loss: 1.7662 - val_accuracy: 0.5494\n",
            "Epoch 274/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.3960 - accuracy: 0.6860\n",
            "Epoch 274: val_loss did not improve from 1.76159\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3960 - accuracy: 0.6860 - val_loss: 1.7620 - val_accuracy: 0.5446\n",
            "Epoch 275/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.3855 - accuracy: 0.6877\n",
            "Epoch 275: val_loss improved from 1.76159 to 1.76032, saving model to best_model.h5\n",
            "938/938 [==============================] - 19s 21ms/step - loss: 1.3855 - accuracy: 0.6878 - val_loss: 1.7603 - val_accuracy: 0.5507\n",
            "Epoch 276/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.3854 - accuracy: 0.6881\n",
            "Epoch 276: val_loss did not improve from 1.76032\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.3861 - accuracy: 0.6880 - val_loss: 1.7604 - val_accuracy: 0.5486\n",
            "Epoch 277/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3825 - accuracy: 0.6899\n",
            "Epoch 277: val_loss improved from 1.76032 to 1.75596, saving model to best_model.h5\n",
            "938/938 [==============================] - 20s 21ms/step - loss: 1.3823 - accuracy: 0.6900 - val_loss: 1.7560 - val_accuracy: 0.5530\n",
            "Epoch 278/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.3821 - accuracy: 0.6885\n",
            "Epoch 278: val_loss did not improve from 1.75596\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3821 - accuracy: 0.6885 - val_loss: 1.7567 - val_accuracy: 0.5516\n",
            "Epoch 279/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.3817 - accuracy: 0.6889\n",
            "Epoch 279: val_loss improved from 1.75596 to 1.75556, saving model to best_model.h5\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 1.3817 - accuracy: 0.6890 - val_loss: 1.7556 - val_accuracy: 0.5511\n",
            "Epoch 280/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3765 - accuracy: 0.6889\n",
            "Epoch 280: val_loss did not improve from 1.75556\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3762 - accuracy: 0.6891 - val_loss: 1.7576 - val_accuracy: 0.5482\n",
            "Epoch 281/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.3711 - accuracy: 0.6916\n",
            "Epoch 281: val_loss improved from 1.75556 to 1.75429, saving model to best_model.h5\n",
            "938/938 [==============================] - 30s 32ms/step - loss: 1.3710 - accuracy: 0.6917 - val_loss: 1.7543 - val_accuracy: 0.5483\n",
            "Epoch 282/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.3693 - accuracy: 0.6910\n",
            "Epoch 282: val_loss did not improve from 1.75429\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3692 - accuracy: 0.6909 - val_loss: 1.7592 - val_accuracy: 0.5498\n",
            "Epoch 283/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.3655 - accuracy: 0.6919\n",
            "Epoch 283: val_loss improved from 1.75429 to 1.75114, saving model to best_model.h5\n",
            "938/938 [==============================] - 30s 33ms/step - loss: 1.3656 - accuracy: 0.6919 - val_loss: 1.7511 - val_accuracy: 0.5508\n",
            "Epoch 284/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.3645 - accuracy: 0.6920\n",
            "Epoch 284: val_loss did not improve from 1.75114\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3645 - accuracy: 0.6920 - val_loss: 1.7554 - val_accuracy: 0.5464\n",
            "Epoch 285/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.3595 - accuracy: 0.6917\n",
            "Epoch 285: val_loss improved from 1.75114 to 1.74678, saving model to best_model.h5\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 1.3599 - accuracy: 0.6917 - val_loss: 1.7468 - val_accuracy: 0.5514\n",
            "Epoch 286/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.3547 - accuracy: 0.6955\n",
            "Epoch 286: val_loss did not improve from 1.74678\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.3546 - accuracy: 0.6957 - val_loss: 1.7481 - val_accuracy: 0.5493\n",
            "Epoch 287/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3564 - accuracy: 0.6939\n",
            "Epoch 287: val_loss did not improve from 1.74678\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3565 - accuracy: 0.6939 - val_loss: 1.7581 - val_accuracy: 0.5512\n",
            "Epoch 288/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.3486 - accuracy: 0.6981\n",
            "Epoch 288: val_loss did not improve from 1.74678\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3483 - accuracy: 0.6982 - val_loss: 1.7468 - val_accuracy: 0.5518\n",
            "Epoch 289/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.3457 - accuracy: 0.6980\n",
            "Epoch 289: val_loss improved from 1.74678 to 1.74541, saving model to best_model.h5\n",
            "938/938 [==============================] - 36s 38ms/step - loss: 1.3455 - accuracy: 0.6977 - val_loss: 1.7454 - val_accuracy: 0.5527\n",
            "Epoch 290/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.3485 - accuracy: 0.6974\n",
            "Epoch 290: val_loss improved from 1.74541 to 1.74264, saving model to best_model.h5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 1.3487 - accuracy: 0.6975 - val_loss: 1.7426 - val_accuracy: 0.5494\n",
            "Epoch 291/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3374 - accuracy: 0.6995\n",
            "Epoch 291: val_loss improved from 1.74264 to 1.74077, saving model to best_model.h5\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 1.3377 - accuracy: 0.6993 - val_loss: 1.7408 - val_accuracy: 0.5497\n",
            "Epoch 292/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.3378 - accuracy: 0.6996\n",
            "Epoch 292: val_loss did not improve from 1.74077\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3379 - accuracy: 0.6996 - val_loss: 1.7434 - val_accuracy: 0.5508\n",
            "Epoch 293/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3361 - accuracy: 0.7009\n",
            "Epoch 293: val_loss did not improve from 1.74077\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3360 - accuracy: 0.7009 - val_loss: 1.7421 - val_accuracy: 0.5505\n",
            "Epoch 294/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3352 - accuracy: 0.7007\n",
            "Epoch 294: val_loss did not improve from 1.74077\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3353 - accuracy: 0.7007 - val_loss: 1.7449 - val_accuracy: 0.5497\n",
            "Epoch 295/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.3314 - accuracy: 0.7030\n",
            "Epoch 295: val_loss improved from 1.74077 to 1.73691, saving model to best_model.h5\n",
            "938/938 [==============================] - 56s 60ms/step - loss: 1.3316 - accuracy: 0.7027 - val_loss: 1.7369 - val_accuracy: 0.5500\n",
            "Epoch 296/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.3259 - accuracy: 0.7051\n",
            "Epoch 296: val_loss did not improve from 1.73691\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3261 - accuracy: 0.7051 - val_loss: 1.7405 - val_accuracy: 0.5513\n",
            "Epoch 297/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.3321 - accuracy: 0.7007\n",
            "Epoch 297: val_loss did not improve from 1.73691\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3319 - accuracy: 0.7007 - val_loss: 1.7386 - val_accuracy: 0.5483\n",
            "Epoch 298/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.3222 - accuracy: 0.7058\n",
            "Epoch 298: val_loss did not improve from 1.73691\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3224 - accuracy: 0.7057 - val_loss: 1.7377 - val_accuracy: 0.5459\n",
            "Epoch 299/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.3213 - accuracy: 0.7026\n",
            "Epoch 299: val_loss improved from 1.73691 to 1.73595, saving model to best_model.h5\n",
            "938/938 [==============================] - 36s 38ms/step - loss: 1.3211 - accuracy: 0.7027 - val_loss: 1.7359 - val_accuracy: 0.5517\n",
            "Epoch 300/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.3139 - accuracy: 0.7077\n",
            "Epoch 300: val_loss did not improve from 1.73595\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.3141 - accuracy: 0.7078 - val_loss: 1.7410 - val_accuracy: 0.5503\n",
            "Epoch 301/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.3183 - accuracy: 0.7037\n",
            "Epoch 301: val_loss did not improve from 1.73595\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3178 - accuracy: 0.7044 - val_loss: 1.7420 - val_accuracy: 0.5479\n",
            "Epoch 302/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.3154 - accuracy: 0.7033\n",
            "Epoch 302: val_loss did not improve from 1.73595\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.3154 - accuracy: 0.7033 - val_loss: 1.7386 - val_accuracy: 0.5522\n",
            "Epoch 303/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.3151 - accuracy: 0.7027\n",
            "Epoch 303: val_loss did not improve from 1.73595\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.3149 - accuracy: 0.7028 - val_loss: 1.7379 - val_accuracy: 0.5510\n",
            "Epoch 304/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.3058 - accuracy: 0.7091\n",
            "Epoch 304: val_loss improved from 1.73595 to 1.72932, saving model to best_model.h5\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 1.3058 - accuracy: 0.7091 - val_loss: 1.7293 - val_accuracy: 0.5517\n",
            "Epoch 305/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.3109 - accuracy: 0.7074\n",
            "Epoch 305: val_loss did not improve from 1.72932\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3109 - accuracy: 0.7074 - val_loss: 1.7337 - val_accuracy: 0.5505\n",
            "Epoch 306/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.3045 - accuracy: 0.7080\n",
            "Epoch 306: val_loss did not improve from 1.72932\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.3044 - accuracy: 0.7079 - val_loss: 1.7424 - val_accuracy: 0.5500\n",
            "Epoch 307/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.3024 - accuracy: 0.7103\n",
            "Epoch 307: val_loss improved from 1.72932 to 1.72894, saving model to best_model.h5\n",
            "938/938 [==============================] - 19s 21ms/step - loss: 1.3026 - accuracy: 0.7102 - val_loss: 1.7289 - val_accuracy: 0.5519\n",
            "Epoch 308/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.2997 - accuracy: 0.7090\n",
            "Epoch 308: val_loss did not improve from 1.72894\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.2999 - accuracy: 0.7088 - val_loss: 1.7367 - val_accuracy: 0.5478\n",
            "Epoch 309/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.2997 - accuracy: 0.7132\n",
            "Epoch 309: val_loss did not improve from 1.72894\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2995 - accuracy: 0.7133 - val_loss: 1.7449 - val_accuracy: 0.5463\n",
            "Epoch 310/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.2963 - accuracy: 0.7112\n",
            "Epoch 310: val_loss did not improve from 1.72894\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2962 - accuracy: 0.7113 - val_loss: 1.7317 - val_accuracy: 0.5510\n",
            "Epoch 311/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.2916 - accuracy: 0.7152\n",
            "Epoch 311: val_loss did not improve from 1.72894\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2920 - accuracy: 0.7151 - val_loss: 1.7312 - val_accuracy: 0.5468\n",
            "Epoch 312/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.2977 - accuracy: 0.7130\n",
            "Epoch 312: val_loss did not improve from 1.72894\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2975 - accuracy: 0.7130 - val_loss: 1.7330 - val_accuracy: 0.5544\n",
            "Epoch 313/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.2850 - accuracy: 0.7150\n",
            "Epoch 313: val_loss did not improve from 1.72894\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2856 - accuracy: 0.7147 - val_loss: 1.7417 - val_accuracy: 0.5457\n",
            "Epoch 314/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.2859 - accuracy: 0.7152\n",
            "Epoch 314: val_loss improved from 1.72894 to 1.72797, saving model to best_model.h5\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 1.2859 - accuracy: 0.7152 - val_loss: 1.7280 - val_accuracy: 0.5511\n",
            "Epoch 315/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.2904 - accuracy: 0.7117\n",
            "Epoch 315: val_loss improved from 1.72797 to 1.72785, saving model to best_model.h5\n",
            "938/938 [==============================] - 1861s 2s/step - loss: 1.2904 - accuracy: 0.7117 - val_loss: 1.7278 - val_accuracy: 0.5513\n",
            "Epoch 316/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.2886 - accuracy: 0.7138\n",
            "Epoch 316: val_loss did not improve from 1.72785\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.2892 - accuracy: 0.7137 - val_loss: 1.7294 - val_accuracy: 0.5559\n",
            "Epoch 317/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.2854 - accuracy: 0.7123\n",
            "Epoch 317: val_loss did not improve from 1.72785\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2858 - accuracy: 0.7123 - val_loss: 1.7382 - val_accuracy: 0.5487\n",
            "Epoch 318/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.2787 - accuracy: 0.7193\n",
            "Epoch 318: val_loss improved from 1.72785 to 1.72371, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 1.2792 - accuracy: 0.7192 - val_loss: 1.7237 - val_accuracy: 0.5542\n",
            "Epoch 319/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.2773 - accuracy: 0.7163\n",
            "Epoch 319: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2774 - accuracy: 0.7163 - val_loss: 1.7252 - val_accuracy: 0.5485\n",
            "Epoch 320/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.2752 - accuracy: 0.7181\n",
            "Epoch 320: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2750 - accuracy: 0.7183 - val_loss: 1.7306 - val_accuracy: 0.5476\n",
            "Epoch 321/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.2770 - accuracy: 0.7178\n",
            "Epoch 321: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2766 - accuracy: 0.7180 - val_loss: 1.7274 - val_accuracy: 0.5547\n",
            "Epoch 322/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.2717 - accuracy: 0.7174\n",
            "Epoch 322: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2716 - accuracy: 0.7175 - val_loss: 1.7298 - val_accuracy: 0.5540\n",
            "Epoch 323/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.2703 - accuracy: 0.7185\n",
            "Epoch 323: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2710 - accuracy: 0.7185 - val_loss: 1.7277 - val_accuracy: 0.5527\n",
            "Epoch 324/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.2709 - accuracy: 0.7167\n",
            "Epoch 324: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2708 - accuracy: 0.7168 - val_loss: 1.7243 - val_accuracy: 0.5516\n",
            "Epoch 325/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.2711 - accuracy: 0.7206\n",
            "Epoch 325: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2712 - accuracy: 0.7206 - val_loss: 1.7287 - val_accuracy: 0.5530\n",
            "Epoch 326/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.2715 - accuracy: 0.7185\n",
            "Epoch 326: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2716 - accuracy: 0.7184 - val_loss: 1.7300 - val_accuracy: 0.5516\n",
            "Epoch 327/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.2633 - accuracy: 0.7196\n",
            "Epoch 327: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2637 - accuracy: 0.7193 - val_loss: 1.7257 - val_accuracy: 0.5517\n",
            "Epoch 328/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.2653 - accuracy: 0.7205\n",
            "Epoch 328: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2650 - accuracy: 0.7205 - val_loss: 1.7309 - val_accuracy: 0.5443\n",
            "Epoch 329/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.2650 - accuracy: 0.7191\n",
            "Epoch 329: val_loss did not improve from 1.72371\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2648 - accuracy: 0.7191 - val_loss: 1.7313 - val_accuracy: 0.5520\n",
            "Epoch 330/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.2561 - accuracy: 0.7217\n",
            "Epoch 330: val_loss improved from 1.72371 to 1.72051, saving model to best_model.h5\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 1.2559 - accuracy: 0.7217 - val_loss: 1.7205 - val_accuracy: 0.5502\n",
            "Epoch 331/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.2579 - accuracy: 0.7219\n",
            "Epoch 331: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2579 - accuracy: 0.7219 - val_loss: 1.7320 - val_accuracy: 0.5545\n",
            "Epoch 332/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.2531 - accuracy: 0.7261\n",
            "Epoch 332: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2536 - accuracy: 0.7260 - val_loss: 1.7252 - val_accuracy: 0.5510\n",
            "Epoch 333/500\n",
            "931/938 [============================>.] - ETA: 0s - loss: 1.2557 - accuracy: 0.7246\n",
            "Epoch 333: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.2559 - accuracy: 0.7246 - val_loss: 1.7271 - val_accuracy: 0.5517\n",
            "Epoch 334/500\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.2501 - accuracy: 0.7261\n",
            "Epoch 334: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2501 - accuracy: 0.7261 - val_loss: 1.7308 - val_accuracy: 0.5484\n",
            "Epoch 335/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.2475 - accuracy: 0.7269\n",
            "Epoch 335: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2471 - accuracy: 0.7270 - val_loss: 1.7321 - val_accuracy: 0.5528\n",
            "Epoch 336/500\n",
            "926/938 [============================>.] - ETA: 0s - loss: 1.2477 - accuracy: 0.7279\n",
            "Epoch 336: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.2475 - accuracy: 0.7278 - val_loss: 1.7250 - val_accuracy: 0.5504\n",
            "Epoch 337/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.2466 - accuracy: 0.7265\n",
            "Epoch 337: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2462 - accuracy: 0.7270 - val_loss: 1.7300 - val_accuracy: 0.5506\n",
            "Epoch 338/500\n",
            "935/938 [============================>.] - ETA: 0s - loss: 1.2455 - accuracy: 0.7261\n",
            "Epoch 338: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2455 - accuracy: 0.7262 - val_loss: 1.7258 - val_accuracy: 0.5512\n",
            "Epoch 339/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.2427 - accuracy: 0.7290\n",
            "Epoch 339: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2428 - accuracy: 0.7288 - val_loss: 1.7248 - val_accuracy: 0.5548\n",
            "Epoch 340/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.2412 - accuracy: 0.7294\n",
            "Epoch 340: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.2412 - accuracy: 0.7293 - val_loss: 1.7231 - val_accuracy: 0.5555\n",
            "Epoch 341/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.2427 - accuracy: 0.7302\n",
            "Epoch 341: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2430 - accuracy: 0.7299 - val_loss: 1.7343 - val_accuracy: 0.5504\n",
            "Epoch 342/500\n",
            "929/938 [============================>.] - ETA: 0s - loss: 1.2444 - accuracy: 0.7289\n",
            "Epoch 342: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2444 - accuracy: 0.7290 - val_loss: 1.7312 - val_accuracy: 0.5514\n",
            "Epoch 343/500\n",
            "936/938 [============================>.] - ETA: 0s - loss: 1.2405 - accuracy: 0.7330\n",
            "Epoch 343: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.2404 - accuracy: 0.7330 - val_loss: 1.7254 - val_accuracy: 0.5516\n",
            "Epoch 344/500\n",
            "930/938 [============================>.] - ETA: 0s - loss: 1.2369 - accuracy: 0.7340\n",
            "Epoch 344: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.2370 - accuracy: 0.7340 - val_loss: 1.7286 - val_accuracy: 0.5520\n",
            "Epoch 345/500\n",
            "927/938 [============================>.] - ETA: 0s - loss: 1.2346 - accuracy: 0.7332\n",
            "Epoch 345: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2341 - accuracy: 0.7336 - val_loss: 1.7342 - val_accuracy: 0.5475\n",
            "Epoch 346/500\n",
            "933/938 [============================>.] - ETA: 0s - loss: 1.2320 - accuracy: 0.7327\n",
            "Epoch 346: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2323 - accuracy: 0.7325 - val_loss: 1.7319 - val_accuracy: 0.5508\n",
            "Epoch 347/500\n",
            "934/938 [============================>.] - ETA: 0s - loss: 1.2326 - accuracy: 0.7292\n",
            "Epoch 347: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.2325 - accuracy: 0.7294 - val_loss: 1.7216 - val_accuracy: 0.5535\n",
            "Epoch 348/500\n",
            "928/938 [============================>.] - ETA: 0s - loss: 1.2335 - accuracy: 0.7298\n",
            "Epoch 348: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.2335 - accuracy: 0.7294 - val_loss: 1.7413 - val_accuracy: 0.5474\n",
            "Epoch 349/500\n",
            "932/938 [============================>.] - ETA: 0s - loss: 1.2298 - accuracy: 0.7338\n",
            "Epoch 349: val_loss did not improve from 1.72051\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 1.2301 - accuracy: 0.7335 - val_loss: 1.7247 - val_accuracy: 0.5514\n",
            "Epoch 350/500\n",
            "937/938 [============================>.] - ETA: 0s - loss: 1.2271 - accuracy: 0.7341\n",
            "Epoch 350: val_loss did not improve from 1.72051\n",
            "Restoring model weights from the end of the best epoch: 330.\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.2270 - accuracy: 0.7341 - val_loss: 1.7278 - val_accuracy: 0.5516\n",
            "Epoch 350: early stopping\n",
            "Training Runtime: 4732.80 seconds\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.6995 - accuracy: 0.5574\n",
            "Test Loss: 1.6995\n",
            "Test Accuracy: 0.5574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8yL_jg93MiL",
        "outputId": "d749f6dd-40f0-4051-8574-b2920e91d130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.60      0.59       956\n",
            "           1       0.68      0.68      0.68      1021\n",
            "           2       0.43      0.40      0.41       992\n",
            "           3       0.39      0.37      0.38      1001\n",
            "           4       0.46      0.54      0.50      1029\n",
            "           5       0.49      0.40      0.44       996\n",
            "           6       0.62      0.62      0.62      1020\n",
            "           7       0.62      0.64      0.63      1007\n",
            "           8       0.65      0.71      0.68       984\n",
            "           9       0.65      0.60      0.63       994\n",
            "\n",
            "    accuracy                           0.56     10000\n",
            "   macro avg       0.56      0.56      0.56     10000\n",
            "weighted avg       0.56      0.56      0.56     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "import numpy as np\n",
        "y_pred = model.predict(X_test_norm)\n",
        "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
        "\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acnn0vsd3yQY",
        "outputId": "9dc313fe-1d82-43f3-8531-da1caf395cd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 8, 9, 9, 1, 0, 3, 6, 4, 3],\n",
              " array([[1, 8, 9, 9, 1, 8, 5, 6, 4, 2]], dtype=uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "y_pred_classes[:10], y_test[:10].T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "W3Q56TNx4VFJ",
        "outputId": "a53b746b-c951-40f8-cfc5-e6e5b66c3dda"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAADcCAYAAADa3YUtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAexElEQVR4nO2de3BU15Xuv+5WP/RodSOBJBpJgJF4GYNsAUIX4sG2AtfOeEws3+Apx8YZV7ghghpMElwql03scqIU/gPHudi+18mgmqkwMNwJcUyu8diyEU4scFAg4SkDFpKM1HoA6taz1eo+9w+C8Olv49MSEmrJ61fVVTqf9jm9+7F6n7XX2mubNE3TIAjCDTGPdgcEIdYRIxEEA8RIBMEAMRJBMECMRBAMECMRBAPESATBADESQTBAjEQQDBAjEQQDRsxItm/fjmnTpsHhcKCgoACffPLJSD2VIIwoppHI3dq9ezeeeOIJvPHGGygoKMArr7yCPXv2oKamBmlpaV96bjgcRmNjI5xOJ0wm03B3TRAAAJqmoaOjAx6PB2azwVihjQCLFy/WSkpKBo5DoZDm8Xi0srIyw3MbGho0APKQxy15NDQ0GH4n4zDM9PX1obq6GqWlpQOa2WxGUVERqqqqqH0gEEAgEBg41v42sDU0NCA5Ofmm+xPuD5GmGjt7enpI6+r0k+Zyu0gzQT/i9QV6qU2zt5G0qqo/kuaZMpm0tHTWQmH9cyYlJlEbS5yNNbOVtMSkRNISnPGk2ax8rsWi/wppijdXpRn+eo8wfr8fWVlZcDqdhm2H3Uja2toQCoWQnp6u09PT03HmzBlqX1ZWhhdeeIH05OTkW2okVsUXwGzihqo+sZHwl1NlcPHx/EVMTEggLUnxJY7GSOLi7KRZLNEZSWIy92M8Gck1ormlH/WelpaWwufzDTwaGhpGu0uCoGPYR5KJEyfCYrGgublZpzc3NyMjI4Pa2+122O38iycIscKwG4nNZkN+fj4qKiqwatUqAFdnrCoqKrB+/fohX1fT+LYJipFSC4f1QogHy0sRBgwAv/w/r5F25MifSLsrfxFpt8+cqTsOdPuozZX2FtLOnjtB2uEDV0jTzHz7dqGhVXfcH+Q3w2Fn/ykx3k2aKzWVtIQJfAs2M3cmaQUFBbrj+fPvoDb2eP4RDIX481Td+gznDOdQrzXsRgIAmzZtwpo1a7Bw4UIsXrwYr7zyCrq6uvCd73xnJJ5OEEaUETGS1atXo7W1Fc8//zy8Xi/y8vKwf/9+cuYFYSwwIkYCAOvXr7+p2ytBiBVGfXZLEGKdEUlLuRn8fj9cLhd8Pp8uJqFp/dzYxJoW1mtmWKjNvv/8D9J+/W87SLt0qYO0z856Sbt97izd8coVX6M2cXFh0hKSOO7Q0dFGWs3ZC6x9elF3bDGzc9zSzBMI4X5+PyZnZZHm7+ki7dLlS6QlJenjM8uWLaM2qx5eRdpdi+4kzeFwkKZiOGIsN/qeKZ/vpp9NEMY5YiSCYIAYiSAYMGKzW8OOie/pQ+E+0tqv6O/pTx4/RG0qP/5P0nLmTSItvo7v88+e40Dk8U/P6Y5bOjlw6HLxfe/EtBTSsrMzSfNeZt+rpVWfkJmawsG/+ER+zra2y6T5fOy7TJ7CfkpPJydutjbpg5q/2f0bavNBxYek/eOaR0n7p6f+ibTUFH6PQiH9d8FsHtkgpIwkgmCAGIkgGCBGIggGiJEIggFjxnFv97LD+WHl26SdrT+mO274nBd69Xbztex97Ph+er6JNLNi4VFkonF9Kzv3JoVm+YwnBjz13E7rZyfU26YPdDa1sPMdZ+GPVxWI62m6SJq/i6/n93NwNfJ31qmYoPBd4ff7tVe3kdZ8sZ60J5/kpNiZs2frji0OXrymipEP1ZmXkUQQDBAjEQQDxEgEwQAxEkEwIGYd987LPpiD152v8ld5ee3+93eRNvVO/VLUtMm8NLW9l526y/XsvKZa2AmNm8jnNlzSO6bWeK40YrWy0xgOctbr5WZ2cs2KDOK4BP31TBpPKJjC/BvY181ZCqps5H4TV3eJc3A/enoCuuOObn6dmVmK2gZmLuH00f59pB0/fJi0FQ/+g+74oW99i9rMmDGDNOV67yiQkUQQDBAjEQQDxEgEwQAxEkEwIGYd9wt1R3XlPQ9+8ha16TVx6vbFFn1a+bSsCdTGYudU9qQkdqKT3VNI6+hgx9fXrne2r/RxarvNxtcPhfnt1xTOZX+ok7Ww/rUnJXCZ0/5AkDRLHPffalNE5i38++mI5/pfwaC+H52dHJWvq+fnzJnGuwuoah63tfBExvZf/C/dcc2FC9Rm69aXSXO73aRFg4wkgmCAGIkgGCBGIggGiJEIggEx67hnTMmE03ndGV34d/OpTbfCob1tjr6eky3EdaYa+7godXsTaw1nT5PmTOA11w6rPhKdmcFOtD2e3+qLF7n/icns4F9q4+h0OCI/P9DLBahDfRwht1o4GyCkSMW3Kzb70TR+L+Mi9jvRNJ4s6OoKkHai5gJpE51c4HtCMk+8JCbqX1dDPW/XodqUSRx3QRghxEgEwQAxEkEwIGZ9kolpOboarffc9yC1+eWOn5LmdusDXitWcn2nKVN42ezvmi6QFkjgjN/uAAfGAkH9/e+S3BxqM+uOaaT9oeoYaUET378nOtlPudKi9w8ut3LtXrPGr9NsVtTbVVSDVtXlNZvYT7HG6f2vDj+/P8EQP0FA4StGLkkGAG8T1x9OTdNndn/j/m9wG8XGRENFRhJBMECMRBAMECMRBAPESATBgJh13IHw3x5XuWv+fdRixZJzpL3/zr/rjpvPb6U2C/I5uzc3lwOAve3sRNfWtpOWaNWf62/gpa8XbXWkZU7kwGRmrps0vyL42dqq71tLYze1OX+KNwTquMT1tDSwQ+5rV0xQBBQBy37972xI4aSHNQ5WhhTBSlVdrKxMzgz+Xsla3fFjjz9ObayK+mhDRUYSQTBAjEQQDBi0kRw8eBAPPvggPB4PTCYTfvvb3+r+r2kann/+eUyePBnx8fEoKirC2bNnh6u/gnDLGbSRdHV1YcGCBdi+fbvy/1u3bsWrr76KN954A4cPH0ZiYiJWrlyJ3l5eRSgIY4Gb2n3XZDJh7969WLVqFYCro4jH48EPfvAD/PCHPwRwdRel9PR0lJeX49FHOfodyfVdUdv0u6KGOULb38MR2uPHDuqO331nJ7W52HCUtCyPW3F9LsRcV8tOef1n+mzegCIqf6WblwyHbfyaps3iGlVhC0fTJ07S1wTL9EyjNm0t3NeWJl4Oa4vj19nTydm87X6eyPC26icMLl3mH8N+cPS+38RLgdHHr7NwEWd//8u//lJ3nDk1m9poigkE0xeKhfv9frjco7D7bm1tLbxeL4qKigY0l8uFgoICVFVVKc8JBALw+/26hyDEEsNqJF7v1T3O09PTdXp6evrA/yIpKyuDy+UaeGQp9hQXhNFk1Ge3SktL4fP5Bh4NDbyARhBGk2E1koyMq/fTzc36jWiam5sH/heJ3W5HcnKy7iEIscSwRtynT5+OjIwMVFRUIC8vD8BVB+nw4cNYt27dELp2vXuKoC3MCbw71Z1LV+qOp2Tyls9v/bqctDNn/kJafR3vvOROnkhadrb+9tLr5fRuWyL3o1mxA1Rzg2Lb7cu8FPXTfv2khdvdTm0c8TwxADNHzZ2JfH2L4v2Ot7KznTtjqv7yca3UprGFHXKrWVFzzMTO9vmzp0j79b/u0B0nTeAlvovzFpO2aGkhadEwaCPp7OzEuXPX00Fqa2tx7NgxpKSkIDs7Gxs3bsRLL72E3NxcTJ8+Hc899xw8Hs/ADJggjDUGbSRHjhzBPffcM3C8adMmAMCaNWtQXl6OzZs3o6urC2vXrkV7ezuWLVuG/fv3KxfxCMJYYNBGsnz5cuWmjdcwmUx48cUX8eKLL95UxwQhVhj12S1BiHViOFXeBMOdiVQDWkTdJ//Fz6lJQpijyTawkztnbh5fX7H7VcMZ/TbYThvXu0pJdJKW6GRH2GTnFO8ku5u0i3X6lPdLzVykW1O8QSZFWrzJwu9HX4id+X7F5xHv1E8ExDm4rpfJxI47Qqw5FJMKHhdPlLz/G/3W5PUXeSvxpffeQ1rOzNyBv/0dqu221chIIggGiJEIggFiJIJggBiJIBgQw467nrBi2tmscEyveBt1x0f/+BG1+fwCrzf3enk9+KpvryLtvgdWk3bov/RbK//m3/43tTlxpoY0ZwoXiM6bfQdpHWn8MfV01uqO29s5e9pu4xT4zk5eCx9WbG+tgc/VFBMe7Zf1DngwrEjFd/D14xVL0NNd/H6kuXiipK2lXd+vAE+UnDh+krS6uuufe2cnFyu/ETKSCIIBYiSCYIAYiSAYMGZ8Es3M952Bbr4Prz2lX5rbF+Lzcu7MJy0zbyFpDjdnlyalcK2s5Q99S3dsjedC1e7f7yXNbuUAYJxiR+GTn7E/0xPQL6W1OTgQpwoS2hI4SBgK8dcg3MdOg9nE13Mm6oOwE1LSqU1/kF+TGdzfBbNnkNbc1Eya94ref+wzc1C2p5dfZ1vr9Qzlrm5FgPMGyEgiCAaIkQiCAWIkgmCAGIkgGDBmHPdwmJe11tefIa27Q798dPJt7AzOXbyEtC6Fo9fYwoGxHoUTGmfXZ74ufaCY2kzIYIf2o/3/QVqCiYNcNtN50tqv6LOA594+k9qkTlTUCzDx+9jYyFm0lyICdgCQ6uZM5tmz9c/bq6g5du4sFzafnMY1D4IBdqYvNnPfuqCfjAnF8W+9WVEM8cqV64XHu7s5qHojZCQRBAPESATBADESQTBAjEQQDBgzjrs5zEtHTf0cTYdVb/fTZ+VRk7TsuaR1dvJyToujnfth4rcscoemODtXhrlt9jzS/ut3/5c0a5gj3alOjvJnpekd5KmeNGoTDClqePl5gqJLkRmc6uT3dukd7Li70vWv/aMj7GiHFcWr0xSO+8nTn5F2pZM/97BJn9EQ0rivvSE+T7NYlH8bISOJIBggRiIIBoiRCIIBYiSCYMCYcdzjzJx+brXwck+LXV+nKXvG7YqrcWp1YiKnxSckuElTbaNsVmh0fSc7vRkeLqJ9+o8HSbPE8Wt/9PFv6441xc+dv4sj2K4JbtImpHJtK62LHfCWmgrSmhov6o5VO2RNSvGQ9nkjF9a+othJKwx+7eGQfolBnCLibnfwea4vLH2IUxT/vhEykgiCAWIkgmCAGIkgGCBGIggGjBnHXVU82zWBHUJn8iTdscXKDnNYsaOSyag497V2Kic9QtLCiuvHcSFpzxR23I+o6kFZk0haUfyPuuMZszhVPqyIRJutioJXimLhtX/lCYRfH2Wtr1f/ujovcd2BCVP4tZsT2bHu6uXJgn5FjYLIQuB9AXb4VRMUKampA3/b7Pz8N0JGEkEwQIxEEAwQIxEEA8aOT6LwI9yTUhXN9A6CaiMbs0nx2xCdS6Ikskyxars81eUTEvhePaC4v+7o4bM7gxH36nHRBce40pfad/n03AV+zk5u5/frtQmKwGGSmz+nusstpPUoOtev2HbZbNZ/fv2Kpd05OTmkTZt6fafgDtnERxCGDzESQTBgUEZSVlaGRYsWwel0Ii0tDatWrUJNjb4EZ29vL0pKSpCamoqkpCQUFxejuZlLVQrCWGFQRlJZWYmSkhIcOnQI7733HoLBIFasWIGuLyTSPf3003j77bexZ88eVFZWorGxEQ8//PCwd1wQbhWDctz379+vOy4vL0daWhqqq6tx9913w+fz4Ve/+hV27tyJe++9FwCwY8cOzJkzB4cOHcKSJVzvKmoUxZphYRvXNH1gTBn8G2HUT8kFoltaORO2W1XIWVGA22RSLF2OQOWQa4rOaWHu2yUvj/7BALdrvaJ3gINxvNTYmc6Oe/P5s6R1BxSfsSK9OT4ig9eimJxZvvzvSJuUdr0fdsXGQjfipnwSn+9qgbSUv1Var66uRjAYRFFR0UCb2bNnIzs7G1VVVcprBAIB+P1+3UMQYokhG0k4HMbGjRuxdOlSzJt3tciB1+uFzWaD2+3WtU1PT4fX61Vep6ysDC6Xa+CRlZU11C4JwogwZCMpKSnBiRMnsGvXrpvqQGlpKXw+38CjoaHhpq4nCMPNkIKJ69evx759+3Dw4EFkZl5P0svIyEBfXx/a29t1o0lzczMyMriEDADY7XbYB5FsJgi3mkEZiaZp2LBhA/bu3YsDBw5g+vTpuv/n5+fDarWioqICxcVXi0bX1NSgvr4ehYWFN9VRDSpHlR02UDRd4UUrTlMSpc8fGWA3KQboplp2VM+dPEVaKMznWh1cx8tmj3Q8o9udOKzQTCEOdQd7uOC0SbWE2paoO+5RZDPUKYpeX/FxtnO/4nOx29jB7ouoJ3bXojxq89Cqf+CLDZFBGUlJSQl27tyJt956C06nc8DPcLlciI+Ph8vlwlNPPYVNmzYhJSUFycnJ2LBhAwoLC29uZksQRpFBGcnrr78OAFi+fLlO37FjB5588kkAwLZt22A2m1FcXIxAIICVK1fitddeG5bOCsJoMOjbLSMcDge2b9+O7du3D7lTghBLSO6WIBgwZlLlTYpaWVF51qrBT6Wp/HvlwMlif2TDIKduHz34EWlt9Y2kdfTw9W9LzyYtLW1yhKIoKK7SFEuLLYpi5H2RqfgAuvu5ndup38ErFOTf3c/qLpLWpSjcHacoYh0GR+E92fp0/JJ//mdqMyPnNtKGiowkgmCAGIkgGCBGIggGiJEIggFjxnEfsj0rA+6qSL0iOh3mSHSonx1JS0TB5u7OS9TmzF+PkdbW2k6aX+G45y3kQOy1zOuBfoU4jT1yLTgA5WyEyayoaZbC9cp6g7wjltavn1BpafRRm0vt7aRZFH2zO3hyprefHfxvP/6Y7viBb/x3ahNW1T4b4qoJGUkEwQAxEkEwQIxEEAwYQz7J0FAtYVWX82X/oz/ItZm8TbzeJbKs7YW/cnavr4XrTPkUAbXJ03JJ+9o995E2VJSbEMVxEG9qzjTSkpLZZzh19JzuuK2NfYFAPwdXncmJpLlSeFOmxf+tgLTVj/4P0giFjznU4moykgiCAWIkgmCAGIkgGCBGIggGjHvHvbODSxS1tHBW6tTMdNJUS++dNp4IOHNEXy7p0HuV1MbfxgHGzg523P/+EXbSp89iZz4SiyKDVonSd+WvwdQZs0lzp/IOxSZzrb4fiqsnJfAS3Ph4ngQoLGQnvfS5UtKmZOqzgMMaT7qYTVG+H1EgI4kgGCBGIggGiJEIggFiJIJgwLh33G1x/DvgV0S//1z/KWnxFs74bW/lJbcnjxzWHZ8/fpratDRyHavsGXNIW/Hg10lTRY+p1leUKa7RxpyTXYqJDEc8adaIiYy0NM4e7ovjGZCCu+8hbe26/0nalKwppIXD+s9FtXHZ8MXbZSQRBEPESATBADESQTBAjEQQDBj3jrsjnlOy5y24i7Tmhs9Ia2uqJa2ujvdZOXVWvytUe4ifM3dJPmkPP/4EadNnziRNVSxcuc125HlK7zW6AuIJiVyke+YsjsI31dbpji/3cKT7zq8VkfbYk2tJ80zJJC2sWpYcscPZcDrpKmQkEQQDxEgEwQAxEkEwQIxEEAwY9457SLHFsdmRRJrJwZHifjM74KlTckhbdr9+xy/PVHa+78ibT5p7Im/drNqJSumBR+GZhhXnKZ15jZ3jNi8vJ+gN8MkpafrIfGH+Mmrz949+hzSXe5Kib4rduszGKe8jvQm5jCSCYIAYiSAYIEYiCAaIkQiCAePecVelkPcH2VH1+bkQ3YSJaaTdfscdpDkS3frntHC0WlWUWlW4W5nyrtxxK7KdwulVpNirLn/uLGcb/L/f/Y60zBQPaV/7un5Hqbwld1ObaJ30aNP9bzUykgiCAYMyktdffx3z589HcnIykpOTUVhYiHfeeWfg/729vSgpKUFqaiqSkpJQXFyM5ubmL7miIMQ+gzKSzMxM/OxnP0N1dTWOHDmCe++9Fw899BBOnjwJAHj66afx9ttvY8+ePaisrERjYyMefvjhEem4INwqTFo0m7N/CSkpKXj55ZfxyCOPYNKkSdi5cyceeeQRAMCZM2cwZ84cVFVVYckS3ohGhd/vh8vlgs/nQ3Jy8oA+1G6qTlP5AtHev2shXtIb1iKzUjkApixUrfBTooV6qwgIhhWFqk8rNhP6uOpPpM29g7OWlxaw1tvdpTu22BVLfOMTSIsiiXnY+eJncKPvmYohdzUUCmHXrl3o6upCYWEhqqurEQwGUVR0PS169uzZyM7ORlVV1ZdcSRBim0HPbh0/fhyFhYXo7e1FUlIS9u7di7lz5+LYsWOw2Wxwu9269unp6fB6eQ3GNQKBAAKBwMCx388VFwVhNBn0SDJr1iwcO3YMhw8fxrp167BmzRqcOsX7cURLWVkZXC7XwCMrK2vI1xKEkWDQRmKz2ZCTk4P8/HyUlZVhwYIF+PnPf46MjAz09fWhPWITyebmZmRkZNzweqWlpfD5fAOPhgbeJEcQRpObDiaGw2EEAgHk5+fDarWioqICxcXFAICamhrU19ejsLDwhufb7XbYVZWpIxhqoMmk3PEout8G5WSBRdVX475F23tVdzXVyRF9U2XLfl5/gbRPT/2VtGVLuVD13DzWVCREfnYqjzw2Y4RRMygjKS0txf3334/s7Gx0dHRg586dOHDgAN599124XC489dRT2LRpE1JSUpCcnIwNGzagsLAw6pktQYhFBmUkLS0teOKJJ9DU1ASXy4X58+fj3Xffxde/frXq4LZt22A2m1FcXIxAIICVK1fitddeG5GOC8Kt4qbjJMPNYOavo2PotTSUb43i1HCEGO0NnqoX0d5uRfZNFXKpP8flVv/08UHSZs/LIy3a2y1T5KsdI7dbg/mexVyC47UPf/imgr+6RtLR0Uladw9vHNTZ2UVatO//WDYSILogdcwZSUfH1WxcmQoWbgUdHR1wuXhr7C8Sc7db4XAYjY2NcDqd6OjoQFZWFhoaGobp1ksYDH6/f9y+/5qmoaOjAx6PB2bzl892xtxIYjabkZl5tZLftWnfa1nHwugwXt9/oxHkGrKeRBAMECMRBANi2kjsdju2bNkSVUReGH7k/b9KzDnughBrxPRIIgixgBiJIBggRiIIBoiRCIIBMWsk27dvx7Rp0+BwOFBQUIBPPvlktLs0LikrK8OiRYvgdDqRlpaGVatWoaamRtfmq14qKiaNZPfu3di0aRO2bNmCP//5z1iwYAFWrlyJlpaW0e7auKOyshIlJSU4dOgQ3nvvPQSDQaxYsQJdXdeTHr/ypaK0GGTx4sVaSUnJwHEoFNI8Ho9WVlY2ir36atDS0qIB0CorKzVN07T29nbNarVqe/bsGWhz+vRpDYBWVVU1Wt28pcTcSNLX14fq6mpdaSKz2YyioiIpTXQL8Pl8AK7WUwMgpaIQg7dbbW1tCIVCSE/X76BkVJpIuHnC4TA2btyIpUuXYt68eQAAr9c7pFJR44mYywIWRo+SkhKcOHECf/jDH0a7KzFFzI0kEydOhMViodkTo9JEws2xfv167Nu3Dx9++OHAUgUAQy4VNZ6IOSOx2WzIz89HRUXFgBYOh1FRUfGlpYmEoaFpGtavX4+9e/figw8+wPTp+k1Sv1gq6hrRlIoaV4z2zIGKXbt2aXa7XSsvL9dOnTqlrV27VnO73ZrX6x3tro071q1bp7lcLu3AgQNaU1PTwKO7u3ugzfe+9z0tOztb++CDD7QjR45ohYWFWmFh4Sj2+tYSk0aiaZr2i1/8QsvOztZsNpu2ePFi7dChQ6PdpXEJrtatoMeOHTsG2vT09Gjf//73tQkTJmgJCQnaN7/5Ta2pqWn0On2LkVR5QTAg5nwSQYg1xEgEwQAxEkEwQIxEEAwQIxEEA8RIBMEAMRJBMECMRBAMECMZ5/z4xz9GXl7eaHdjTCNGIggGiJGMAcLhMLZu3YqcnBzY7XZkZ2fjJz/5CQDgmWeewcyZM5GQkIDbbrsNzz33HILBIACgvLwcL7zwAv7yl7/AZDLBZDKhvLx8FF/J2EQWXY0BSktL8eabb2Lbtm1YtmwZmpqacObMGQCA0+lEeXk5PB4Pjh8/ju9+97twOp3YvHkzVq9ejRMnTmD//v14//33AUS/3YDwBUY7w1L4cvx+v2a327U333wzqvYvv/yylp+fP3C8ZcsWbcGCBSPUu68GMpLEOKdPn0YgEMB9992n/P/u3bvx6quv4vz58+js7ER/f/+43HBnNBGfJMaJj4+/4f+qqqrw2GOP4YEHHsC+fftw9OhRPPvss+jr67uFPRz/iJHEOLm5uYiPj9ctn73Gxx9/jKlTp+LZZ5/FwoULkZubi7q6Ol0bm82GUCh0q7o7LpHbrRjH4XDgmWeewebNm2Gz2bB06VK0trbi5MmTyM3NRX19PXbt2oVFixbh97//Pfbu3as7f9q0aaitrcWxY8eQmZkJp9P5ld+UZ9CMtlMkGBMKhbSXXnpJmzp1qma1WrXs7Gztpz/9qaZpmvajH/1IS01N1ZKSkrTVq1dr27Zt01wu18C5vb29WnFxseZ2u2lZrhAdsnxXEAwQn0QQDBAjEQQDxEgEwQAxEkEwQIxEEAwQIxEEA8RIBMEAMRJBMECMRBAMECMRBAPESATBADESQTDg/wM/KqNvEJk6/wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_sample(x_test, y_pred_classes, 10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vDc2CJbY24jE",
        "FXQKQ7d1qU7F",
        "P8fvc4SG5h2b",
        "zbmbr9Ol-wb0"
      ],
      "authorship_tag": "ABX9TyPGdm3ILc1tnhvWWJwq03Xc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
